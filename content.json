{"meta":{"title":"Providence's blog","subtitle":"所有的愤怒都来自力不从心","description":"记录我的生活","author":"Ty","url":"https://blog.providencezhang.cn","root":"/"},"pages":[],"posts":[{"title":"学习资源","date":"2021-04-07T02:06:25.000Z","path":"2021/04/07/学习资源/","text":"线上学习资源汇总可以不上学，但是一定要学习，不断学习 技术相关基础管理相关金融相关xalpha——基金投资的全流程管理：github 书单资源获取一、视频类 预告片世界：https://www.yugaopian.cn/ 33台词：http://33.agilestudio.cn/3.MixKit：https://mixkit.co/free-stock-video/4.Pexel：https://www.pexels.com/zh-cn/video/5.Videezy：https://www.videezy.com/6.VJShi：https://www.vjshi.com/ 二、PPT模板类1.51PPT模板：http://www.51pptmoban.com/2.优品PPT：https://www.ypppt.com/3.第一PPT：http://www.1ppt.com/4.叮当设计：https://www.dingdangsheji.com/5.PPT超级市场：http://ppt.sotary.com/web/wxapp/index.html 三：静态图片1.PH：https://pxhere.com/2.CC0图片网：https://cc0.cn/3.Foodiesfeed：https://www.foodiesfeed.com/4.Unplash：https://unsplash.com/5.Pixabay：https://pixabay.com/ 四、动态图1.Giphy：https://giphy.com/2.GfyCat：https://gfycat.com/3.Tenor：https://tenor.com/4.GIF ABYSS：https://gifs.alphacoders.com/5.动图宇宙：https://biaoqingsoso.com/6.Soogif：https://www.soogif.com/7.闪萌：http://www.weshineapp.com/ 五、壁纸1.WallHaven：https://wallhaven.cc/2.10Wallpaper：https://www.10wallpaper.com/3.alphacoders：https://wall.alphacoders.com/?lang=Chinese4.极简壁纸：https://bz.zzzmh.cn/index5.3G壁纸：https://www.3gbizhi.com/6.必应壁纸：https://bing.ioliu.cn/ 六、图标类1.阿里巴巴矢量图库：https://www.iconfont.cn/2.Ikonate：https://ikonate.com/3.iconstore：https://iconstore.co/4.icoon：https://icooon-mono.com/5.iconfinder：https://www.iconfinder.com/ 七、PSD模板1.素材中国：http://www.sccnn.com/2.站长素材：https://sc.chinaz.com/psd/3.365PSD：https://cn.365psd.com/free-psd4.freepik：https://www.freepik.com/psd5.freebiesbug： https://freebiesbug.com/ 八、音频类1.Mixkit：https://mixkit.co/free-stock-music/2.爱给网：https://www.aigei.com/3.淘声网：https://www.tosound.com/4.耳聆：https://www.ear0.com/ [Internet/互联网][资源整合]让科技更好的服务你 https://www.bilibili.com/read/cv11445790","raw":"---\ntitle: 学习资源\ndate: 2021-04-7 10:06:25\ntags:\n    - 学习笔记\n    - 资源链接\n---\n\n# 线上学习资源汇总\n\n可以不上学，但是一定要学习，不断学习\n\n## 技术相关\n\n### 基础\n\n## 管理相关\n\n## 金融相关\n\nxalpha——基金投资的全流程管理：[github](https://github.com/refraction-ray/xalpha)\n\n# 书单\n\n# 资源获取\n\n一、视频类\n1. 预告片世界：https://www.yugaopian.cn/\n2. 33台词：http://33.agilestudio.cn/\n3.MixKit：https://mixkit.co/free-stock-video/ \n4.Pexel：https://www.pexels.com/zh-cn/video/ \n5.Videezy：https://www.videezy.com/ \n6.VJShi：https://www.vjshi.com/ \n\n二、PPT模板类\n1.51PPT模板：http://www.51pptmoban.com/ \n2.优品PPT：https://www.ypppt.com/ \n3.第一PPT：http://www.1ppt.com/ \n4.叮当设计：https://www.dingdangsheji.com/ \n5.PPT超级市场：http://ppt.sotary.com/web/wxapp/index.html \n\n三：静态图片\n1.PH：https://pxhere.com/ \n2.CC0图片网：https://cc0.cn/ \n3.Foodiesfeed：https://www.foodiesfeed.com/ \n4.Unplash：https://unsplash.com/ \n5.Pixabay：https://pixabay.com/ \n\n四、动态图\n1.Giphy：https://giphy.com/ \n2.GfyCat：https://gfycat.com/ \n3.Tenor：https://tenor.com/ \n4.GIF ABYSS：https://gifs.alphacoders.com/ \n5.动图宇宙：https://biaoqingsoso.com/ \n6.Soogif：https://www.soogif.com/ \n7.闪萌：http://www.weshineapp.com/\n\n五、壁纸\n1.WallHaven：https://wallhaven.cc/ \n2.10Wallpaper：https://www.10wallpaper.com/ \n3.alphacoders：https://wall.alphacoders.com/?lang=Chinese \n4.极简壁纸：https://bz.zzzmh.cn/index \n5.3G壁纸：https://www.3gbizhi.com/ \n6.必应壁纸：https://bing.ioliu.cn/ \n\n六、图标类\n1.阿里巴巴矢量图库：https://www.iconfont.cn/ \n2.Ikonate：https://ikonate.com/ \n3.iconstore：https://iconstore.co/ \n4.icoon：https://icooon-mono.com/ \n5.iconfinder：https://www.iconfinder.com/\n\n七、PSD模板\n1.素材中国：http://www.sccnn.com/ \n2.站长素材：https://sc.chinaz.com/psd/ \n3.365PSD：https://cn.365psd.com/free-psd \n4.freepik：https://www.freepik.com/psd \n5.freebiesbug： https://freebiesbug.com/ \n\n八、音频类\n1.Mixkit：https://mixkit.co/free-stock-music/ \n2.爱给网：https://www.aigei.com/ \n3.淘声网：https://www.tosound.com/ \n4.耳聆：https://www.ear0.com/\n\n[Internet/互联网][资源整合]让科技更好的服务你 https://www.bilibili.com/read/cv11445790","content":"<h1 id=\"线上学习资源汇总\"><a href=\"#线上学习资源汇总\" class=\"headerlink\" title=\"线上学习资源汇总\"></a>线上学习资源汇总</h1><p>可以不上学，但是一定要学习，不断学习</p>\n<h2 id=\"技术相关\"><a href=\"#技术相关\" class=\"headerlink\" title=\"技术相关\"></a>技术相关</h2><h3 id=\"基础\"><a href=\"#基础\" class=\"headerlink\" title=\"基础\"></a>基础</h3><h2 id=\"管理相关\"><a href=\"#管理相关\" class=\"headerlink\" title=\"管理相关\"></a>管理相关</h2><h2 id=\"金融相关\"><a href=\"#金融相关\" class=\"headerlink\" title=\"金融相关\"></a>金融相关</h2><p>xalpha——基金投资的全流程管理：<a href=\"https://github.com/refraction-ray/xalpha\">github</a></p>\n<h1 id=\"书单\"><a href=\"#书单\" class=\"headerlink\" title=\"书单\"></a>书单</h1><h1 id=\"资源获取\"><a href=\"#资源获取\" class=\"headerlink\" title=\"资源获取\"></a>资源获取</h1><p>一、视频类</p>\n<ol>\n<li>预告片世界：<a href=\"https://www.yugaopian.cn/\">https://www.yugaopian.cn/</a></li>\n<li>33台词：<a href=\"http://33.agilestudio.cn/\">http://33.agilestudio.cn/</a><br>3.MixKit：<a href=\"https://mixkit.co/free-stock-video/\">https://mixkit.co/free-stock-video/</a><br>4.Pexel：<a href=\"https://www.pexels.com/zh-cn/video/\">https://www.pexels.com/zh-cn/video/</a><br>5.Videezy：<a href=\"https://www.videezy.com/\">https://www.videezy.com/</a><br>6.VJShi：<a href=\"https://www.vjshi.com/\">https://www.vjshi.com/</a> </li>\n</ol>\n<p>二、PPT模板类<br>1.51PPT模板：<a href=\"http://www.51pptmoban.com/\">http://www.51pptmoban.com/</a><br>2.优品PPT：<a href=\"https://www.ypppt.com/\">https://www.ypppt.com/</a><br>3.第一PPT：<a href=\"http://www.1ppt.com/\">http://www.1ppt.com/</a><br>4.叮当设计：<a href=\"https://www.dingdangsheji.com/\">https://www.dingdangsheji.com/</a><br>5.PPT超级市场：<a href=\"http://ppt.sotary.com/web/wxapp/index.html\">http://ppt.sotary.com/web/wxapp/index.html</a> </p>\n<p>三：静态图片<br>1.PH：<a href=\"https://pxhere.com/\">https://pxhere.com/</a><br>2.CC0图片网：<a href=\"https://cc0.cn/\">https://cc0.cn/</a><br>3.Foodiesfeed：<a href=\"https://www.foodiesfeed.com/\">https://www.foodiesfeed.com/</a><br>4.Unplash：<a href=\"https://unsplash.com/\">https://unsplash.com/</a><br>5.Pixabay：<a href=\"https://pixabay.com/\">https://pixabay.com/</a> </p>\n<p>四、动态图<br>1.Giphy：<a href=\"https://giphy.com/\">https://giphy.com/</a><br>2.GfyCat：<a href=\"https://gfycat.com/\">https://gfycat.com/</a><br>3.Tenor：<a href=\"https://tenor.com/\">https://tenor.com/</a><br>4.GIF ABYSS：<a href=\"https://gifs.alphacoders.com/\">https://gifs.alphacoders.com/</a><br>5.动图宇宙：<a href=\"https://biaoqingsoso.com/\">https://biaoqingsoso.com/</a><br>6.Soogif：<a href=\"https://www.soogif.com/\">https://www.soogif.com/</a><br>7.闪萌：<a href=\"http://www.weshineapp.com/\">http://www.weshineapp.com/</a></p>\n<p>五、壁纸<br>1.WallHaven：<a href=\"https://wallhaven.cc/\">https://wallhaven.cc/</a><br>2.10Wallpaper：<a href=\"https://www.10wallpaper.com/\">https://www.10wallpaper.com/</a><br>3.alphacoders：<a href=\"https://wall.alphacoders.com/?lang=Chinese\">https://wall.alphacoders.com/?lang=Chinese</a><br>4.极简壁纸：<a href=\"https://bz.zzzmh.cn/index\">https://bz.zzzmh.cn/index</a><br>5.3G壁纸：<a href=\"https://www.3gbizhi.com/\">https://www.3gbizhi.com/</a><br>6.必应壁纸：<a href=\"https://bing.ioliu.cn/\">https://bing.ioliu.cn/</a> </p>\n<p>六、图标类<br>1.阿里巴巴矢量图库：<a href=\"https://www.iconfont.cn/\">https://www.iconfont.cn/</a><br>2.Ikonate：<a href=\"https://ikonate.com/\">https://ikonate.com/</a><br>3.iconstore：<a href=\"https://iconstore.co/\">https://iconstore.co/</a><br>4.icoon：<a href=\"https://icooon-mono.com/\">https://icooon-mono.com/</a><br>5.iconfinder：<a href=\"https://www.iconfinder.com/\">https://www.iconfinder.com/</a></p>\n<p>七、PSD模板<br>1.素材中国：<a href=\"http://www.sccnn.com/\">http://www.sccnn.com/</a><br>2.站长素材：<a href=\"https://sc.chinaz.com/psd/\">https://sc.chinaz.com/psd/</a><br>3.365PSD：<a href=\"https://cn.365psd.com/free-psd\">https://cn.365psd.com/free-psd</a><br>4.freepik：<a href=\"https://www.freepik.com/psd\">https://www.freepik.com/psd</a><br>5.freebiesbug： <a href=\"https://freebiesbug.com/\">https://freebiesbug.com/</a> </p>\n<p>八、音频类<br>1.Mixkit：<a href=\"https://mixkit.co/free-stock-music/\">https://mixkit.co/free-stock-music/</a><br>2.爱给网：<a href=\"https://www.aigei.com/\">https://www.aigei.com/</a><br>3.淘声网：<a href=\"https://www.tosound.com/\">https://www.tosound.com/</a><br>4.耳聆：<a href=\"https://www.ear0.com/\">https://www.ear0.com/</a></p>\n<p>[Internet/互联网][资源整合]让科技更好的服务你 <a href=\"https://www.bilibili.com/read/cv11445790\">https://www.bilibili.com/read/cv11445790</a></p>\n","slug":"学习资源","updated":"2021-06-26T15:49:17.998Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2021/04/07/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90/","excerpt":"","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"资源链接","slug":"资源链接","permalink":"https://blog.providencezhang.cn/tags/%E8%B5%84%E6%BA%90%E9%93%BE%E6%8E%A5/"}]},{"title":"装修记录","date":"2021-02-19T00:48:01.000Z","path":"2021/02/19/装修记录/","text":"装修踩坑记录硬装墙漆类型：分为水性漆与油漆，大多使用油漆品牌：基本上就是立邦和多乐士，多乐士的调色更好一些施工方式：一遍底漆，两遍面漆（实际施工只用了两遍面漆，大面积刮腻子需要先刷底漆）准备工具：滚子（重点是不掉毛，30块左右），小刷子，托盘（盆加纸板也可以代替），美纹纸，工装 地板类型：强化复合，实木复合，实木（价格递增）最终选用圣象强化复合，170一平 灯具欧普两室套装四件套，米家智控（京东年货节￥680）安装：钻孔，膨胀螺丝 软装沙发科技布+4cm乳胶+高弹海绵 双人位1.8m 阿里巴巴 ￥1734 升降桌180*80 淘宝升降桌工厂直销店 ￥1729","raw":"---\ntitle: 装修记录\ndate: 2021-02-19 08:48:01\ntags:\n    - 装修\n    - 建材\n    - 室内设计\ncategories: 随笔\n\n---\n\n# 装修踩坑记录\n\n## 硬装\n\n### 墙漆\n\n类型：分为水性漆与油漆，大多使用油漆  \n品牌：基本上就是立邦和多乐士，多乐士的调色更好一些\n施工方式：一遍底漆，两遍面漆（实际施工只用了两遍面漆，大面积刮腻子需要先刷底漆）  \n准备工具：滚子（重点是不掉毛，30块左右），小刷子，托盘（盆加纸板也可以代替），美纹纸，工装  \n\n### 地板\n\n类型：强化复合，实木复合，实木（价格递增）  \n最终选用圣象强化复合，170一平  \n\n### 灯具\n\n欧普两室套装四件套，米家智控（京东年货节￥680）  \n安装：钻孔，膨胀螺丝  \n\n## 软装\n\n### 沙发\n\n科技布+4cm乳胶+高弹海绵 双人位1.8m 阿里巴巴 ￥1734\n\n### 升降桌\n\n180*80 淘宝升降桌工厂直销店 ￥1729\n","content":"<h1 id=\"装修踩坑记录\"><a href=\"#装修踩坑记录\" class=\"headerlink\" title=\"装修踩坑记录\"></a>装修踩坑记录</h1><h2 id=\"硬装\"><a href=\"#硬装\" class=\"headerlink\" title=\"硬装\"></a>硬装</h2><h3 id=\"墙漆\"><a href=\"#墙漆\" class=\"headerlink\" title=\"墙漆\"></a>墙漆</h3><p>类型：分为水性漆与油漆，大多使用油漆<br>品牌：基本上就是立邦和多乐士，多乐士的调色更好一些<br>施工方式：一遍底漆，两遍面漆（实际施工只用了两遍面漆，大面积刮腻子需要先刷底漆）<br>准备工具：滚子（重点是不掉毛，30块左右），小刷子，托盘（盆加纸板也可以代替），美纹纸，工装  </p>\n<h3 id=\"地板\"><a href=\"#地板\" class=\"headerlink\" title=\"地板\"></a>地板</h3><p>类型：强化复合，实木复合，实木（价格递增）<br>最终选用圣象强化复合，170一平  </p>\n<h3 id=\"灯具\"><a href=\"#灯具\" class=\"headerlink\" title=\"灯具\"></a>灯具</h3><p>欧普两室套装四件套，米家智控（京东年货节￥680）<br>安装：钻孔，膨胀螺丝  </p>\n<h2 id=\"软装\"><a href=\"#软装\" class=\"headerlink\" title=\"软装\"></a>软装</h2><h3 id=\"沙发\"><a href=\"#沙发\" class=\"headerlink\" title=\"沙发\"></a>沙发</h3><p>科技布+4cm乳胶+高弹海绵 双人位1.8m 阿里巴巴 ￥1734</p>\n<h3 id=\"升降桌\"><a href=\"#升降桌\" class=\"headerlink\" title=\"升降桌\"></a>升降桌</h3><p>180*80 淘宝升降桌工厂直销店 ￥1729</p>\n","slug":"装修记录","updated":"2021-04-07T10:39:07.261Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2021/02/19/%E8%A3%85%E4%BF%AE%E8%AE%B0%E5%BD%95/","excerpt":"","categories":[{"name":"随笔","slug":"随笔","permalink":"https://blog.providencezhang.cn/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"装修","slug":"装修","permalink":"https://blog.providencezhang.cn/tags/%E8%A3%85%E4%BF%AE/"},{"name":"建材","slug":"建材","permalink":"https://blog.providencezhang.cn/tags/%E5%BB%BA%E6%9D%90/"},{"name":"室内设计","slug":"室内设计","permalink":"https://blog.providencezhang.cn/tags/%E5%AE%A4%E5%86%85%E8%AE%BE%E8%AE%A1/"}]},{"title":"杂记：工具以及日常命令合集","date":"2020-11-16T03:59:11.000Z","path":"2020/11/16/tools/","text":"网络相关windows命令行设置代理设置代理netsh winhttp set proxy 127.0.0.1:10808取消代理netsh winhttp reset proxy查看代理netsh winhttp show proxy pip下载速度慢python -m pip install —upgrade pip太慢 输入：python -m pip install —upgrade pip -i http://pypi.douban.com/simple —trusted-host pypi.douban.com 其他下载链接：豆瓣(douban) http://pypi.douban.com/simple/阿里云 http://mirrors.aliyun.com/pypi/simple/中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/anaconda 环境中pip install 第三方库下载较慢； pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas windows上使用linuxwsl和vm Adreno Profiler提取 网易镇魔曲手游美术资源","raw":"---\ntitle: 杂记：工具以及日常命令合集\ndate: 2020-11-16 11:59:11\ntags:\n---\n\n# 网络相关\n\n## windows\n\n### 命令行设置代理\n\n设置代理\nnetsh winhttp set proxy 127.0.0.1:10808\n取消代理\nnetsh winhttp reset proxy\n查看代理\nnetsh winhttp show proxy\n\n### pip下载速度慢\n\npython -m pip install --upgrade pip太慢\n\n输入：\npython -m pip install --upgrade pip  -i http://pypi.douban.com/simple --trusted-host pypi.douban.com\n\n其他下载链接：\n豆瓣(douban) http://pypi.douban.com/simple/\n阿里云 http://mirrors.aliyun.com/pypi/simple/\n中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/\n清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/\n中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/\nanaconda 环境中pip install 第三方库下载较慢；\n\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas\n\n### windows上使用linux\n\nwsl和vm\n\n# Adreno Profiler提取 网易镇魔曲手游美术资源","content":"<h1 id=\"网络相关\"><a href=\"#网络相关\" class=\"headerlink\" title=\"网络相关\"></a>网络相关</h1><h2 id=\"windows\"><a href=\"#windows\" class=\"headerlink\" title=\"windows\"></a>windows</h2><h3 id=\"命令行设置代理\"><a href=\"#命令行设置代理\" class=\"headerlink\" title=\"命令行设置代理\"></a>命令行设置代理</h3><p>设置代理<br>netsh winhttp set proxy 127.0.0.1:10808<br>取消代理<br>netsh winhttp reset proxy<br>查看代理<br>netsh winhttp show proxy</p>\n<h3 id=\"pip下载速度慢\"><a href=\"#pip下载速度慢\" class=\"headerlink\" title=\"pip下载速度慢\"></a>pip下载速度慢</h3><p>python -m pip install —upgrade pip太慢</p>\n<p>输入：<br>python -m pip install —upgrade pip  -i <a href=\"http://pypi.douban.com/simple\">http://pypi.douban.com/simple</a> —trusted-host pypi.douban.com</p>\n<p>其他下载链接：<br>豆瓣(douban) <a href=\"http://pypi.douban.com/simple/\">http://pypi.douban.com/simple/</a><br>阿里云 <a href=\"http://mirrors.aliyun.com/pypi/simple/\">http://mirrors.aliyun.com/pypi/simple/</a><br>中国科技大学 <a href=\"https://pypi.mirrors.ustc.edu.cn/simple/\">https://pypi.mirrors.ustc.edu.cn/simple/</a><br>清华大学 <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple/\">https://pypi.tuna.tsinghua.edu.cn/simple/</a><br>中国科学技术大学 <a href=\"http://pypi.mirrors.ustc.edu.cn/simple/\">http://pypi.mirrors.ustc.edu.cn/simple/</a><br>anaconda 环境中pip install 第三方库下载较慢；</p>\n<p>pip install -i <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\">https://pypi.tuna.tsinghua.edu.cn/simple</a> pandas</p>\n<h3 id=\"windows上使用linux\"><a href=\"#windows上使用linux\" class=\"headerlink\" title=\"windows上使用linux\"></a>windows上使用linux</h3><p>wsl和vm</p>\n<h1 id=\"Adreno-Profiler提取-网易镇魔曲手游美术资源\"><a href=\"#Adreno-Profiler提取-网易镇魔曲手游美术资源\" class=\"headerlink\" title=\"Adreno Profiler提取 网易镇魔曲手游美术资源\"></a>Adreno Profiler提取 网易镇魔曲手游美术资源</h1>","slug":"tools","updated":"2021-04-07T10:39:07.256Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/11/16/tools/","excerpt":"","categories":[],"tags":[]},{"title":"Games101图形学入门课程","date":"2020-09-03T06:42:22.000Z","path":"2020/09/03/Games101/","text":"Games-cn 101图形学课程视频链接官网链接 P4 Transformation旋转矩阵是正交矩阵，正交矩阵的逆=正交矩阵的转置 TODO 投影变换推导（透视投影，正交投影，弱透视投影）参考资料 p6 Rasterization 2走样的本质：Sample（采样）的本质是离散化表示一个时域图像，离散化表示时域图像在频域上看是对频域图像的不断复制。当分辨率低，采样间隔大时，频域空间的间隔反而小，这会导致重复的频域图像间有重叠，结果就是导致走样。 p7 Shading 1Lambertian(Diffuse) Shading independent of view direction L_{d} = k_{d}(I/r^{2})max(0,n·l)视频连接59:00 p8 Shading 2Specular Term(Blinn-Phong) h = bisector(v,I) \\\\ = {v+l\\over \\parallel v+l \\parallel}L_{s} = k_{s}(I/r^{2})max(0,cos\\alpha) \\\\ = k_{s}(I/r^{2})max(0,n·h) 高光和观察点（相机）位置有关系，越光滑的平面越接近镜面反射，反之会形成围绕反射方向的一个反射区间，Blinn-Phong通过引入半程向量，比较半程向量和法线是否接近（blinn-phong）来代替出射方向和视角方向是否接近（phong），因为出射方向不好算 高光项会加个指数p，来控制高光区域的大小 L_{s} = k_{s}(I/r^{2})max(0,n·h)^{p}Ambient Term在blinn-phong中就是个常数项，以后会接触GI，比较复杂 shading频率：Flat、Gouraud、Phong分别对应逐面、逐顶点、逐像素 p9 Shading 3Barycentric Coordinates（重心坐标）： \\alpha + \\beta + \\gamma = 1\\alpha A + \\beta B + \\gamma C = (x,y)ABC三点平面内的任意点P(x,y)可以用上式表达，当$\\alpha \\beta \\gamma$ 均 &gt;0 时，点P在三角形内部$\\alpha \\beta \\gamma$ 的值可以通过三角想面积求得15:00 处理摩尔纹：mipmap计算Mipmap Level D： $D = log_{2}L$三线性插值：一个插值是level与level间的，一个是纹理相邻像素间的 Overblur：用各向异性过滤 == Ripmap，就是生成横竖拉伸的，大小为原来纹理三倍的纹理贴图","raw":"---\ntitle: Games101图形学入门课程\ndate: 2020-09-03 14:42:22\nmathjax: true\ntags:\n    - 图形学\n    - 线上课程\n---\n\n# Games-cn 101图形学课程\n\n[视频链接](https://www.bilibili.com/video/BV1X7411F744)  \n[官网链接](http://games-cn.org/intro-graphics/)\n\n## P4 Transformation\n\n旋转矩阵是正交矩阵，正交矩阵的逆=正交矩阵的转置  \n\nTODO 投影变换推导（透视投影，正交投影，弱透视投影）\n[参考资料](https://zhuanlan.zhihu.com/p/158856632)\n\n## p6 Rasterization 2\n\n走样的本质：Sample（采样）的本质是离散化表示一个时域图像，离散化表示时域图像在频域上看是对频域图像的不断复制。当分辨率低，采样间隔大时，频域空间的间隔反而小，这会导致重复的频域图像间有重叠，结果就是导致走样。\n\n\n## p7 Shading 1\n\nLambertian(Diffuse) Shading independent of view direction\n$$ L_{d} = k_{d}(I/r^{2})max(0,n·l) $$\n[视频连接59:00](https://www.bilibili.com/video/BV1X7411F744?p=7)\n\n## p8 Shading 2\n\nSpecular Term(Blinn-Phong)\n$$ h = bisector(v,I) \\\\\n     = {v+l\\over \\parallel v+l \\parallel} $$\n$$ L_{s} = k_{s}(I/r^{2})max(0,cos\\alpha) \\\\\n         = k_{s}(I/r^{2})max(0,n·h) $$\n> 高光和观察点（相机）位置有关系，越光滑的平面越接近镜面反射，反之会形成围绕反射方向的一个反射区间，Blinn-Phong通过引入半程向量，比较半程向量和法线是否接近（blinn-phong）来代替出射方向和视角方向是否接近（phong），因为出射方向不好算  \n\n高光项会加个指数p，来控制高光区域的大小\n$$ L_{s} = k_{s}(I/r^{2})max(0,n·h)^{p} $$\n\n\nAmbient Term在blinn-phong中就是个常数项，以后会接触GI，比较复杂  \n\nshading频率：Flat、Gouraud、Phong分别对应逐面、逐顶点、逐像素  \n\n## p9 Shading 3\n\nBarycentric Coordinates（重心坐标）：\n$$ \\alpha + \\beta + \\gamma = 1 $$\n$$ \\alpha A + \\beta B + \\gamma C = (x,y) $$\nABC三点平面内的任意点P(x,y)可以用上式表达，当$\\alpha \\beta \\gamma$ 均 >0 时，点P在三角形内部  \n$\\alpha \\beta \\gamma$ 的值可以[通过三角想面积求得15:00](https://www.bilibili.com/video/BV1X7411F744?p=9)  \n\n处理摩尔纹：mipmap  \n计算Mipmap Level D： $D = log_{2}L$  \n三线性插值：一个插值是level与level间的，一个是纹理相邻像素间的  \n\nOverblur：用各向异性过滤 == Ripmap，就是生成横竖拉伸的，大小为原来纹理三倍的纹理贴图  \n\n","content":"<h1 id=\"Games-cn-101图形学课程\"><a href=\"#Games-cn-101图形学课程\" class=\"headerlink\" title=\"Games-cn 101图形学课程\"></a>Games-cn 101图形学课程</h1><p><a href=\"https://www.bilibili.com/video/BV1X7411F744\">视频链接</a><br><a href=\"http://games-cn.org/intro-graphics/\">官网链接</a></p>\n<h2 id=\"P4-Transformation\"><a href=\"#P4-Transformation\" class=\"headerlink\" title=\"P4 Transformation\"></a>P4 Transformation</h2><p>旋转矩阵是正交矩阵，正交矩阵的逆=正交矩阵的转置  </p>\n<p>TODO 投影变换推导（透视投影，正交投影，弱透视投影）<br><a href=\"https://zhuanlan.zhihu.com/p/158856632\">参考资料</a></p>\n<h2 id=\"p6-Rasterization-2\"><a href=\"#p6-Rasterization-2\" class=\"headerlink\" title=\"p6 Rasterization 2\"></a>p6 Rasterization 2</h2><p>走样的本质：Sample（采样）的本质是离散化表示一个时域图像，离散化表示时域图像在频域上看是对频域图像的不断复制。当分辨率低，采样间隔大时，频域空间的间隔反而小，这会导致重复的频域图像间有重叠，结果就是导致走样。</p>\n<h2 id=\"p7-Shading-1\"><a href=\"#p7-Shading-1\" class=\"headerlink\" title=\"p7 Shading 1\"></a>p7 Shading 1</h2><p>Lambertian(Diffuse) Shading independent of view direction</p>\n<script type=\"math/tex; mode=display\">L_{d} = k_{d}(I/r^{2})max(0,n·l)</script><p><a href=\"https://www.bilibili.com/video/BV1X7411F744?p=7\">视频连接59:00</a></p>\n<h2 id=\"p8-Shading-2\"><a href=\"#p8-Shading-2\" class=\"headerlink\" title=\"p8 Shading 2\"></a>p8 Shading 2</h2><p>Specular Term(Blinn-Phong)</p>\n<script type=\"math/tex; mode=display\">h = bisector(v,I) \\\\\n     = {v+l\\over \\parallel v+l \\parallel}</script><script type=\"math/tex; mode=display\">L_{s} = k_{s}(I/r^{2})max(0,cos\\alpha) \\\\\n         = k_{s}(I/r^{2})max(0,n·h)</script><blockquote>\n<p>高光和观察点（相机）位置有关系，越光滑的平面越接近镜面反射，反之会形成围绕反射方向的一个反射区间，Blinn-Phong通过引入半程向量，比较半程向量和法线是否接近（blinn-phong）来代替出射方向和视角方向是否接近（phong），因为出射方向不好算  </p>\n</blockquote>\n<p>高光项会加个指数p，来控制高光区域的大小</p>\n<script type=\"math/tex; mode=display\">L_{s} = k_{s}(I/r^{2})max(0,n·h)^{p}</script><p>Ambient Term在blinn-phong中就是个常数项，以后会接触GI，比较复杂  </p>\n<p>shading频率：Flat、Gouraud、Phong分别对应逐面、逐顶点、逐像素  </p>\n<h2 id=\"p9-Shading-3\"><a href=\"#p9-Shading-3\" class=\"headerlink\" title=\"p9 Shading 3\"></a>p9 Shading 3</h2><p>Barycentric Coordinates（重心坐标）：</p>\n<script type=\"math/tex; mode=display\">\\alpha + \\beta + \\gamma = 1</script><script type=\"math/tex; mode=display\">\\alpha A + \\beta B + \\gamma C = (x,y)</script><p>ABC三点平面内的任意点P(x,y)可以用上式表达，当$\\alpha \\beta \\gamma$ 均 &gt;0 时，点P在三角形内部<br>$\\alpha \\beta \\gamma$ 的值可以<a href=\"https://www.bilibili.com/video/BV1X7411F744?p=9\">通过三角想面积求得15:00</a>  </p>\n<p>处理摩尔纹：mipmap<br>计算Mipmap Level D： $D = log_{2}L$<br>三线性插值：一个插值是level与level间的，一个是纹理相邻像素间的  </p>\n<p>Overblur：用各向异性过滤 == Ripmap，就是生成横竖拉伸的，大小为原来纹理三倍的纹理贴图  </p>\n","slug":"Games101","updated":"2020-09-29T12:04:24.302Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/09/03/Games101/","excerpt":"","categories":[],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://blog.providencezhang.cn/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"线上课程","slug":"线上课程","permalink":"https://blog.providencezhang.cn/tags/%E7%BA%BF%E4%B8%8A%E8%AF%BE%E7%A8%8B/"}]},{"title":"来自网络的C++笔记","date":"2020-08-27T16:00:00.000Z","path":"2020/08/28/Cpp/","text":"基础知识RAII全称是 Resource Acquisition Is Initialization ， 即“资源获取即初始化”，其核心是把资源和对象的生命周期绑定：对象创建获取资源，对象销毁释放资源。这就是的资源也有了生命周期，有了自动回收的功能。lock_guard 都利用了 RAII机制来实现。 防止内存泄露的方式有 RAII、智能指针。 大端和小端 大端就是高字节在高地址，低字节在低地址。 小端就是低字节在高地址，高字节在低地址。 123456789101112131415// 大端小端区分 bool isBigEndian() &#123; union NUM &#123; int a; char b; // 如果是大端 b 就是最高位 ，小端就是最低位 &#125;num; num.a = 0x1234; if(num.b == 0x12) &#123; return true; &#125; return false; &#125; 大端小端转换 12345678910//无符号整型16位 uint16_t bswap_16(uint16_t x) &#123; return ((x &amp; 0x00ff) &lt;&lt; 8) | (x &amp; 0xff00) &gt;&gt; 8) ; &#125; //无符号整型32位uint32_t bswap_32(uint32_t x) &#123; return ((x &amp; 0xff000000) &gt;&gt; 24)| ((x &amp; 0x00ff0000) &gt;&gt; 8) | \\ ((x &amp; 0x0000ff00) &lt;&lt; 8) | ((x &amp; 0x000000ff) &lt;&lt; 24) ; &#125; 生成可执行文件过程及各个过程完成的事情： 预编译处理(.c) : 将源文件main.cc 翻译成一个ASCII码的中间件文件 main.i 编译、优化程序（.s、.asm）： 将 main.i文件 翻译成一个 ASCII 汇编文件 main.s 汇编程序(.obj、.o、.a、.ko) ：运行汇编器，将 main.s 翻译成一个可重定位目标文件main.o 链接程序（.exe、.elf、.axf等） ： 运行链接器，将main.o 中使用到的目标文件组合起来，创建一个可执行的文件 为了构造可执行文件，这链接器必须完成两个主要任务： 符号解析 ：目的是将每个符号引用正好和一个符号定义关联起来。每个符号对应于一个函数、全局变量、static变量等 重定位：对于由编译器和汇编器生成的从地址0开始的代码和数据节，链接器将每个符号定义与一个内存位置关联起来，从而重定位这些数据节，然后修改所有对这些符号的引用，使得他们指向内存位置。静态库与动态库 根本区别：是在编译期还是在是执行期完成链接、装入动作。链接的主要内容就是把各个模块之间相互引用的部分都处理好，使得各个模块之间能够正确地衔接 静态库：之所以叫做静态库，是因为在链接阶段，当使用链接器将由汇编生成的目标文件构造成一个可执行的输出文件时，它只是复制静态库中里这个即将生成的可执行文件所引用到的目标模块。静态库特点总结： 静态库对函数库的链接是放在编译时期完成的。 程序在运行时与函数库再无瓜葛，移植方便。 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。 动态库：动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，增量更新 + 动态库把对一些库函数的**链接载入**推迟到程序运行的时期。 可以实现进程之间的资源共享。（因此动态库也称为共享库） 将一些程序升级变得简单。 甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）。 编译型语言和解释型语言的区别 编译型语言在运行前就生成可执行文件，运行时就没有编译了 解释型语言在运行的时候才翻译static、extern、全局变量 static全局变量与普通的全局变量有什么区别：static全局变量只初使化一次，防止在其他文件单元中被引用; static局部变量和普通局部变量有什么区别：static局部变量只被初始化一次，下一次依据上一次结果值； 程序的局部变量存在于（堆栈）中，全局变量存在于（静态区 ）中，动态申请数据存在于（ 堆）中。 extern全局变量(用extern修饰的变量只是说明该变量在其他地方定义，所以在其他地方一定要用明确的定义如int a，并且不能用static修饰）、static全局变量和static局部变量的生存期都是“永久”，区别只是可见域不同。extern全局变量可见区域是工程，static全局变量可见区域是文件，而static局部变量的可见区域是块。 volatile 阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回。 阻止编译器调整操作volatile变量的指令顺序。 注意：即使 volatile 能够阻止编译器调整顺序， 也无法阻止CPU动态调度换序（reorder） assert 断言主要用于检查逻辑上不可能的情况。例如，它们可用于检查代码在开始运行之前所期望的状态，或者在运行完成后检查状态。与正常的错误处理不同，断言通常在运行时被禁用。 assert 是个宏而非函数，如果条件返回错误，则会抛出异常，最后会调用 abort 终止程序，发送的是 SIGABRT，可以通过宏 NODEBUG 来关闭 assert，但是需要设置在源代码的开头。 1234567891011121314#define assert(expr) \\ (static_cast &lt;bool&gt; (expr) \\ ? void (0) \\ : __assert_fail (#expr, __FILE__, __LINE__, __ASSERT_FUNCTION))extern void __assert_fail (const char *__assertion, const char *__file, unsigned int __line, const char *__function)&#123; __THROW __attribute__ ((__noreturn__));&#125; 在判断失败时会调用 __assert_fail 来抛出异常，在C++中异常的底层是用 abort 实现的。 指针和引用的区别 目的不同：指针是为了兼容 C 而存在，引用是为了操作符重载而存在 在声明引用的的同时就要对它初始化，并且一经声明就不可以再和其它对象绑定在一起了。 引用更像是常量指针，只能改变绑定对象的值，不能改变绑定的对象。 引用它一定不为空，因此相对于指针，它不用检查它所指对象是否为空，更加安全也增加了效率new、malloc new：不仅仅是分配内存，还包括了对象类型转换以及初始化 是先调用operator new分配内存空间，返回是void *类型； 再将返回类型转换为指定类型，再调用类的构造函数。 如果内存空间不足，会抛出std::bad_alloc异常 malloc 返回 void*类型，并且在内存不足时，返回NULL指针 当开辟的空间小于 128K时，调用brk() 函数，malloc的底层实现是系统调用函数 brk() 当开辟的空间大于 128K时，mmap() 系统调用函数来在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟 operator new 底层也是由malloc实现。 malloc底层是由slab实现。 对于POD类型对象，使用new 创建的对象，也是可以使用free来释放销毁对象，原因就是在于这个对象是POD 类型。没有其他资源需要释放，或者文件描述符需要关闭，因此可以不调用析构函数而使用free来替代delete。尽管可以，但是不推荐，这样的代码并不健壮。 new 在C++里是可以用 malloc + placement 替代的，或者说等效于这两个。 1234567891011121314151617181920212223// 更好的展示 malloc 与 new 的区别与联系class Foo &#123; public: Foo(int a=0, int b=0): a(a),b(b) &#123; &#125; ~Foo() &#123; std::cout&lt;&lt;&quot;dtor&quot;&lt;&lt;std::endl; &#125;private: int a; int b;&#125;;int main(int argc, char const *argv[])&#123; // new = placement new + malloc Foo* foo = static_cast&lt;Foo*&gt;(::malloc(sizeof(Foo))); new(foo)Foo(1,1); // delete foo-&gt;~Foo(); ::free(foo); return 0;&#125;// 运行结束，无内存泄露 除了new和malloc，还有什么方式可以在堆中分配内存么，以及怎么释放？ mmap，munmap 多态多态的三个条件：继承，重写（override），基类引用指向派生类对象。 静态多态 重载，在编译时期就可以确定 模板技术：比如 CRTP，它是使用子类来作为基类的模板参数，在基类中调用子类的方法。 12345678template&lt;typename Derived&gt;class Base&#123; // 其他忽略 Derived&amp; convert() &#123; return static_cast&lt;Derived&amp;&gt;(*this); &#125;&#125;; 这个也从侧面说明static_cast 可以让子类转换为父类，要使得保证安全，前提是转换后调用子类的方法中没有使用子类独有的数据成员 动态多态运行时才确定调用的是哪个函数。核心关键在于虚函数：子类重写基类的虚方法，定义指向子类对象的基类指针。这个基类指针的行为直到运行时才能确定调用的是子类还是基类的方法，这就是多态。 实现原理是：虚函数表和虚函数指针vptr。详情 重载(overload)和重写(override) 重载：允许多个同名函数，而这些函数的参数列表不同，函数模板这么实现的，在编译期间就能确定。 C++函数重载底层实现原理是C++利用 name mangling 技术，来改变函数名，区分参数不同的同名函数。编译器通过函数名和其参数类型识别重载函数。不能仅仅基于不同的返回类型而实现函数重载，是因为经过 name mangling 后得到的函数名与返回值类型是无关的。 12345678void func(int a) &#123; &#125;int func(int a, int b) &#123; return a+b; &#125;int main(int argc, char const *argv[])&#123; return 0;&#125; 比如，如上的代码。在经过编译后，得到的符号表如下： 1234$ objdump -t main.o0000000000000000 g F .text 000000000000000e _Z4funci000000000000000e g F .text 0000000000000018 _Z4funcii0000000000000026 g F .text 0000000000000016 main 其中， 前缀 __z 是规定，4 是函数名的字符个数，i是第一个函数的参数类型int，ii是第二个函数的参数类型int, int。由此可见也是与返回值无关的。 重写override：是指子类重新定义父类的方法，子类的函数名和参数列表以及返回值必须与父类的完全一致。对于虚函数的重写，c++11中新定义了一个关键词override，就是为了让子类在重写父类的虚函数方法时，如何参数列表发生更改可以让编译器报错。 staticstatic变量都是在全局数据区分配内存,声明周期直到程序运行结束. 四类static 全局static变量和static函数：都已经被匿名命名空间取代，作用是不能外部文件使用 局部static变量：在数据区.data分配内存，首次初始化以后，以后调用都不会再初始化，作用域仅局限于函数，生命周期直到程序运行结束 静态数据成员:类对象共享，不能在类声明中定义，是因为在定义时就要分配空间，也是在.data 静态成员函数:静态成员函数，不隐含this指针，不能调用非静态成员函数/变量，可以用作回调函数 为什么要引入static 需要一个数据对象为整个类而非某个对象服务，同时又不能破坏类的封装特性，因此将静态成员隐藏在类的内部,提供静态成员函数接口，因为共享,可以节省内存。 对象 空类有六个成员函数12345678910class Empty &#123; public: Empty(); Empty(const Empty&amp; ); ~Empty(); Empty&amp; operator=(consy Empty&amp; ); Empty* operator&amp; (); // 取地址运算符 const Empty* operator&amp; () const; // const 类型取地址运算符&#125;; 构造函数可以是虚函数吗？析构函数可以是虚函数吗？ 虚函数对应一个vtbl，这个vtbl实际是存储在对象的内存空间.如果构造函数是虚的,对象的构造就需要vtbl来调用，而虚函数表又是在对象构造后才能建立,因此构造函数不能是虚函数. 而析构函数在使用多态的继承中一般都是虚析构函数.为的是能正确选择析构函数. c++的深拷贝如何理解 在类中有指针时并且内部分配资源.经过浅拷贝后,最终会造成资源一次分配,多次释放.造成系统崩溃. C++中如何在main()函数之前执行操作main函数执行之前，主要就是初始化系统相关资源： 设置栈指针 初始化静态static变量和global全局变量，即.data段的内容 将未初始化部分的全局变量赋初值：数值型short，int，long等为0，bool为FALSE，指针为NULL等等，即.bss段的内容 全局对象初始化，在main之前调用构造函数 将main函数的参数argc，argv等传递给main函数，然后才真正运行main函数 main函数执行之后： 全局对象的析构函数会在main函数之后执行； 可以用 atexit 注册一个函数，它会在main 之后执行; sizeof 和 strlen 区别12345678int main(int argc, char const *argv[])&#123; const char* str = &quot;name&quot;; sizeof(str); // 取的是指针str的长度，是8 strlen(str); // 取的是这个字符串的长度，不包含结尾的 \\0。大小是4 return 0;&#125; strcpy、strncpy和mmemcpy的区别123char* strcpy(char* dest, const char* src);char* strncpy(char* dest, const char* src, size_t n);void* memcpy (void* dest, const void* src, size_t n); 前面两个函数是以字符为单位，而mmemcpy是以字节为单位。 strcpy和memcpy主要有以下3方面的区别。 复制的内容不同。strcpy 只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等。 复制的方法不同。strcpy 不需要指定长度，它遇到被复制字符的串结束符&#39;\\0&#39;才结束，所以容易溢出。memcpy 则是根据其第3个参数决定复制的长度，而且如果字符串数据中包含&#39;\\0&#39;，只能用memcpy。 用途不同。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy strncpy ：在复制字符串时，memcpy更加类似于strncpy。strncpy和memcpy很相似，只不过它在一个终止的空字符处停止。当 n &gt; strlen(src) 时，dst[strlen(len)] ~ dst[n-1]都是\\0；当 n&lt;=strlen(src)时，复制前src的n个字符。这里隐藏了一个事实，就是dst指向的内存一定会被写n个字符。 memcpy需要注意的是： dest 指针要分配足够的空间，也即大于等于 n 字节的空间。如果没有分配空间，会出现断错误。 dest 和 src 所指的内存空间不能重叠（如果发生了重叠，使用 memmove() 会更加安全）。 动手实现 memcpy： 12345678910111213141516171819202122232425262728void* myMemcpy(void* dst, const void* src, size_t n) &#123; if(dst ==nullptr || src==nullptr) return nullptr; if(src == dst) retrun src; char* pdst = static_cast&lt;char*&gt;(dst); const char* psrc = static_cast&lt;const char*&gt;(src); // 发生重叠时，从后向前复制 if(psrc &lt; pdst &amp;&amp; pdst &lt; psrc + n) &#123; for(int i=n-1; i &gt;=0; --i) pdst[i] = psrc[i]; &#125; else &#123; for(int i=0; i &lt; n; ++i) pdst[i] = psrc[i]; &#125; return pdst;&#125;// 使用int main(int argc, char const *argv[])&#123; char buf[12]=&#123;0&#125;; char str[] = &quot;hello world cpp&quot;; myMemcpy(str, str+6, 9); std::cout&lt;&lt;str&lt;&lt;std::endl; return 0;&#125; 野指针和悬空指针都是是指向无效内存区域(这里的无效指的是”不安全不可控”)的指针，访问行为将会导致未定义行为。 野指针野指针，指的是没有被初始化过的指针 1234567int main(void) &#123; int* p; // 未初始化 std::cout&lt;&lt; *p &lt;&lt; std::endl; // 未初始化就被使用 return 0;&#125; 因此，为了防止出错，对于指针初始化时都是赋值为 nullptr，这样在使用时编译器就会直接报错，产生非法内存访问。 悬空指针悬空指针，指针最初指向的内存已经被释放了的一种指针。 123456789int main(void) &#123; int * p = nullptr; int* p2 = new int; p = p2; delete p2;&#125; 此时 p和p2就是悬空指针，指向的内存已经被释放。继续使用这两个指针，行为不可预料。需要设置为p=p2=nullptr。此时再使用，编译器会直接保错。 避免野指针比较简单，但悬空指针比较麻烦。c++引入了智能指针，C++智能指针的本质就是避免悬空指针的产生。 malloc、calloc、realloc123456#include &lt;stdlib.h&gt;void *malloc(size_t size);void *calloc(size_t nmemb, size_t size);void *realloc(void *ptr, size_t size);void free(void *ptr); malloc最常用的分配内存函数，分配size个字节。分配的内存是未初始化的，如果size==0，要么返回NULL，要么返回一个独一无二的指针，能被free释放。 realloc：用来改变已有内存区的大小，而不改变内容。新的大小为参数size，即newsize。 ptr==NULL：realloc(NULL,size)就相当于malloc(size) size==0：realloc(ptr, 0)就相当于free(ptr) ptr==NULL &amp;&amp; size==0：危险。 如果newsize &gt; oldsize，那么增加的内存是未初始化的，原来的内存内容保持不变，即[ptr, ptr+oldsize)内部不变，[ptr+oldsize, ptr+newsize)是初始化的内容。 如果newsize &lt; oldsize，尾部的内容就被切去，释放，只是剩下前面。 因此 realloc之后不能给这个内存区初始化. calloc分配nmemb个元素，每个元素大小是size个字节的连续内存。 内存大小是nmemb*size的连续内存区 这块内存被初始化为0。 如果size==0，要么返回NULL，要么返回一个独一无二的指针，能被free释放。 编译知识为了减小编译依赖加快编译速度和生成二进制文件的大小，C/C++ 项目中一般在 .h 文件对于*指针类型（包括智能指针） 尽量使用前置声明，而不是直接包含对应类的头文件。例如： 12345678910111213//Test.h//在这里使用A的前置声明，而不是直接包含A.h文件class A;class Test&#123;public: Test(); ~Test();private: A*&#125;; Copy Elision g++ 编译器是默认开启 copy elison 选项的。如果要关闭这个选项，使用 -fno-elide-constructors。copy elision 主要包括以下两项内容： 1. 返回值优化 即通过将返回对象所占空间的直接构造到他们本来要复制/移动到的对象中去，依次来避免拷贝/移动操作。返回值优化包括具名返回值优化 NRVO 与 匿名返回值优化 URVO，区别在于返回值是具名的局部变量（NRVO）还是无名的临时对象（URVO） URVO 与 彻底 Copy elision 1234567891011121314151617181920class Copyable &#123; public: Copyable() &#123; std::cout&lt;&lt;&quot;default ctor&quot;&lt;&lt;std::endl; &#125; Copyable(const Copyable&amp; rhs) = delete; Copyable(Copyable&amp;&amp; rhs) = delete;&#125;;Copyable return_urvo_value() &#123; return Copyable&#123;&#125;; // since c++17 ok&#125;int main(int argc, char const *argv[]) &#123; auto x = return_urvo_value(); return 0;&#125; 上述代码在C++17中是可以编译通过的。在 C++17 之前，并没有明确的提出在什么情况下，可以彻底进行 Copy Elision（这里的彻底的指的是包括不进行检查是否有可用的 copy/move 构造函数）。在C++17中，对于匿名对象（or 临时对象）不论是传递参数，还是以返回值返回时，都不会调用拷贝/移动构造。因此上面的这段代码在C++17是可以正常编过的，而在C++14会编译出错。 123456789101112131415$ g++ main.cc -std=c++14 -o main &amp;&amp; ./mainmain.cc: In function ‘Copyable return_urvo_value()’:main.cc:29:19: error: use of deleted function ‘Copyable::Copyable(Copyable&amp;&amp;)’ 29 | return Copyable&#123;&#125;; | ^main.cc:24:3: note: declared here 24 | Copyable(Copyable&amp;&amp; rhs) = delete; | ^~~~~~~~main.cc: In function ‘int main(int, const char**)’:main.cc:34:31: error: use of deleted function ‘Copyable::Copyable(Copyable&amp;&amp;)’ 34 | auto x = return_urvo_value(); | ^main.cc:24:3: note: declared here 24 | Copyable(Copyable&amp;&amp; rhs) = delete; | ^~~~~~~~ 自然，只要将上面代码中的如下两行注释掉，即可正常编译，并且 Copyable的构造函数都是只被调用一次，即copy elision 起作用了。 注意：Copyable的复制/移动构造函数必须同时可访问。 12Copyable(const Copyable&amp; rhs) = delete; Copyable(Copyable&amp;&amp; rhs) = delete; 因此，在C++17以前，对于 urvo 不在乎是否返回的对象的复制/移动构造函数是否存在或者可访问，copy elision 都能生效。而在 C++14 之前，返回的对象可以没有复制/移动构造函数，但是必须可以访问。 nrvo在 nrvo时，返回对象的复制/移动构造函数必须可访问。否则编译不过。 1234567891011121314151617181920212223242526class Copyable &#123; public: Copyable() &#123; std::cout&lt;&lt;&quot;default ctor&quot;&lt;&lt;std::endl; &#125; Copyable(const Copyable&amp; rhs) = delete; Copyable(Copyable&amp;&amp; rhs) = delete;&#125;;Copyable return_urvo_value() &#123; return Copyable&#123;&#125;;&#125;Copyable return_nrvo_value() &#123; Copyable local; return local;&#125;int main(int argc, char const *argv[]) &#123; auto x = return_urvo_value(); auto y = return_nrvo_value(); return 0;&#125; 如上代码，即使是C++17也会编译失败，必须将如下两行代码注释掉，使得 Copyable 对象的复制/移动构造函数可访问。copy elision 才能生效：Copyable 的默认构造函数只调用一次。 12// Copyable(const Copyable&amp; rhs) = delete;// Copyable(Copyable&amp;&amp; rhs) = delete; 2. 右值拷贝优化 右值拷贝优化，当某一个类的临时对象以值传递给该类的另一个对象时，也可以直接利用该临时对象的来避免拷贝/移动操作。在上面的基础上，加上如下的代码：12345678910111213void pass_by_value(Copyable rhs) &#123; &#125;int main(int argc, char const *argv[]) &#123; auto x = return_urvo_value(); auto y = return_nrvo_value(); pass_by_value(Copyable()); return 0;&#125;最终的输出也是调用默认三次构造函数：1234$ g++ main.cc -std=c++11 -o main &amp;&amp; ./maindefault ctordefault ctordefault ctor 到此，copy elision 基本分析结束。如果想查看没有copy elision 作用下的输出，开启-fno-elide-constructors。 Copy Elision 作用对于一些没有拷贝/移动构造的对象，如 unique_ptr、 atomic 等。现在我们能够定义一个工厂函数，即使没有复制或移动构造函数都可以返回一个对象。例如，以下通用工厂函数:12345678910111213141516template &lt;typename T, typename... Args&gt;T make_instance(Args&amp;&amp; ... args)&#123; return T&#123; std::forward&lt;Args&gt;(args)... &#125;;&#125;int main()&#123; int i = make_instance&lt;int&gt;(42); // std::unique_ptr 实现了 移动构造函数，因此可以编译成功 auto up = make_instance&lt;std::unique_ptr&lt;int&gt;&gt;(new int&#123; 42 &#125;); // 禁止了复制构造函数，但是也没有实现移动构造函数，因此要到 C++17 才能编译过 auto ai = make_instance&lt;std::atomic&lt;int&gt;&gt;(42); return 0;&#125;参考 STLstd::vector std::vector 在 push_back 以成倍增长可以在均摊后达到O(1)的事件复杂度，相对于增长指定大小的O(n)时间复杂度更好。 为了防止申请内存的浪费，现在使用较多的有2倍与1.5倍的增长方式，而1.5倍的增长方式可以更好的实现对内存的重复利用，因为更好 std::vector/std::list的实现原理及其使用场景std::vector是用连续内存的数组实现的，std::list是通过指针之间的指向实现不连续内存的高效率使用. std::vector 与 std::list 数组，最大的好处是能以 O(1) 用索引访问任意元素，次要好处是内存布局紧凑，省内存之余还有高缓存一致性（cache coherence）。但数组的缺点是不能快速插入元素，而且我们在解析 JSON 数组的时候，还不知道应该分配多大的数组才合适。 链表，它的最大优点是可快速地插入元素（开端、末端或中间），但需要以 O(n) 时间去经索引取得内容。如果我们只需顺序遍历，那么是没有问题的。还有一个小缺点，就是相对数组而言，链表在存储每个元素时有额外内存开销（存储下一节点的指针），而且遍历时元素所在的内存可能不连续，令缓存不命中（cache miss）的机会上升。 std::bind对于如下代码，使用 std::bind 绑定类的成员函数并调用。 1234567891011121314151617class Foo &#123; public: Foo()=default; void add(const int&amp; lhs, const int&amp; rhs) &#123; std::cout&lt;&lt; (lhs + rhs)&lt;&lt;std::endl;; &#125;&#125;;int main(int argc, char const *argv[])&#123; Foo foo1; // 绑定并且执行 std::bind(&amp;Foo::add, &amp;foo1, 1, 2)(); return 0;&#125; 最后内部执行的代码如下： 123456template&lt;typename _Res, typename _MemFun, typename _Tp, typename... _Args&gt;constexpr _Res__invoke_impl(__invoke_memfun_deref, _MemFun&amp;&amp; __f, _Tp&amp;&amp; __t, _Args&amp;&amp;... __args)&#123; return ((*std::forward&lt;_Tp&gt;(__t)).*__f)(std::forward&lt;_Args&gt;(__args)...);&#125; 其中 _t ，类型是 Foo*&amp; 函数对象指针，指向的foo1对象。 _f是函数指针，指向的就是add成员函数 __invoke_memfun_deref：是用来标记是哪种把绑定方式，比如上述代码中的绑定对象成员函数 因此，最终，调用可以简化为如下： 1foo1.add(1,2); 整个std::bind 最终的执行代码如下： 123456789101112131415161718192021222324252627282930// 直接传入函数调用: std::bind(func, arg1, arg2); 或者静态成员函数// 很明显，这里没有类对象template&lt;typename _Res, typename _Fn, typename... _Args&gt;constexpr _Res__invoke_impl(__invoke_other, _Fn&amp;&amp; __f, _Args&amp;&amp;... __args)&#123; return std::forward&lt;_Fn&gt;(__f)(std::forward&lt;_Args&gt;(__args)...); &#125;// 上面介绍过template&lt;typename _Res, typename _MemFun, typename _Tp, typename... _Args&gt;constexpr _Res__invoke_impl(__invoke_memfun_deref, _MemFun&amp;&amp; __f, _Tp&amp;&amp; __t, _Args&amp;&amp;... __args)&#123; return ((*std::forward&lt;_Tp&gt;(__t)).*__f)(std::forward&lt;_Args&gt;(__args)...);&#125;// 下面几种没见过调用template&lt;typename _Res, typename _MemFun, typename _Tp, typename... _Args&gt;constexpr _Res__invoke_impl(__invoke_memfun_ref, _MemFun&amp;&amp; __f, _Tp&amp;&amp; __t, _Args&amp;&amp;... __args)&#123; return (__invfwd&lt;_Tp&gt;(__t).*__f)(std::forward&lt;_Args&gt;(__args)...); &#125;template&lt;typename _Res, typename _MemPtr, typename _Tp&gt;constexpr _Res__invoke_impl(__invoke_memobj_ref, _MemPtr&amp;&amp; __f, _Tp&amp;&amp; __t)&#123; return __invfwd&lt;_Tp&gt;(__t).*__f; &#125;template&lt;typename _Res, typename _MemPtr, typename _Tp&gt;constexpr _Res__invoke_impl(__invoke_memobj_deref, _MemPtr&amp;&amp; __f, _Tp&amp;&amp; __t)&#123; return (*std::forward&lt;_Tp&gt;(__t)).*__f; &#125; Lambda lambda可以理解为是仿函数的语法糖。 1234567int main(int argc, char const *argv[])&#123; auto add = [](int a, int b) &#123; return a+b; &#125;; int c = add(1,2); return 0;&#125; 对于上面的lambda函数，在gdb调试，经过编译的到的函数类型： 123(gdb) s&lt;lambda(int, int)&gt;::operator()(int, int) const (__closure=0x7fffffffe6d3, a=1, b=2) at main.cpp:2424 auto add = [](int a, int b) &#123; return a+b; &#125;; lambda可以看作是匿名的函数对象，并且 lambda表达式默认是 const属性。 1234567891011121314class Foo &#123; public: Foo() &#123; []()&#123;std::cout&lt;&lt;&quot;123&quot;&lt;&lt;std::endl; &#125;(); &#125;&#125;;int main(int argc, char const *argv[])&#123; Foo foo; return 0;&#125; 在类中调用lambda表达式，编译出来的类型如下： 1Foo::Foo()::&#123;lambda()#1&#125;::operator()() const 而实际上，lambda与operator本质上也是一样的，如下代码：1234567891011121314151617181920212223242526class Foo &#123; public: Foo() &#123; // 以下两个设计等价 [this](const char* str)&#123;this-&gt;print(str); &#125;(&quot;lambda&quot;); Unmaed(this)(&quot;operator&quot;); &#125; void print(const char* str) &#123; std::cout&lt;&lt;str&lt;&lt;std::endl; &#125; private: struct Unmaed &#123; Unmaed(Foo* foo): foo_(foo) &#123; &#125; void operator()(const char* str) const &#123; foo_-&gt;print(str); &#125; Foo* foo_; &#125;; &#125;; std::bind 与 lambad区别 lambda 可以重载，但是 std::bind 无法区别重载 123456 void f(int) &#123;&#125;void f(double) &#123;&#125; auto g = [] &#123; f(1); &#125;; // OK auto g = std::bind(f, 1); // 错误 auto g = std::bind(static_cast&lt;void(*)(int)&gt;(f), 1); // OK 为此必须指定对应的函数指针类型。lambda 闭包类的 operator() 采用的是能被编译器内联的常规的函数调用。而std::bind采用的是一般不会被内联的函数指针调用，这意味着 lambda 比 std::bind 运行得更快。 传给 std::bind 的参数，绑定的是 std::bind，而不是std::bind内部管理的函数123456789101112131415161718void f(std::chrono::steady_clock::time_point t, int i)&#123; std::this_thread::sleep_until(t); std::cout &lt;&lt; i;&#125;auto g = [](int i)&#123; f(std::chrono::steady_clock::now() + std::chrono::seconds(3), i);&#125;;g(1); // 3秒后打印1// 用std::bind实现相同效果，但存在问题auto h = std::bind(f, std::chrono::steady_clock::now() + std::chrono::seconds(3), std::placeholders::_1);h(1); // 3秒后打印1，但3秒指的是调用std::bind后的3秒，而非调用f后的3秒 计算时间的表达式作为实参被传递给std::bind，因此计算发生在调用std::bind的时刻，而非调用其绑定的函数的时刻。 在 c++14 中，完全没有理由使用 std::bind，c++11由于特性受限，存在两个使用场景： 模拟c++11缺少的移动捕获 函数对象 operator() 是模板时，如果将此函数作为参数使用，用 std::bind 绑定才能接受任意类型参数1234567891011 struct X &#123; template&lt;typename T&gt; void operator()(const T&amp;) const; &#125;; X x; auto f = std::bind(x, _1); // f可以接受任意参数类型 // c++14 做法 X a; auto f = [a](const auto&amp; x) &#123; a(x); &#125;; Lambda 与 std::bind 区别补充std::bind 传入的参数默认情况下是 “值传递”，想要使用引用传递需要std::ref。详细可以参考下面的代码： 123456789101112131415161718192021222324252627282930313233343536class Foo &#123; public: Foo() &#123; std::cout&lt;&lt;&quot;default&quot;&lt;&lt;std::endl; &#125; Foo(const Foo&amp; rhs) &#123; std::cout&lt;&lt;&quot;ctor&quot;&lt;&lt;std::endl; &#125;&#125;;void add(const Foo&amp; lhs, const Foo&amp; rhs) &#123; &#125;int main(int argc, char const *argv[])&#123; std::cout&lt;&lt;std::boolalpha; Foo foo1; Foo foo2; std::cout&lt;&lt;&quot;bind: pass by value&quot;&lt;&lt;std::endl; auto func = std::bind(add, foo1, foo2); std::cout&lt;&lt;&quot;bind: pass by ref&quot;&lt;&lt;std::endl; auto func = std::bind(add, std::ref(foo1), std::ref(foo2)); std::cout&lt;&lt;&quot;lambda &quot;&lt;&lt;std::endl; [&amp;foo1, &amp;foo2]&#123; add(foo1, foo2);&#125;(); return 0;&#125; 上面的代码输出：12345678$ g++ -g -O0 main.cc -o main &amp;&amp; ./maindefaultdefaultbind: pass by valuectorctorbind: pass by reflambda 可以看到std::bind在默认情况下，是依靠值传递，使用了std::ref来包裹传入参数才是使用引用传递。用 gdb 调试，可以跟踪到发生构造 Foo 对象的位置：123456789101112131415template&lt;typename _UHead&gt;constexpr _Head_base(_UHead&amp;&amp; __h) : _Head(std::forward&lt;_UHead&gt;(__h)) &#123; &#125;// 整个调用链如下：#0 Foo::Foo (this=0x7fffffffe068, rhs=...) at main.cc:13#1 0x0000555555555a8c in std::_Head_base&lt;1ul, Foo, true&gt;::_Head_base&lt;Foo&amp;&gt; (this=0x7fffffffe068, __h=...) at /usr/include/c++/9/tuple:87#2 0x00005555555559e8 in std::_Tuple_impl&lt;1ul, Foo&gt;::_Tuple_impl&lt;Foo&amp;&gt; (this=0x7fffffffe068, __head=...) at /usr/include/c++/9/tuple:349#3 0x00005555555558f3 in std::_Tuple_impl&lt;0ul, Foo, Foo&gt;::_Tuple_impl&lt;Foo&amp;, Foo&amp;, void&gt; (this=0x7fffffffe068, __head=...) at /usr/include/c++/9/tuple:218#4 0x0000555555555815 in std::tuple&lt;Foo, Foo&gt;::tuple&lt;Foo&amp;, Foo&amp;, true&gt; (this=0x7fffffffe068, __a1=..., __a2=...) at /usr/include/c++/9/tuple:969#5 0x00005555555556fc in std::_Bind&lt;void (*(Foo, Foo))(Foo const&amp;, Foo const&amp;)&gt;::_Bind&lt;Foo&amp;, Foo&amp;&gt;(void (*&amp;&amp;)(Foo const&amp;, Foo const&amp;), Foo&amp;, Foo&amp;) (this=0x7fffffffe060, __f=@0x7fffffffe010: 0x5555555551ea &lt;add(Foo const&amp;, Foo const&amp;)&gt;) at /usr/include/c++/9/functional:467#6 0x0000555555555571 in std::bind&lt;void (&amp;)(Foo const&amp;, Foo const&amp;), Foo&amp;, Foo&amp;&gt; (__f= @0x5555555551ea: &#123;void (const Foo &amp;, const Foo &amp;)&#125; 0x5555555551ea &lt;add(Foo const&amp;, Foo const&amp;)&gt;) at /usr/include/c++/9/functional:812#7 0x00005555555552b7 in main (argc=1, argv=0x7fffffffe198) at main.cc:30 左值引用和右值引用区别 左值引用，也就是“常规引用”，不能绑定到要转换的表达式，字面常量，或返回右值的表达式。而右值引用恰好相反，可以绑定到这类表达式，但不能绑定到一个左值上。 右值引用就是必须绑定到右值的引用，通过&amp;&amp;获得。右值引用只能绑定到一个将要销毁的对象上，因此可以自由地移动其资源。 返回左值的表达式包括返回左值引用的函数及赋值，下标，解引用和前置递增/递减运算符； 返回右值的包括返回非引用类型的函数及算术，关系，位和后置递增/递减运算符。可以看到左值的特点是有持久的状态，而右值则是短暂的 12345678void func(int&amp;&amp; index, int idx) &#123; if(idx &gt; 3) return; func(index++, ++idx); // Ok func(++index, ++idx); // Error std::cout&lt;&lt; std::is_rvalue_reference&lt;decltype(index)&gt;::value &lt;&lt;std::endl;&#125; 在上面的代码中，++index 产生的是左值，而 index++ 产生的是右值。因此上面的可以编译成功，下面的编译不过。 【注意】：已经命名的右值，编译器会认为是左值。 左值与右值变量都是左值，即使变量是右值引用类型12int&amp;&amp; ref1 = 1; // ok int&amp;&amp; ref2 = ref1; // error 因为 ref2 是右值引用类型的变量，不能将其绑定到左值ref1上。ref1 与 ref2 是左值，因为他们都是变量，但是变量类型是右值引用类型，即这两个变量只能绑定到右值上。 四种类型转换总结static_cast 基类和子类之间转换： static_cast 的使用，当且仅当类型之间可隐式转化时，static_cast 的转化才是合法的。有一个例外，那就是类层次间的向下转型，static_cast 可以完成类层次间的向下转型，但是向下转型无法通过隐式转换完成。 向上转换安全：子类指针转换成父类指针是安全的; 向下转换不安全：父类指针转换成子类指针是不安全的。 static_cast不能进行无关类型(如非基类和子类)指针之间的转换。 12345class Base&#123; &#125;;class Derived : public base&#123; /**....*/ &#125;; Base* B = new Base; Derived* D = static_cast&lt;Drived*&gt;(B); // 不安全 为什么不安全？ D指向本质上还是B的对象模型，D指向的内存模型中可能存在B没有的成员变量。如果 D-&gt;foo() 中使用了 D 的成员变量，那么这个函数调用就是不安全的。因此，向下转换是安全的。 static_cast 还可以在左值和右值之间显示地转换。虽然不能隐式地将左值转换为右值，但是可以使用static_cast显示地将左值转换为右值。 基本数据类型转换: enum, int, char, float等。安全性问题由开发者来保证。 把空指针转换成目标类型的空指针 1int* iptr = static_cast&lt;int*&gt;(::malloc(sizoef(int))); 把任何类型的表达式转换成void类型：static_cast&lt;void&gt;(iptr) static_cast 不能去掉类型的const、volitale属性(用const_cast) 隐式转换都建议使用 static_cast 进行标明和替换 dynamic_cast专门用于将多态基类的指针或引用强制转换为派生类的指针或引用，而且能够检查转换的安全性。对于不安全的指针转换，转换结果返回 nullptr 指针。 使用特点： 基类必须要有虚函数，因为dynamic_cast是运行时类型检查，需要运行时类型信息，而这个信息是存储在类的虚函数表中，只有一个类定义了虚函数，才会有虚函数表 对于下行转换，dynamic_cast是安全的（当类型不一致时，转换过来的是空指针），而static_cast是不安全的（当类型不一致时，转换过来的是错误意义的指针，可能造成踩内存，非法访问等各种问题), reinterpreter_cast 下行转换是可以转换，但是不安全。 相同基类不同子类之间的交叉转换，转换结果是是 nullptr 1234567891011121314class Base&#123;public: virtual void fun() &#123; &#125; &#125;;class Drived : public base &#123;public: int i;&#125;;Base *Bptr = new Drived()；//语句0Derived *Dptr1 = static_cast&lt;Derived*&gt;(Bptr); //语句1；Derived *Dptr2 = dynamic_cast&lt;Derived*&gt;(Bptr); //语句2； 此时语句1和语句2都是安全的，因为此时 Bptr 确实是指向的派生类的内存模型，所以两个类型转换都是安全的。Dptr1 和 Dptr2 可以尽情访问 Drived 类中的成员，绝对不会出问题。但是如果此时语句0更改为如下表达： 1Base* Bptr = new Base(); ` 那么 Bptr 指向的是Base对象内存模型。因此语句1是不安全的，因为如果访问子类的数据成员，其行为将是未定义。而语句2返回的是 nullptr，更加直观的告诉用户不安全。 reinterpreter_cast用于进行各种不同类型的指针之间、不同类型的引用之间以及指针和能容纳指针的整数类型之间的转换。转换时执行的是逐 byte 复制的操作。 reinterpret_cast是从底层对数据仅仅进行重新解释，但没有进行二进制的转换，依赖具体的平台，可移植性差； reinterpret_cast可以将整型转换为指针，也可以把指针转换为数组； reinterpret_cast可以在指针和引用里进行肆无忌惮的转换； const_cast 常量指针转换为非常量指针， 并且仍然指向原来的对象 常量引用被转换为非常量引用，并且仍然指向原来的对象 自己实现一个非侵入式的智能指针123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153// RAII 技术封装 class RefCount &#123;public: RefCount() : reference_&#123;0&#125; &#123; &#125; ~RefCount() &#123; this-&gt;decrementRef(); &#125; void IncrementRef() &#123; ++reference_; &#125; bool decrementRef() &#123; if (--reference_ == 0) &#123; delete this; return true; &#125; return false; &#125; int64_t use_count() &#123; return reference_; &#125; private: std::atomic&lt;int64_t&gt; reference_; &#125;; template &lt;typename T&gt; class SharedPtr &#123; public: SharedPtr() : ptr_(nullptr) &#123;&#125; explicit SharedPtr(T* ptr) : ptr_(ptr), ref_(new RefCount) &#123; if (ref_) ref_-&gt;IncrementRef(); &#125; SharedPtr(const SharedPtr&amp; other) : ptr_(other.ptr_), ref_(other.ref_) &#123; if (ref_) ref_-&gt;IncrementRef(); &#125; SharedPtr(SharedPtr&amp;&amp; other) noexcept &#123; ptr_ = other.ptr_; ref_ = other.ref_; other.ptr_ = nullptr; other.ref_ = nullptr; &#125; SharedPtr&amp; operator=(const SharedPtr&amp; other) &#123; if (this == &amp;other || *this == other) return *this; reset(); ptr_ = other.ptr_; ref_ = other.ref_; ref_-&gt;IncrementRef(); return *this; &#125; SharedPtr&amp; operator=(SharedPtr&amp;&amp; other) noexcept &#123; if (this == &amp;other || *this == other) return *this; reset(); ptr_ = other.ptr_; ref_ = other.ref_; other.ptr_ = nullptr; other.ref_ = nullptr; return *this; &#125; ~SharedPtr() &#123; if (ref_) this-&gt;decrementRef(); &#125; T&amp; operator*() const &#123; return *ptr_; &#125; T* operator-&gt;() const &#123; return ptr_; &#125; explicit operator bool() const &#123; return !!ptr_; &#125; T* get() const &#123; return ptr_; &#125; void reset() &#123; if (ptr_) &#123; this-&gt;decrementRef(); // ptr_ = nullptr; &#125; &#125; void decrementRef() &#123; if(ref_ &amp;&amp; ptr_) &#123; if(ref_-&gt;decrementRef()) &#123; delete ptr_; ptr_ = nullptr; &#125; &#125; &#125; int64_t use_count() &#123; return ref_-&gt;use_count(); &#125; bool unique() &#123; return use_count() == 1; &#125; void swap(SharedPtr &amp; other) &#123; std::swap(ptr_, other.ptr_); std::swap(ref_, other.ref_); &#125; friend inline bool operator==(SharedPtr const&amp; lhs, SharedPtr const&amp; rhs) &#123; return lhs.ptr_ == rhs.ptr_; &#125; friend inline bool operator!=(SharedPtr const&amp; lhs, SharedPtr const&amp; rhs) &#123; return lhs.ptr_ != rhs.ptr_; &#125; friend inline bool operator&lt;(SharedPtr const&amp; lhs, SharedPtr const&amp; rhs) &#123; return lhs.ptr_ &lt; rhs.ptr_; &#125; private: T* ptr_; RefCount* ref_; &#125;; int main(int argc, char const *argv[]) &#123; SharedPtr&lt;int&gt; iptr (new int); SharedPtr&lt;int&gt; iptr2(iptr); SharedPtr&lt;int&gt; iptr3(std::move(iptr)); SharedPtr&lt;int&gt; iptr4 = iptr2; SharedPtr&lt;int&gt; iptr5 = std::move(iptr3); std::cout&lt;&lt;iptr5.use_count()&lt;&lt;std::endl; // 3 return 0; &#125; 迭代器失效的场景 序列式容器 序列式容器会失效的原因是因为其存储都是连续的，因此删除或者插入一个元素都有可能导致其他元素的迭代器失效。 vector 在遍历时，执行erase会导致删除节点之后的全部失效 在push_back时，之前的end()操作得到的迭代器失效 insert/push_back导致capacity()改变，那么之前的first()/end()得到的迭代器会失效 insert一个元素，如果空间没有分配，那么插入节点之前的迭代器位置有效，之后的失效。 简而言之：导致内存分配的全会失效，导致元素移动的会局部失效 deque 在首尾添加元素，会导致迭代器失效，但是指针、引用不会失效 其余位置插入元素，迭代器、指针、引用都是失效 在首尾之外的位置删除元素，那么其他位置的迭代器都失效 在首尾删除元素，只是会导致被指向的删除元素的迭代器失效 关联式容器 基于哈希表实现的std::unordered_map/std::set 导致迭代器失效，一般是插入元素导致 reshash 产生，如果是删除只是会导致被删除元素的迭代器失效。std::unordered_map底层实现及其解决 hash 冲突方法 std::unorder_map 解决冲突方式是 拉链法（数组的每个元素都连着一个链表？）：将所有产生冲突的关键字所对应的数据全部存储在同一个线性链表中（bucket）。这个方法解决数据存储位置发生冲突的哈希表，整个存储结构如图 1 所示。 其中 p_i表示存储的各个键值对。 当使用无序容器存储键值对时，会先申请一整块连续的存储空间，但此空间并不用来直接存储键值对，而是存储各个链表的头指针，各键值对真正的存储位置是各个链表的节点。STL 标准库默认选用vector容器存储各个链表的头指针。STL 标准库中，将图 1 中的各个链表称为桶 bucket，每个桶都有自己的编号（从 0 开始）。当有新键值对存储到无序容器中时，整个存储过程分为如下几步： 将该键值对中 key 的值带入设计好的哈希函数，会得到一个哈希值: H = hash(key)； 将 H 和无序容器拥有桶的数量 n 做整除运算（即H % n），该结果即表示应将此键值对存储到的桶的编号； 建立一个新节点存储此键值对，同时将该节点链接到相应编号的桶上 其他解决冲突的方法 开放地址法： H =(hash(key) + d) \\% m 其中`m`是哈希表的表长，`d`是一个增量，当产生冲突时，选择以下三种方法一种获取d的值，然后计算，直到计算出的*hash* 值不存在冲突。 + 线性探测法：d = 1,2,3,... + 二次探测法：d = 12,-12, 22, -22... + 伪随机数探测法: d = 伪随机数 再哈希法rehasp当通过哈希函数求得的哈希地址同其他关键字产生冲突时，使用另一个哈希函数计算，直到冲突不再发生 rehashp上述的拉链法解决了哈希冲突的问题，但是当插入元素很多，产生了严重哈希冲突时，就会导致某个链表长度越来越长，进而导致哈希表的查找就会退化为链表，效率降低为O(n)的时间复杂度。 哈希表存储结构还有一个重要的属性，称为负载因子load factor，用于衡量容器存储键值对的空/满程度：即负载因子越大，意味着容器越满，即各链表中挂载着越多的键值对，这无疑会降低容器查找目标键值对的效率；反之，负载因子越小，容器肯定越空，但并不一定各个链表中挂载的键值对就越少。 负载因子的计算方法为：负载因子 = 容器存储的总键值对 / 桶数 STL 中默认情况下，无序容器的最大负载因子为 1.0。如果操作无序容器过程中，使得最大复杂因子超过了默认值，则容器会自动增加桶数，并重新进行哈希，以此来减小负载因子的值。需要注意的是，此过程会导致容器迭代器失效，但指向单个键值对的引用或者指针仍然有效。 因此当插入元素过多，使得负载因子的大于1.0，就会产生rehash行为，来改善即将下降的效率。 STL中的 unordered_map 的 rehash 策略一下代码节选自g++的STL库： 12345678910111213141516171819202122232425262728293031323334353637383940414243// __n_bkt is current bucket count, __n_elt is current element count,// and __n_ins is number of elements to be inserted. Do we need to// increase bucket count? If so, return make_pair(true, n), where n// is the new bucket count. If not, return make_pair(false, 0).std::pair&lt;bool, size_t&gt; _M_need_rehash(size_t __n_bkt, size_t __n_elt, size_t __n_ins) noexcept &#123; if (__n_elt + __n_ins &gt;= _M_next_resize) &#123; long double __min_bkts = (__n_elt + __n_ins) / (long double)_M_max_load_factor; if (__min_bkts &gt;= __n_bkt) // 这个是需要rehash 时返回的策略 return std::make_pair(true, _M_next_bkt(std::max&lt;size_t&gt;(__builtin_floor(__min_bkts) + 1, __n_bkt * _S_growth_factor))); _M_next_resize = __builtin_floor(__n_bkt * (long double)_M_max_load_factor); return std::make_pair(false, 0); &#125; return std::make_pair(false, 0); &#125;size_t _M_next_bkt(size_t __n) noexcept &#123; const auto __max_width = std::min&lt;size_t&gt;(sizeof(size_t), 8); // 8 个字节 const auto __max_bkt = size_t(1) &lt;&lt; (__max_width * __CHAR_BIT__ - 1); // 2 ^ 63 size_t __res = __clp2(__n); // 计算大于等于 n 的最小的2的幂 if (__res == __n) __res &lt;&lt;= 1; if (__res == 0) __res = __max_bkt; // Set next resize to the max value so that we never try to rehash again // as we already reach the biggest possible bucket number. // Note that it might result in max_load_factor not being respected. if (__res == __max_bkt) _M_next_resize = size_t(-1); else _M_next_resize = __builtin_ceil(__res * (long double)_M_max_load_factor); return __res;&#125; 其中，在这个类的前面有定义： _M_max_load_factor 初始化为 1.0 static const size_t _S_growth_factor = 2; 整个扩容的策略大致是按照2倍的策略增长，但是并不严格按照。在MSVC中按照的是8倍的扩充策略。 多线程下的 std::unordered_mapSTL中的 哈希表 是线程不安全的（其实 STL 库都是线程不安全的）。 比如两个线程同时向 std::unordered_map 中插入数据，当发生rehash时，如果不加锁，可能导致两个线程都会产生rehash。 如何优化 多线程读写操作？这里要借鉴下java的分段锁。 参考链接 hash std::unordered_map底层原理 g++ 中 std::unordered_map 的实现 map 与 红黑树. 红黑树的规则 树根始终为黑色 外部节点均为黑色 其余节点若为红色，则器孩子节点必为黑色 从任一外部外部节点到根节点的沿途，黑色节点的数目相等 条件1和2说明，红色节点均是内部节点，其父节点及左、右孩子节点必然存在；另外条件3说明，红节点之父必为黑色，因此树中任一通路都不含相邻的红节点 红黑树的效率为什么比AVL树高?如果只有查询操作哪种树的效率高? 红黑树的效率高,是因为不需要像AVL树那样,为了维护高度平衡性,而不断地动态调整以维护左右子树高度差不超过1.红黑树降低了对平衡度的要求,以减少每次插入/删除操作时的动态调整次数.但是就查询效率而言,是不如AVL树的. 工具如何进行性能排查？找出性能瓶颈？性能测试？有什么工具： valgrind :可以查找代码问题GDB学习参考链接 GDB学习1 GDB学习2 GDB学习3 GDB学习4 GDB学习5 GDB学习6 GDB学习7","raw":"---\ntitle: 来自网络的C++笔记\ndate: 2020-08-28 00:00:00\ntags:\n    - C++\n    - notebook\ncategories: 学习笔记\n---\n\n## 基础知识\n#### RAII  \n全称是 **R**esource **A**cquisition **I**s **I**nitialization ， 即“资源获取即初始化”，其核心是把资源和对象的生命周期绑定：对象创建获取资源，对象销毁释放资源。这就是的资源也有了生命周期，有了自动回收的功能。*lock_guard* 都利用了 *RAII*机制来实现。\n\n防止内存泄露的方式有 **R**AII、智能指针。\n\n#### 大端和小端\n\n+ 大端就是高字节在高地址，低字节在低地址。 \n\n+ 小端就是低字节在高地址，高字节在低地址。\n\n   ```cpp\n      // 大端小端区分  \n      bool isBigEndian() {  \n           union NUM  {  \n               int a;  \n               char b; // 如果是大端 b 就是最高位 ，小端就是最低位  \n           }num;  \n\n           num.a = 0x1234;  \n           if(num.b == 0x12)  \n           {  \n               return true;  \n           }  \n\n           return false;  \n       }\n   ```\n   \n+ 大端小端转换\n   ```cpp\n   //无符号整型16位  \n   uint16_t bswap_16(uint16_t x)  {  \n       return ((x & 0x00ff) << 8) | (x & 0xff00) >> 8) ;  \n   }  \n    \n   //无符号整型32位\n   uint32_t bswap_32(uint32_t x) {  \n       return ((x & 0xff000000) >> 24)| ((x & 0x00ff0000) >> 8) | \\\n              ((x & 0x0000ff00) << 8) | ((x & 0x000000ff) << 24) ;  \n   } \n   ```\n\n#### 生成可执行文件过程及各个过程完成的事情：  \n1. 预编译处理(.c) : 将源文件`main.cc` 翻译成一个ASCII码的中间件文件 `main.i`  \n2. 编译、优化程序（.s、.asm）： 将 `main.i`文件 翻译成一个 ASCII 汇编文件 `main.s`  \n3. 汇编程序(`.obj、.o、.a、.ko`)  ：运行汇编器，将 `main.s` 翻译成一个可重定位目标文件`main.o`   \n4. 链接程序（`.exe、.elf、.axf`等） ： 运行链接器，将`main.o` 中使用到的目标文件组合起来，创建一个可执行的文件     \n    为了构造可执行文件，这链接器必须完成两个主要任务：  \n    + 符号解析  ：目的是将每个符号引用正好和一个符号定义关联起来。每个符号对应于一个函数、全局变量、static变量等\n    + 重定位：对于由编译器和汇编器生成的从地址0开始的代码和数据节，链接器将每个符号定义与一个内存位置关联起来，从而重定位这些数据节，然后修改所有对这些符号的引用，使得他们**指向内存位置**。\n#### 静态库与动态库\n\n**根本区别**：是在编译期还是在是执行期完成链接、装入动作。链接的主要内容就是把各个模块之间相互引用的部分都处理好，\n使得各个模块之间能够正确地衔接\n\n + 静态库：之所以叫做静态库，是因为在**链接阶段**，当使用链接器将由汇编生成的目标文件构造成一个可执行的输出文件时，它只是**复制静态库中里这个即将生成的可执行文件所引用到的目标模块**。静态库特点总结：\n\n   +  静态库对函数库的链接是放在编译时期完成的。\n\n   + 程序在运行时与函数库再无瓜葛，移植方便。\n\n   + 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。\n\n + 动态库：动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。**不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例**，规避了空间浪费问题。动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，**增量更新**\n\n   \t+  动态库把对一些库函数的**链接载入**推迟到程序运行的时期。\n   + 可以实现进程之间的资源共享。（因此动态库也称为共享库）\n\n   + 将一些程序升级变得简单。\n\n   + 甚至可以真正做到链接载入完全由程序员在程序代码中控制（**显示调用**）。\n#### 编译型语言和解释型语言的区别\n  +  编译型语言在运行前就生成可执行文件，运行时就没有编译了\n  + 解释型语言在运行的时候才翻译\n####  static、extern、全局变量\n+ static全局变量与普通的全局变量有什么区别：static全局变量只初使化一次，防止在其他文件单元中被引用;\n\n+ static局部变量和普通局部变量有什么区别：static局部变量只被初始化一次，下一次依据上一次结果值；\n\n+ 程序的局部变量存在于（堆栈）中，全局变量存在于（静态区 ）中，动态申请数据存在于（ 堆）中。\n\n  extern全局变量(用extern修饰的变量只是说明该变量在其他地方定义，所以在其他地方一定要用明确的定义如int a，并且不能用static修饰）、static全局变量和static局部变量的生存期都是“永久”，区别只是可见域不同。extern全局变量可见区域是工程，static全局变量可见区域是文件，而static局部变量的可见区域是块。\n  \n#### volatile\n+ 阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回。\n\n+ 阻止编译器调整操作`volatile`变量的指令顺序。\n\n  注意：即使 `volatile` 能够阻止编译器调整顺序， 也无法阻止CPU动态调度换序（`reorder`）\n#### *assert*\n\n断言主要用于检查逻辑上不可能的情况。例如，它们可用于检查代码在开始运行之前所期望的状态，或者在运行完成后检查状态。**与正常的错误处理不同，断言通常在运行时被禁用**。\n\n*assert* 是个宏而非函数，如果条件返回错误，则会抛出异常，最后会调用 *abort* 终止程序，发送的是 *SIGABRT*，可以通过宏 ***NODEBUG*** 来关闭 *assert*，但是需要设置在源代码的开头。\n\n```cpp\n#define assert(expr)\t\t\t\t\t\t\t\t\\\n     (static_cast <bool> (expr)\t\t\t\t\t\t \\\n      ? void (0)\t\t\t\t\t\t\t\t\t\\\n      : __assert_fail (#expr, __FILE__, __LINE__, __ASSERT_FUNCTION))\n\nextern \nvoid __assert_fail (const char *__assertion, \n                    const char *__file,\n                    unsigned int __line, \n                    const char *__function)\n{\n     __THROW __attribute__ ((__noreturn__));\n}\n\n```\n\n在判断失败时会调用 *__assert_fail* 来抛出异常，在C++中异常的底层是用 *abort* 实现的。\n\n####  指针和引用的区别\n+ 目的不同：指针是为了兼容 C 而存在，引用是为了操作符重载而存在\n+ 在声明引用的的同时就要对它初始化，并且一经声明就不可以再和其它对象绑定在一起了。\n+ 引用更像是常量指针，只能改变绑定对象的值，不能改变绑定的对象。\n+ 引用它一定不为空，因此相对于指针，它不用检查它所指对象是否为空，更加安全也增加了效率\n####  new、malloc\n+ new：不仅仅是分配内存，还包括了对象类型转换以及初始化\n  + 是先调用*operator new*分配内存空间，返回是*void* *类型；\n  + 再将返回类型转换为指定类型，再调用类的构造函数。\n  +  如果内存空间不足，会抛出*std::bad_alloc*异常\n  \n+ malloc\n  + 返回 `void*`类型，并且在内存不足时，返回`NULL`指针\n  + 当开辟的空间小于 `128K`时，调用`brk()` 函数，`malloc`的底层实现是系统调用函数 `brk()`\n  + 当开辟的空间大于 `128K `时，`mmap()` 系统调用函数来在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟\n\n    `operator new` 底层也是由`malloc`实现。 `malloc`底层是由`slab`实现。\n\n    对于`POD`类型对象，使用`new` 创建的对象，也是可以使用`free`来释放销毁对象，原因就是在于这个对象是`POD` 类型。没有其他资源需要释放，或者文件描述符需要关闭，因此可以不调用析构函数而使用`free`来替代`delete`。尽管可以，但是不推荐，这样的代码并不健壮。\n\n    `new` 在C++里是可以用 `malloc + placement` 替代的，或者说等效于这两个。\n\n    ```cpp\n    // 更好的展示 malloc 与 new 的区别与联系\n    class Foo { \n    public:\n        Foo(int a=0, int b=0): a(a),b(b) { }\n\n        ~Foo() { std::cout<<\"dtor\"<<std::endl; }\n    private:\n        int a;\n        int b;\n    };\n\n    int main(int argc, char const *argv[])\n    {\n        // new = placement new + malloc\n        Foo* foo = static_cast<Foo*>(::malloc(sizeof(Foo)));\n        new(foo)Foo(1,1);\n        \n        // delete\n        foo->~Foo();\n        ::free(foo);\n        return 0;\n    }\n    // 运行结束，无内存泄露\n    ```\n\n+  除了`new`和`malloc`，还有什么方式可以在堆中分配内存么，以及怎么释放？  \n    **`mmap`，`munmap`**\n#### 多态  \n多态的三个条件：继承，重写（`override`），基类引用指向派生类对象。\n+ 静态多态   \n  \n    + 重载，在编译时期就可以确定\n    \n    + 模板技术：比如 `CRTP`，它是使用子类来作为基类的模板参数，在基类中调用子类的方法。\n    \n      ```cpp\n      template<typename Derived>\n      class Base{ \n            // 其他忽略\n          Derived& convert() \n          { \n          \treturn static_cast<Derived&>(*this);\n          }\n      };\n      ```\n      这个也从侧面说明`static_cast` 可以让子类转换为父类，要使得保证安全，前提是转换后调用子类的方法中没有使用子类独有的数据成员\n    \n+ 动态多态    \n  运行时才确定调用的是哪个函数。核心关键在于虚函数：子类重写基类的虚方法，定义指向子类对象的基类指针。这个基类指针的行为直到运行时才能确定调用的是子类还是基类的方法，这就是多态。\n\n  实现原理是：虚函数表和虚函数指针`vptr`。[详情](./3.虚拟成员函数.md)\n#### 重载(`overload`)和重写(`override`)\n\n+ 重载：允许多个同名函数，而这些函数的参数列表不同，函数模板这么实现的，在编译期间就能确定。\n\n  C++函数重载底层实现原理是C++利用 **`name mangling`** 技术，来改变函数名，区分参数不同的同名函数。编译器通过函数名和其参数类型识别重载函数。不能仅仅基于不同的返回类型而实现函数重载，是因为经过 `name mangling` 后得到的函数名与返回值类型是无关的。\n    ```cpp\n      void func(int a) { }\n\n      int func(int a, int b) { return a+b; }\n\n      int main(int argc, char const *argv[])\n      {\n        return 0;\n      }\n    ```\n    比如，如上的代码。在经过编译后，得到的符号表如下：\n    ```cpp\n      $ objdump -t main.o\n      0000000000000000 g     F .text  000000000000000e _Z4funci\n      000000000000000e g     F .text  0000000000000018 _Z4funcii\n      0000000000000026 g     F .text  0000000000000016 main\n    ```\n    其中， 前缀 `__z` 是规定，`4` 是函数名的字符个数，`i`是第一个函数的参数类型`int`，`ii`是第二个函数的参数类型`int, int`。由此可见也是与返回值无关的。\n\n+ 重写`override`：是指子类重新定义父类的方法，子类的函数名和参数列表以及返回值必须与父类的完全一致。对于虚函数的重写，c++11中新定义了一个关键词`override`，就是为了让子类在重写父类的虚函数方法时，如何参数列表发生更改可以让编译器报错。\n#### `static`\n`static`变量都是在全局数据区分配内存,声明周期直到程序运行结束.\n\n+ 四类`static`\n  + 全局`static`变量和`static`函数：都已经被匿名命名空间取代，作用是不能外部文件使用\n  + 局部`static`变量：在数据区`.data`分配内存，首次初始化以后，以后调用都不会再初始化，**作用域仅局限于函数**，生命周期直到程序运行结束\n  + 静态数据成员:类对象共享，不能在类声明中定义，是因为在定义时就要分配空间，也是在`.data` \n  + 静态成员函数:静态成员函数，**不隐含this指针**，不能调用非静态成员函数/变量，可以用作回调函数\n  \n+ 为什么要引入`static`  \n\n  需要一个数据对象为整个类而非某个对象服务，同时又不能破坏类的封装特性，因此将静态成员隐藏在类的内部,提供静态成员函数接口，因为共享,可以节省内存。\n####  对象\n+ 空类有六个成员函数\n  ```cpp\n    class Empty { \n    public:\n      Empty(); \n      Empty(const Empty& );\n      ~Empty();\n\n      Empty& operator=(consy Empty& );\n      Empty* operator& ();               // 取地址运算符\n      const Empty* operator& () const;   // const 类型取地址运算符\n    };\n  ```\n+ 构造函数可以是虚函数吗？析构函数可以是虚函数吗？\n  \n  虚函数对应一个`vtbl`，这个`vtbl`实际是存储在对象的内存空间.如果构造函数是虚的,对象的构造就需要`vtbl`来调用，而虚函数表又是在对象构造后才能建立,因此构造函数不能是虚函数.\n\n  而析构函数在使用多态的继承中一般都是虚析构函数.为的是能正确选择析构函数.\n\n+ `c++`的深拷贝如何理解 \n  \n  在类中有指针时并且内部分配资源.经过浅拷贝后,最终会造成资源一次分配,多次释放.造成系统崩溃.\n#### C++中如何在main()函数之前执行操作\nmain函数执行之前，主要就是初始化系统相关资源：\n+ 设置栈指针\n+ 初始化静态`static`变量和`global`全局变量，即`.data`段的内容\n+ 将未初始化部分的全局变量赋初值：数值型`short`，`int`，`long`等为`0`，`bool`为`FALSE`，指针为`NULL`等等，即`.bss`段的内容     \n+ 全局对象初始化，在`main`之前调用构造函数\n+ 将main函数的参数`argc`，`argv`等传递给`main`函数，然后才真正运行`main`函数\n\n**main函数执行之后**：  \n\n+ 全局对象的析构函数会在main函数之后执行； \n+ 可以用 **`atexit`** 注册一个函数，它会在main 之后执行;\n#### sizeof  和 strlen 区别\n```cpp\n  int main(int argc, char const *argv[]){\n      \n      const char* str = \"name\";\n\n      sizeof(str); // 取的是指针str的长度，是8\n      strlen(str); // 取的是这个字符串的长度，不包含结尾的 \\0。大小是4\n      return 0;\n  }\n```\n####  strcpy、strncpy和mmemcpy的区别\n  ```cpp\n  char* strcpy(char*  dest, const char* src);\n  char* strncpy(char* dest, const char* src, size_t n);\n  void* memcpy (void* dest, const void* src, size_t n);\n  ```\n  前面两个函数是以字符为单位，而`mmemcpy`是以字节为单位。\n\n  `strcpy`和`memcpy`主要有以下3方面的区别。  \n  + 复制的内容不同。`strcpy` 只能复制字符串，而`memcpy`可以复制任意内容，例如字符数组、整型、结构体、类等。\n  + 复制的方法不同。`strcpy` 不需要指定长度，它遇到被复制字符的串结束符`'\\0'`才结束，所以容易溢出。`memcpy` 则是根据其第3个参数决定复制的长度，而且如果字符串数据中包含`'\\0'`，只能用`memcpy`。\n  + 用途不同。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy\n\n  `strncpy` ：在复制字符串时，`memcpy`更加类似于`strncpy`。  \n  `strncpy`和`memcpy`很相似，只不过它在一个终止的空字符处停止。当 `n > strlen(src)` 时，`dst[strlen(len)] ~ dst[n-1]`都是`\\0`；当 `n<=strlen(src)`时，复制前`src`的n个字符。这里隐藏了一个事实，就是`dst`指向的内存一定会被写n个字符。\n\n  `memcpy`需要注意的是：   \n  + `dest` 指针要分配足够的空间，也即大于等于 `n` 字节的空间。如果没有分配空间，会出现断错误。\n  + `dest` 和 `src` 所指的内存空间不能重叠（如果发生了重叠，使用 `memmove()` 会更加安全）。\n\n  动手实现 `memcpy`： \n  ```cpp\n  void* myMemcpy(void* dst, const void* src, size_t n) { \n    if(dst ==nullptr || src==nullptr) return nullptr;\n    if(src == dst) retrun src;\n      \n      char* pdst       = static_cast<char*>(dst); \n      const char* psrc = static_cast<const char*>(src);\n      // 发生重叠时，从后向前复制\n      if(psrc <  pdst && pdst < psrc + n) \n      { \n          for(int i=n-1; i >=0; --i)  pdst[i] = psrc[i];\n      }\n      else \n      { \n          for(int i=0; i < n; ++i) pdst[i] = psrc[i];\n      }\n      return pdst;\n  }\n\n  // 使用\n  int main(int argc, char const *argv[])\n  {\n      char buf[12]={0};\n      char str[]  = \"hello world cpp\";\n\n      myMemcpy(str, str+6, 9);\n      std::cout<<str<<std::endl;\n      return 0;\n  }\n  ```\n####  野指针和悬空指针   \n  都是是指向无效内存区域(这里的无效指的是\"不安全不可控\")的指针，访问行为将会导致未定义行为。\n  + 野指针   \n    野指针，指的是没有被初始化过的指针\n    \n    ```cpp\n    int main(void) { \n        \n        int* p;     // 未初始化\n        std::cout<< *p << std::endl; // 未初始化就被使用\n        \n        return 0;\n    }\n    ```\n    因此，为了防止出错，对于指针初始化时都是赋值为 `nullptr`，这样在使用时编译器就会直接报错，产生非法内存访问。\n    \n  + 悬空指针    \n    悬空指针，指针最初指向的内存已经被释放了的一种指针。\n    \n    ```cpp\n    int main(void) { \n      int * p = nullptr;\n    \n      int* p2 = new int;\n      \n      p = p2;\n    \n      delete p2;\n    }\n    ```\n此时 p和p2就是悬空指针，指向的内存已经被释放。继续使用这两个指针，行为不可预料。需要设置为`p=p2=nullptr`。此时再使用，编译器会直接保错。\n    \n    避免野指针比较简单，但悬空指针比较麻烦。c++引入了智能指针，C++智能指针的本质就是避免悬空指针的产生。\n#### malloc、calloc、realloc\n```c\n    #include <stdlib.h>\n\n    void *malloc(size_t size);\n    void *calloc(size_t nmemb, size_t size);\n    void *realloc(void *ptr, size_t size);\n    void free(void *ptr);\n```\n+ `malloc`\n  最常用的分配内存函数，分配`size`个字节。**分配的内存是未初始化的**，如果`size==0`，要么返回`NULL`，要么返回一个独一无二的指针，能被`free`释放。\n+ `realloc`：用来改变已有内存区的大小，而不改变内容。新的大小为参数`size`，即newsize。\n  \n  + `ptr==NULL`：`realloc(NULL,size)`就相当于`malloc(size)`\n  + `size==0`：`realloc(ptr, 0)`就相当于`free(ptr)`\n  + `ptr==NULL && size==0`：危险。\n  + 如果`newsize > oldsize`，那么增加的内存是未初始化的，原来的内存内容保持不变，即`[ptr, ptr+oldsize)`内部不变，`[ptr+oldsize, ptr+newsize)`是初始化的内容。\n+ 如果`newsize < oldsize`，尾部的内容就被切去，释放，只是剩下前面。\n  \n  **因此 `realloc`之后不能给这个内存区初始化**.\n+ `calloc`\n  分配`nmemb`个元素，每个元素大小是`size`个字节的连续内存。\n  + 内存大小是`nmemb*size`的连续内存区\n  + **这块内存被初始化为`0`**。\n\n  如果`size==0`，要么返回`NULL`，要么返回一个独一无二的指针，能被`free`释放。\n#### 编译知识\n为了减小编译依赖加快编译速度和生成二进制文件的大小，C/C++ 项目中一般在 *.h 文件对于**指针类型（包括智能指针）** 尽量使用前置声明，而不是直接包含对应类的头文件。例如：\n```cpp\n  //Test.h\n  //在这里使用A的前置声明，而不是直接包含A.h文件\n  class A;\n\n  class Test\n  {\n  public:\n    Test();\n    ~Test();\n\n  private:\n    A*\n  };\n```\n#### Copy Elision\n\ng++ 编译器是默认开启 `copy elison` 选项的。如果要关闭这个选项，使用 `-fno-elide-constructors`。`copy elision` 主要包括以下两项内容：\n\n<font color=yellow>1. 返回值优化</font>  \n\n即通过将返回对象所占空间的直接构造到他们本来要复制/移动到的对象中去，依次来避免拷贝/移动操作。返回值优化包括具名返回值优化 `NRVO` 与 匿名返回值优化 `URVO`，区别在于返回值是具名的局部变量（`NRVO`）还是无名的临时对象（`URVO`）\n+ `URVO` 与 彻底 `Copy elision`\n  ```cpp\n    class Copyable { \n\n    public:\n      Copyable() { std::cout<<\"default ctor\"<<std::endl; }\n\n      Copyable(const Copyable& rhs) = delete; \n      Copyable(Copyable&& rhs) = delete;\n    };\n\n    Copyable return_urvo_value() { \n\n      return Copyable{}; // since c++17 ok\n    }\n\n    int main(int argc, char const *argv[]) {\n\n      auto x  = return_urvo_value();\n      \n      return 0;\n    }\n  ```\n  上述代码在C++17中是可以编译通过的。在 C++17 之前，并没有明确的提出在什么情况下，可以彻底进行 `Copy Elision`（这里的彻底的指的是包括不进行检查是否有可用的 *copy/move* 构造函数）。在C++17中，对于匿名对象（or 临时对象）不论是传递参数，还是以返回值返回时，都不会调用拷贝/移动构造。因此上面的这段代码在C++17是可以正常编过的，而在C++14会编译出错。\n  ```cpp  \n    $ g++ main.cc -std=c++14 -o main && ./main\n    main.cc: In function ‘Copyable return_urvo_value()’:\n    main.cc:29:19: error: use of deleted function ‘Copyable::Copyable(Copyable&&)’\n      29 |   return Copyable{};\n         |                   ^\n    main.cc:24:3: note: declared here\n      24 |   Copyable(Copyable&& rhs) = delete;\n         |   ^~~~~~~~\n    main.cc: In function ‘int main(int, const char**)’:\n    main.cc:34:31: error: use of deleted function ‘Copyable::Copyable(Copyable&&)’\n      34 |   auto x  = return_urvo_value();\n         |                               ^\n    main.cc:24:3: note: declared here\n      24 |   Copyable(Copyable&& rhs) = delete;\n         |   ^~~~~~~~\n  ```\n    自然，只要将上面代码中的如下两行注释掉，即可正常编译，并且 `Copyable`的构造函数都是只被调用一次，即`copy elision` 起作用了。 注意：`Copyable`的复制/移动构造函数必须同时可访问。\n    ```cpp\n      Copyable(const Copyable& rhs) = delete; \n      Copyable(Copyable&& rhs) = delete;\n    ```\n    因此，在C++17以前，对于 `urvo` 不在乎是否返回的对象的复制/移动构造函数是否存在或者可访问，`copy elision` 都能生效。而在 `C++14` 之前，返回的对象可以没有复制/移动构造函数，但是必须可以访问。\n\n+ `nrvo`    \n  在 `nrvo`时，返回对象的复制/移动构造函数必须可访问。否则编译不过。\n  ```cpp\n    class Copyable { \n    public:\n      Copyable() { std::cout<<\"default ctor\"<<std::endl; }\n\n      Copyable(const Copyable& rhs) = delete;\n      Copyable(Copyable&& rhs) = delete;\n    };\n\n    Copyable return_urvo_value() { \n\n      return Copyable{};\n    }\n\n    Copyable return_nrvo_value() { \n      Copyable local;\n\n      return local;\n    }\n\n    int main(int argc, char const *argv[]) {\n\n      auto x  = return_urvo_value();\n      auto y  = return_nrvo_value();\n      \n      return 0;\n    }\n  ```\n  如上代码，即使是C++17也会编译失败，必须将如下两行代码注释掉，使得 `Copyable` 对象的复制/移动构造函数可访问。`copy elision` 才能生效：`Copyable` 的默认构造函数只调用一次。\n  ```cpp\n    // Copyable(const Copyable& rhs) = delete;\n    // Copyable(Copyable&& rhs) = delete;\n  ```\n\n<font color=yellow> 2. 右值拷贝优化 </font>  \n\n右值拷贝优化，当某一个类的临时对象以值传递给该类的另一个对象时，也可以直接利用该临时对象的来避免拷贝/移动操作。在上面的基础上，加上如下的代码：\n```cpp  \n  void pass_by_value(Copyable rhs) { \n\n  }\n\n  int main(int argc, char const *argv[]) {\n\n    auto x  = return_urvo_value();\n    auto y  = return_nrvo_value();\n\n    pass_by_value(Copyable());\n    \n    return 0;\n  }\n```\n最终的输出也是调用默认三次构造函数：\n```bash\n  $ g++ main.cc -std=c++11 -o main && ./main\n  default ctor\n  default ctor\n  default ctor\n```\n\n到此，`copy elision` 基本分析结束。如果想查看没有`copy elision` 作用下的输出，开启`-fno-elide-constructors`。\n#### Copy Elision 作用  \n对于一些没有拷贝/移动构造的对象，如 `unique_ptr`、 `atomic` 等。现在我们能够定义一个工厂函数，即使没有复制或移动构造函数都可以返回一个对象。例如，以下通用工厂函数:\n```cpp\n  template <typename T, typename... Args>\n  T make_instance(Args&& ... args)\n  {\n    return T{ std::forward<Args>(args)... };\n  }\n  \n  int main()\n  {\n    int i   = make_instance<int>(42);\n    // std::unique_ptr 实现了 移动构造函数，因此可以编译成功 \n    auto up = make_instance<std::unique_ptr<int>>(new int{ 42 }); \n    // 禁止了复制构造函数，但是也没有实现移动构造函数，因此要到 C++17 才能编译过\n    auto ai = make_instance<std::atomic<int>>(42);                  \n  \n    return 0;\n  }\n```\n[参考](https://blog.csdn.net/davidhopper/article/details/90696200)\n\n## STL \n### *std::vector*\n  + *std::vector* 在 *push_back* 以成倍增长可以在均摊后达到O(1)的事件复杂度，相对于增长指定大小的O(n)时间复杂度更好。\n  + 为了防止申请内存的浪费，现在使用较多的有2倍与1.5倍的增长方式，而1.5倍的增长方式可以更好的实现对内存的重复利用，因为更好\n  + *std::vector/std::list*的实现原理及其使用场景   \n    *std::vector*是用连续内存的数组实现的，*std::list*是通过指针之间的指向实现不连续内存的高效率使用.\n\n*std::vector* 与 *std::list*\n\n  + 数组，最大的好处是能以 *O(1)* 用索引访问任意元素，次要好处是内存布局紧凑，省内存之余还有高缓存一致性（*cache coherence*）。但数组的缺点是不能快速插入元素，而且我们在解析 *JSON* 数组的时候，还不知道应该分配多大的数组才合适。\n  + 链表，它的最大优点是可快速地插入元素（开端、末端或中间），但需要以 *O(n)* 时间去经索引取得内容。如果我们只需顺序遍历，那么是没有问题的。还有一个小缺点，就是相对数组而言，链表在存储每个元素时有额外内存开销（存储下一节点的指针），而且遍历时元素所在的内存可能不连续，令缓存不命中（*cache miss*）的机会上升。\n\n### *std::bind* \n\n对于如下代码，使用 *std::bind* 绑定类的成员函数并调用。\n\n```cpp\nclass Foo { \npublic:\n  Foo()=default;\n\n  void add(const int& lhs, const int& rhs) \n  { \n    std::cout<< (lhs + rhs)<<std::endl;;\n  }\n};\n\nint main(int argc, char const *argv[])\n{\n  Foo foo1;\n   // 绑定并且执行\n  std::bind(&Foo::add, &foo1, 1, 2)();\n  return 0;\n}\n```\n\n最后内部执行的代码如下：\n\n```cpp\ntemplate<typename _Res, typename _MemFun, typename _Tp, typename... _Args>\nconstexpr _Res\n__invoke_impl(__invoke_memfun_deref, _MemFun&& __f, _Tp&& __t, _Args&&... __args)\n{\n  return ((*std::forward<_Tp>(__t)).*__f)(std::forward<_Args>(__args)...);\n}\n```\n\n其中 \n\n+ `_t` ，类型是 `Foo*&` 函数对象指针，指向的`foo1`对象。\n+ `_f`是函数指针，指向的就是`add`成员函数\n+ `__invoke_memfun_deref`：是用来标记是哪种把绑定方式，比如上述代码中的绑定对象成员函数\n\n因此，最终，调用可以简化为如下：\n\n```cpp\nfoo1.add(1,2);\n```\n\n整个`std::bind` 最终的执行代码如下：\n\n```cpp\n// 直接传入函数调用: std::bind(func, arg1, arg2); 或者静态成员函数\n// 很明显，这里没有类对象\ntemplate<typename _Res, typename _Fn, typename... _Args>\nconstexpr _Res\n__invoke_impl(__invoke_other, _Fn&& __f, _Args&&... __args)\n{ return std::forward<_Fn>(__f)(std::forward<_Args>(__args)...); }\n\n// 上面介绍过\ntemplate<typename _Res, typename _MemFun, typename _Tp, typename... _Args>\nconstexpr _Res\n__invoke_impl(__invoke_memfun_deref, _MemFun&& __f, _Tp&& __t, _Args&&... __args)\n{\n  return ((*std::forward<_Tp>(__t)).*__f)(std::forward<_Args>(__args)...);\n}\n\n// 下面几种没见过调用\ntemplate<typename _Res, typename _MemFun, typename _Tp, typename... _Args>\nconstexpr _Res\n__invoke_impl(__invoke_memfun_ref, _MemFun&& __f, _Tp&& __t, _Args&&... __args)\n{ return (__invfwd<_Tp>(__t).*__f)(std::forward<_Args>(__args)...); }\n\ntemplate<typename _Res, typename _MemPtr, typename _Tp>\nconstexpr _Res\n__invoke_impl(__invoke_memobj_ref, _MemPtr&& __f, _Tp&& __t)\n{ return __invfwd<_Tp>(__t).*__f; }\n\ntemplate<typename _Res, typename _MemPtr, typename _Tp>\nconstexpr _Res\n__invoke_impl(__invoke_memobj_deref, _MemPtr&& __f, _Tp&& __t)\n{ return (*std::forward<_Tp>(__t)).*__f; }\n```\n\n*Lambda*\n\n*lambda*可以理解为是仿函数的语法糖。\n\n```cpp\nint main(int argc, char const *argv[])\n{\n  auto add  = [](int a, int b) { return a+b; };\n  int c = add(1,2);\n\n  return 0;\n}\n```\n\n对于上面的`lambda`函数，在gdb调试，经过编译的到的函数类型：\n\n```cpp\n(gdb) s\n<lambda(int, int)>::operator()(int, int) const (__closure=0x7fffffffe6d3, a=1, b=2) at main.cpp:24\n24        auto add  = [](int a, int b) { return a+b; };\n```\n\n`lambda`可以看作是匿名的函数对象，并且 `lambda`表达式默认是 `const`属性。\n\n```cpp\nclass Foo { \npublic:\n  Foo() \n  { \n    [](){std::cout<<\"123\"<<std::endl; }();\n  }\n};\n\nint main(int argc, char const *argv[])\n{ \n  Foo foo;\n\n  return 0;\n}\n```\n\n在类中调用`lambda`表达式，编译出来的类型如下：\n\n```cpp\nFoo::Foo()::{lambda()#1}::operator()() const\n```\n\n而实际上，lambda与operator本质上也是一样的，如下代码：\n```cpp\n\tclass Foo { \n    public:\n      Foo() \n      { \n        // 以下两个设计等价\n        [this](const char* str){this->print(str); }(\"lambda\");\n        Unmaed(this)(\"operator\");\n      }\n\n      void print(const char* str) { \n        std::cout<<str<<std::endl;\n      }\n\n    private:\n      struct Unmaed\n      {\n        Unmaed(Foo* foo): foo_(foo) { }\n\n        void operator()(const char* str) const\n        {\n          foo_->print(str);\n        }\n\n        Foo* foo_;\n      };\n    };\n```\n#### std::bind 与 lambad区别\n\n+ `lambda` 可以重载，但是 `std::bind` 无法区别重载\n  \n  ```cpp\n    void f(int) {}\n  void f(double) {}\n  \n    auto g = [] { f(1); }; // OK\n    auto g = std::bind(f, 1); // 错误\n    auto g = std::bind(static_cast<void(*)(int)>(f), 1); // OK\n  ```\n\n为此必须指定对应的函数指针类型。`lambda` 闭包类的 `operator()` 采用的是能被编译器内联的常规的函数调用。而`std::bind`采用的是一般不会被内联的函数指针调用，这意味着 **`lambda` 比 `std::bind` 运行得更快**。\n\n+ 传给 `std::bind` 的参数，绑定的是 `std::bind`，而不是`std::bind`内部管理的函数\n  ```cpp\n  void f(std::chrono::steady_clock::time_point t, int i)\n  {\n      std::this_thread::sleep_until(t);\n      std::cout << i;\n  }\n\n  auto g = [](int i)\n  {\n      f(std::chrono::steady_clock::now() + std::chrono::seconds(3), i);\n  };\n\n  g(1); // 3秒后打印1\n  // 用std::bind实现相同效果，但存在问题\n  auto h = std::bind(f,\n                      std::chrono::steady_clock::now() + \t std::chrono::seconds(3),\n                      std::placeholders::_1);\n\n  h(1); // 3秒后打印1，但3秒指的是调用std::bind后的3秒，而非调用f后的3秒\n  ```\n\n计算时间的表达式作为实参被传递给`std::bind`，因此计算发生在调用`std::bind`的时刻，而非调用其绑定的函数的时刻。\n\n在 `c++14` 中，完全没有理由使用 `std::bind`，`c++11`由于特性受限，存在两个使用场景：\n  + 模拟`c++11`缺少的移动捕获\n  + 函数对象 `operator()` 是模板时，如果将此函数作为参数使用，用 `std::bind` 绑定才能接受任意类型参数\n  ```cpp\n  struct X {\n      template<typename T>\n      void operator()(const T&) const;\n  };\n  \nX x;\n  auto f = std::bind(x, _1); // f可以接受任意参数类型\n  \n// c++14 做法\n  X a;\n  auto f = [a](const auto& x) { a(x); };\n  ```\n#### *Lambda* 与 *std::bind* 区别补充\n`std::bind` 传入的参数默认情况下是 “值传递”，想要使用引用传递需要`std::ref`。详细可以参考下面的代码：\n\n```cpp\n  class Foo { \n  public:\n    Foo() \n    { \n      std::cout<<\"default\"<<std::endl; \n    }\n\n    Foo(const Foo& rhs)     \n    { \n      std::cout<<\"ctor\"<<std::endl;\n    }\n  };\n\n  void add(const Foo& lhs, const Foo& rhs) { \n\n  }\n\n\n  int main(int argc, char const *argv[])\n  {\n    std::cout<<std::boolalpha;\n\n    Foo foo1;\n    Foo foo2;\n  \n    std::cout<<\"bind: pass by value\"<<std::endl;\n    auto func = std::bind(add,  foo1, foo2);\n    \n    std::cout<<\"bind: pass by ref\"<<std::endl;\n    auto func = std::bind(add,  std::ref(foo1), std::ref(foo2));\n\n    std::cout<<\"lambda \"<<std::endl;\n    [&foo1, &foo2]{ add(foo1, foo2);}();\n\n    return 0;\n  }\n```\n上面的代码输出：\n```bash\n  $ g++ -g  -O0 main.cc -o main && ./main\n  default\n  default\n  bind: pass by value\n  ctor\n  ctor\n  bind: pass by ref\n  lambda \n```\n可以看到`std::bind`在默认情况下，是依靠值传递，使用了`std::ref`来包裹传入参数才是使用引用传递。用 `gdb` 调试，可以跟踪到发生构造 `Foo` 对象的位置：\n```cpp\ntemplate<typename _UHead>\nconstexpr _Head_base(_UHead&& __h) : _Head(std::forward<_UHead>(__h)) { }\n\n// 整个调用链如下：\n#0  Foo::Foo (this=0x7fffffffe068, rhs=...) at main.cc:13\n#1  0x0000555555555a8c in std::_Head_base<1ul, Foo, true>::_Head_base<Foo&> (this=0x7fffffffe068, __h=...) at /usr/include/c++/9/tuple:87\n#2  0x00005555555559e8 in std::_Tuple_impl<1ul, Foo>::_Tuple_impl<Foo&> (this=0x7fffffffe068, __head=...) at /usr/include/c++/9/tuple:349\n#3  0x00005555555558f3 in std::_Tuple_impl<0ul, Foo, Foo>::_Tuple_impl<Foo&, Foo&, void> (this=0x7fffffffe068, __head=...)\n    at /usr/include/c++/9/tuple:218\n#4  0x0000555555555815 in std::tuple<Foo, Foo>::tuple<Foo&, Foo&, true> (this=0x7fffffffe068, __a1=..., __a2=...) at /usr/include/c++/9/tuple:969\n#5  0x00005555555556fc in std::_Bind<void (*(Foo, Foo))(Foo const&, Foo const&)>::_Bind<Foo&, Foo&>(void (*&&)(Foo const&, Foo const&), Foo&, Foo&)\n    (this=0x7fffffffe060, __f=@0x7fffffffe010: 0x5555555551ea <add(Foo const&, Foo const&)>) at /usr/include/c++/9/functional:467\n#6  0x0000555555555571 in std::bind<void (&)(Foo const&, Foo const&), Foo&, Foo&> (__f=\n    @0x5555555551ea: {void (const Foo &, const Foo &)} 0x5555555551ea <add(Foo const&, Foo const&)>) at /usr/include/c++/9/functional:812\n#7  0x00005555555552b7 in main (argc=1, argv=0x7fffffffe198) at main.cc:30\n```\n\n### 左值引用和右值引用区别  \n 左值引用，也就是“常规引用”，不能绑定到要转换的表达式，字面常量，或返回右值的表达式。而右值引用恰好相反，可以绑定到这类表达式，但不能绑定到一个左值上。\n\n 右值引用就是必须绑定到右值的引用，通过&&获得。右值引用只能绑定到一个将要销毁的对象上，因此可以自由地移动其资源。\n\n 返回左值的表达式包括返回左值引用的函数及赋值，下标，解引用和**前置递增/递减运算符**；\n 返回右值的包括返回非引用类型的函数及算术，关系，位和后置递增/递减运算符。可以看到左值的特点是有持久的状态，而右值则是短暂的\n ```cpp\n  void func(int&& index, int idx) { \n    if(idx > 3) return;\n\n    func(index++, ++idx);  // Ok \n    func(++index, ++idx);  // Error\n\n    std::cout<< std::is_rvalue_reference<decltype(index)>::value <<std::endl;\n  }\n ```\n 在上面的代码中，`++index` 产生的是左值，而 `index++` 产生的是右值。因此上面的可以编译成功，下面的编译不过。\n\n【注意】：已经命名的右值，编译器会认为是左值。\n### 左值与右值\n变量都是左值，即使变量是右值引用类型\n```cpp\n  int&& ref1 = 1;     //  ok \n  int&& ref2 = ref1; // error \n```\n因为 `ref2` 是右值引用类型的变量，不能将其绑定到左值`ref1`上。**`ref1` 与 `ref2` 是左值，因为他们都是变量，但是变量类型是右值引用类型，即这两个变量只能绑定到右值上**。\n### 四种类型转换总结\n#### *static_cast*\n\n+ 基类和子类之间转换：  \n    `static_cast` 的使用，当且仅当类型之间可隐式转化时，`static_cast` 的转化才是合法的。有一个例外，那就是类层次间的向下转型，`static_cast` 可以完成类层次间的向下转型，但是向下转型无法通过隐式转换完成。\n    \n    + 向上转换安全：子类指针转换成父类指针是安全的;\n    \n    + 向下转换不安全：父类指针转换成子类指针是不安全的。\n    \n    + `static_cast`不能进行无关类型(如非基类和子类)指针之间的转换。\n      \n      ```cpp\n    class Base{ };\n    class Derived : public base{ /**....*/ };\n      \n        Base*    B = new Base;\n        Derived* D = static_cast<Drived*>(B); // 不安全\n      ```\n      为什么不安全？   \n      \n      D指向本质上还是B的对象模型，D指向的内存模型中可能存在B没有的成员变量。如果 `D->foo()` 中使用了 `D` 的成员变量，那么这个函数调用就是不安全的。因此，向下转换是安全的。\n    \n+ `static_cast` 还可以在左值和右值之间显示地转换。虽然不能隐式地将左值转换为右值，但是可以使用`static_cast`显示地将左值转换为右值。\n+ 基本数据类型转换: `enum`, `int`, `char`, `float`等。安全性问题由开发者来保证。\n+ 把空指针转换成目标类型的空指针  \n    ```cpp\n        int* iptr = static_cast<int*>(::malloc(sizoef(int)));\n    ```\n+ 把任何类型的表达式转换成void类型：`static_cast<void>(iptr)`\n+ `static_cast` 不能去掉类型的`const、volitale`属性(用`const_cast`)\n+ 隐式转换都建议使用 `static_cast` 进行标明和替换\n\n#### *dynamic_cast*\n\n专门用于将多态基类的指针或引用强制转换为派生类的指针或引用，而且能够检查转换的安全性。对于不安全的指针转换，转换结果返回 nullptr 指针。  \n\n使用特点：　　\n+ 基类必须要有虚函数，因为`dynamic_cast`是运行时类型检查，需要运行时类型信息，而这个信息是存储在类的虚函数表中，只有一个类定义了虚函数，才会有虚函数表　　\n\n+ 对于下行转换，`dynamic_cast`是安全的（当类型不一致时，转换过来的是空指针），而`static_cast`是不安全的（当类型不一致时，转换过来的是错误意义的指针，可能造成踩内存，非法访问等各种问题), `reinterpreter_cast` 下行转换是可以转换，但是不安全。　\n\n+ 相同基类不同子类之间的交叉转换，转换结果是是 nullptr\n  ```cpp\n    class Base\n    {\n    public: \n      virtual void fun() { } \n    };\n\n    class Drived : public base {\n    public:\n      int i;\n    };\n\n    Base     *Bptr = new Drived()；//语句0\n    Derived *Dptr1 = static_cast<Derived*>(Bptr);  //语句1；\n    Derived *Dptr2 = dynamic_cast<Derived*>(Bptr); //语句2；\n  ```\n此时语句1和语句2都是安全的，因为此时 `Bptr` 确实是指向的派生类的内存模型，所以两个类型转换都是安全的。`Dptr1` 和 `Dptr2` 可以尽情访问 `Drived` 类中的成员，绝对不会出问题。但是如果此时语句0更改为如下表达：\n  ```cpp\n    Base* Bptr = new Base(); `\n  ```\n  那么 `Bptr` 指向的是`Base`对象内存模型。因此语句1是不安全的，因为如果访问子类的数据成员，其行为将是未定义。而语句2返回的是 `nullptr`，更加直观的告诉用户不安全。\n\n#### *reinterpreter_cast*\n\n用于进行各种不同类型的指针之间、不同类型的引用之间以及指针和能容纳指针的整数类型之间的转换。转换时执行的是**逐 `byte` 复制**的操作。\n\n+ `reinterpret_cast`是从底层对数据仅仅进行重新解释，但没有进行二进制的转换，依赖具体的平台，可移植性差；　　\n+ `reinterpret_cast`可以将整型转换为指针，也可以把指针转换为数组；　　\n+ `reinterpret_cast`可以在指针和引用里进行肆无忌惮的转换；\n\n#### *const_cast*  \n\n+ 常量指针转换为非常量指针， 并且仍然指向原来的对象　　\n+ 常量引用被转换为非常量引用，并且仍然指向原来的对象\n\n### 自己实现一个非侵入式的智能指针\n```cpp\n// RAII 技术封装  \nclass RefCount {\npublic:\n      RefCount() : reference_{0} \n      { }\n\n      ~RefCount() { \n          this->decrementRef();\n      }\n\n      void IncrementRef()\n      {\n          ++reference_;\n      }\n\n      bool decrementRef()\n      {\n          if (--reference_ == 0) {\n            delete this;\n            return true;\n          }\n          return false;\n      }\n      \n      int64_t use_count() {\n          return reference_;\n      }\n\n  private:\n      std::atomic<int64_t> reference_;\n  };\n\n\n  template <typename T>\n  class SharedPtr\n  {\n  public:\n      SharedPtr() : ptr_(nullptr) {}\n\n      explicit SharedPtr(T* ptr) \n      : ptr_(ptr),\n        ref_(new RefCount)\n      {\n          if (ref_) ref_->IncrementRef();\n      }\n\n      SharedPtr(const SharedPtr& other) \n      : ptr_(other.ptr_),\n        ref_(other.ref_)\n      {\n          if (ref_) ref_->IncrementRef();\n      }\n\n      SharedPtr(SharedPtr&& other) noexcept {\n          ptr_ = other.ptr_;\n          ref_ = other.ref_;\n          other.ptr_ = nullptr;\n          other.ref_ = nullptr;\n      }\n\n      SharedPtr& operator=(const SharedPtr& other) {\n          if (this == &other || *this == other) \n              return *this;\n\n          reset();\n          ptr_ = other.ptr_;\n          ref_ = other.ref_;\n          ref_->IncrementRef();\n          return *this;\n      }\n\n      SharedPtr& operator=(SharedPtr&& other) noexcept {\n          if (this == &other || *this == other) return *this;\n\n          reset();\n          ptr_ = other.ptr_;\n          ref_ = other.ref_;\n          \n          other.ptr_ = nullptr;\n          other.ref_ = nullptr;\n\n          return *this;\n      }\n\n      ~SharedPtr() \n      {\n          if (ref_) this->decrementRef(); \n      }\n\n      T& operator*()  const { return *ptr_; }\n      T* operator->() const { return ptr_; }\n\n      explicit operator bool() const { return !!ptr_; }\n\n      T* get() const { return ptr_; }\n\n      void reset() {\n          if (ptr_) {\n              this->decrementRef();\n              // ptr_ = nullptr;\n          }\n      }\n\n      void decrementRef() { \n          if(ref_ && ptr_) { \n              if(ref_->decrementRef()) { \n                  delete ptr_;\n                  ptr_ = nullptr;\n              }\n          }\n      }\n\n      int64_t use_count() {\n          return  ref_->use_count();\n      }\n\n      bool unique() {\n          return use_count() == 1;\n      }\n\n      void swap(SharedPtr & other) {\n          std::swap(ptr_, other.ptr_);\n          std::swap(ref_, other.ref_);\n      }\n\n      friend inline bool operator==(SharedPtr const& lhs, SharedPtr const& rhs) {\n          return lhs.ptr_ == rhs.ptr_;\n      }\n\n      friend inline bool operator!=(SharedPtr const& lhs, SharedPtr const& rhs) {\n          return lhs.ptr_ != rhs.ptr_;\n      }\n\n      friend inline bool operator<(SharedPtr const& lhs, SharedPtr const& rhs) {\n          return lhs.ptr_ < rhs.ptr_;\n      }\n\n  private:\n      T*        ptr_; \n      RefCount* ref_;\n  };\n\n  int main(int argc, char const *argv[]) {\n    \n      SharedPtr<int> iptr (new int);\n      SharedPtr<int> iptr2(iptr);\n      SharedPtr<int> iptr3(std::move(iptr));\n      SharedPtr<int> iptr4 = iptr2;\n      SharedPtr<int> iptr5 = std::move(iptr3);\n\n      std::cout<<iptr5.use_count()<<std::endl; // 3\n      return 0;\n  }\n```\n### 迭代器失效的场景\n+ 序列式容器\n    序列式容器会失效的原因是因为其存储都是连续的，因此删除或者插入一个元素都有可能导致其他元素的迭代器失效。\n  \n  + `vector`\n    \n      + 在遍历时，执行`erase`会导致删除节点之后的全部失效\n      + 在`push_back`时，之前的`end()`操作得到的迭代器失效\n    + `insert/push_back`导致`capacity()`改变，那么之前的`first()/end()`得到的迭代器会失效\n  + `insert`一个元素，如果空间没有分配，那么插入节点之前的迭代器位置有效，之后的失效。\n    \n      简而言之：导致内存分配的全会失效，导致元素移动的会局部失效\n  + `deque`\n    + 在首尾添加元素，会导致迭代器失效，但是指针、引用不会失效\n    + 其余位置插入元素，迭代器、指针、引用都是失效\n    + 在首尾之外的位置删除元素，那么其他位置的迭代器都失效\n    + 在首尾删除元素，只是会导致被指向的删除元素的迭代器失效\n+ 关联式容器\n  + 基于哈希表实现的*std::unordered_map/std::set* 导致迭代器失效，一般是插入元素导致 *reshash* 产生，如果是删除只是会导致被删除元素的迭代器失效。\n    ![case](image/unorder_map非法化.jpg)\n###  *std::unordered_map*\n#### 底层实现及其解决 *hash* 冲突方法 \n\n*std::unorder_map*  解决冲突方式是 **拉链法**（数组的每个元素都连着一个链表？）：将所有产生冲突的关键字所对应的数据全部存储在同一个线性链表中（*bucket*）。这个方法解决数据存储位置发生冲突的哈希表，整个存储结构如图 1 所示。\n\n<div align=center><img src=./image/hashtable.gif> </div>\n\n  其中 p_i表示存储的各个键值对。\n\n当使用无序容器存储键值对时，会先申请一整块连续的存储空间，但此空间并不用来直接存储键值对，而是存储各个链表的头指针，各键值对真正的存储位置是各个链表的节点。`STL` 标准库默认选用`vector`容器存储各个链表的头指针。`STL` 标准库中，将图 1 中的各个链表称为桶 *bucket*，每个桶都有自己的编号（从 0 开始）。当有新键值对存储到无序容器中时，整个存储过程分为如下几步：\n  + 将该键值对中 `key` 的值带入设计好的哈希函数，会得到一个哈希值: *H = hash(key)*；\n  + 将 H 和无序容器拥有桶的数量 n 做整除运算（即` H % n`），该结果即表示应将此键值对存储到的桶的编号；\n  + 建立一个新节点存储此键值对，同时将该节点链接到相应编号的桶上\n\n **其他解决冲突的方法**\n  + 开放地址法：\n    $$\n    H =(hash(key) + d)  \\%  m\n    $$\n    \n    \n     其中`m`是哈希表的表长，`d`是一个增量，当产生冲突时，选择以下三种方法一种获取d的值，然后计算，直到计算出的*hash* 值不存在冲突。\n    \n    +  线性探测法：d = 1,2,3,...\n    +  二次探测法：d = 12,-12, 22, -22...\n    +  伪随机数探测法: d = 伪随机数\n    \n  + 再哈希法`rehasp`  \n    当通过哈希函数求得的哈希地址同其他关键字产生冲突时，使用另一个哈希函数计算，直到冲突不再发生\n\n#### rehashp\n\n上述的拉链法解决了哈希冲突的问题，但是当插入元素很多，产生了严重哈希冲突时，就会导致某个链表长度越来越长，进而导致哈希表的查找就会退化为链表，效率降低为O(n)的时间复杂度。\n\n 哈希表存储结构还有一个重要的属性，称为负载因子`load factor`，用于衡量容器存储键值对的空/满程度：即负载因子越大，意味着容器越满，即各链表中挂载着越多的键值对，这无疑会降低容器查找目标键值对的效率；反之，负载因子越小，容器肯定越空，但并不一定各个链表中挂载的键值对就越少。\n\n>  负载因子的计算方法为：负载因子 = 容器存储的总键值对 / 桶数\n\n` STL` 中默认情况下，无序容器的最大负载因子为 1.0。如果操作无序容器过程中，使得最大复杂因子超过了默认值，则容器会自动增加桶数，并重新进行哈希，以此来减小负载因子的值。需要注意的是，此过程会导致容器迭代器失效，但指向单个键值对的引用或者指针仍然有效。\n\n因此当插入元素过多，使得负载因子的大于1.0，就会产生*rehash*行为，来改善即将下降的效率。\n\n **STL中的 *unordered_map* 的 *rehash* 策略**\n一下代码节选自g++的*STL*库：\n\n```cpp\n// __n_bkt is current bucket count, __n_elt is current element count,\n// and __n_ins is number of elements to be inserted.  Do we need to\n// increase bucket count?  If so, return make_pair(true, n), where n\n// is the new bucket count.  If not, return make_pair(false, 0).\nstd::pair<bool, size_t>\n _M_need_rehash(size_t __n_bkt, size_t __n_elt, size_t __n_ins) noexcept {\n  if (__n_elt + __n_ins >= _M_next_resize) {\n      \n    long double __min_bkts = (__n_elt + __n_ins) / (long double)_M_max_load_factor;\n      \n    if (__min_bkts >= __n_bkt)\n      //  这个是需要rehash 时返回的策略\n      return std::make_pair(true, \n                            _M_next_bkt(std::max<size_t>(__builtin_floor(__min_bkts) + 1,\n                                                         __n_bkt * _S_growth_factor)));\n\n        _M_next_resize  = __builtin_floor(__n_bkt * (long double)_M_max_load_factor);\n\n        return std::make_pair(false, 0);\n      }\n     \n      return std::make_pair(false, 0);\n    }\n\nsize_t _M_next_bkt(size_t __n) noexcept {\n    \n  const auto __max_width = std::min<size_t>(sizeof(size_t), 8);           // 8 个字节\n  const auto __max_bkt   = size_t(1) << (__max_width * __CHAR_BIT__ - 1); // 2 ^ 63\n  size_t __res           = __clp2(__n);        // 计算大于等于 n 的最小的2的幂\n\n  if (__res == __n) __res <<= 1;\n  if (__res == 0) __res = __max_bkt;\n\n  // Set next resize to the max value so that we never try to rehash again\n  // as we already reach the biggest possible bucket number.\n  // Note that it might result in max_load_factor not being respected.\n  if (__res == __max_bkt)\n    _M_next_resize = size_t(-1);\n  else\n    _M_next_resize = __builtin_ceil(__res * (long double)_M_max_load_factor);\n\n  return __res;\n}\n```\n其中，在这个类的前面有定义：\n>  + ***_M_max_load_factor*** 初始化为 1.0\n>  + ***static const size_t _S_growth_factor = 2;***\n\n整个扩容的策略大致是按照2倍的策略增长，但是并不严格按照。在MSVC中按照的是8倍的扩充策略。\n\n#### 多线程下的 *std::unordered_map* \n`STL`中的 哈希表 是线程不安全的（其实 `STL` 库都是线程不安全的）。 比如两个线程同时向 *std::unordered_map* 中插入数据，当发生*rehash*时，如果不加锁，可能导致两个线程都会产生*rehash*。\n\n**如何优化 多线程读写操作？这里要借鉴下java的分段锁。**\n\n#### 参考链接\n\n  + [hash](http://c.biancheng.net/view/3437.html)\n  + [std::unordered_map底层原理](http://c.biancheng.net/view/7235.html)\n  + g++ 中 *std::unordered_map* 的实现\n\n###  *map* 与 红黑树.\n\n+ 红黑树的规则\n\n  1. 树根始终为黑色\n  2. 外部节点均为黑色\n  3. 其余节点若为红色，则器孩子节点必为黑色\n  4. 从任一外部外部节点到根节点的沿途，黑色节点的数目相等\n\n  条件1和2说明，红色节点均是内部节点，其父节点及左、右孩子节点必然存在；另外条件3说明，红节点之父必为黑色，因此树中任一通路都不含相邻的红节点\n\n+ 红黑树的效率为什么比AVL树高?如果只有查询操作哪种树的效率高?\n  \n  红黑树的效率高,是因为不需要像`AVL`树那样,为了维护高度平衡性,而不断地动态调整以维护左右子树高度差不超过1.红黑树降低了对平衡度的要求,以减少每次插入/删除操作时的动态调整次数.但是就查询效率而言,是不如`AVL`树的.\n\n## 工具\n####  如何进行性能排查？找出性能瓶颈？性能测试？有什么工具：\n+ *valgrind* :可以查找代码问题\n####  GDB学习参考链接\n+ [GDB学习1](https://blog.csdn.net/haoel/article/details/2879)\n+ [GDB学习2](https://blog.csdn.net/haoel/article/details/2880)\n+ [GDB学习3](https://blog.csdn.net/haoel/article/details/2881)\n+ [GDB学习4](https://blog.csdn.net/haoel/article/details/2882)\n+ [GDB学习5](https://blog.csdn.net/haoel/article/details/2883)\n+ [GDB学习6](https://blog.csdn.net/haoel/article/details/2884)\n+ [GDB学习7](https://blog.csdn.net/haoel/article/details/2885)\n","content":"<h2 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h2><h4 id=\"RAII\"><a href=\"#RAII\" class=\"headerlink\" title=\"RAII\"></a>RAII</h4><p>全称是 <strong>R</strong>esource <strong>A</strong>cquisition <strong>I</strong>s <strong>I</strong>nitialization ， 即“资源获取即初始化”，其核心是把资源和对象的生命周期绑定：对象创建获取资源，对象销毁释放资源。这就是的资源也有了生命周期，有了自动回收的功能。<em>lock_guard</em> 都利用了 <em>RAII</em>机制来实现。</p>\n<p>防止内存泄露的方式有 <strong>R</strong>AII、智能指针。</p>\n<h4 id=\"大端和小端\"><a href=\"#大端和小端\" class=\"headerlink\" title=\"大端和小端\"></a>大端和小端</h4><ul>\n<li><p>大端就是高字节在高地址，低字节在低地址。 </p>\n</li>\n<li><p>小端就是低字节在高地址，高字节在低地址。</p>\n <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 大端小端区分  </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isBigEndian</span><span class=\"params\">()</span> </span>&#123;  </span><br><span class=\"line\">     <span class=\"class\"><span class=\"keyword\">union</span> <span class=\"title\">NUM</span>  &#123;</span>  </span><br><span class=\"line\">         <span class=\"keyword\">int</span> a;  </span><br><span class=\"line\">         <span class=\"keyword\">char</span> b; <span class=\"comment\">// 如果是大端 b 就是最高位 ，小端就是最低位  </span></span><br><span class=\"line\">     &#125;num;  </span><br><span class=\"line\"></span><br><span class=\"line\">     num.a = <span class=\"number\">0x1234</span>;  </span><br><span class=\"line\">     <span class=\"keyword\">if</span>(num.b == <span class=\"number\">0x12</span>)  </span><br><span class=\"line\">     &#123;  </span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;  </span><br><span class=\"line\">     &#125;  </span><br><span class=\"line\"></span><br><span class=\"line\">     <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;  </span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>大端小端转换</p>\n <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//无符号整型16位  </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">uint16_t</span> <span class=\"title\">bswap_16</span><span class=\"params\">(<span class=\"keyword\">uint16_t</span> x)</span>  </span>&#123;  </span><br><span class=\"line\">    <span class=\"keyword\">return</span> ((x &amp; <span class=\"number\">0x00ff</span>) &lt;&lt; <span class=\"number\">8</span>) | (x &amp; <span class=\"number\">0xff00</span>) &gt;&gt; <span class=\"number\">8</span>) ;  </span><br><span class=\"line\">&#125;  </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//无符号整型32位</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">uint32_t</span> <span class=\"title\">bswap_32</span><span class=\"params\">(<span class=\"keyword\">uint32_t</span> x)</span> </span>&#123;  </span><br><span class=\"line\">    <span class=\"keyword\">return</span> ((x &amp; <span class=\"number\">0xff000000</span>) &gt;&gt; <span class=\"number\">24</span>)| ((x &amp; <span class=\"number\">0x00ff0000</span>) &gt;&gt; <span class=\"number\">8</span>) | \\</span><br><span class=\"line\">           ((x &amp; <span class=\"number\">0x0000ff00</span>) &lt;&lt; <span class=\"number\">8</span>) | ((x &amp; <span class=\"number\">0x000000ff</span>) &lt;&lt; <span class=\"number\">24</span>) ;  </span><br><span class=\"line\">&#125; </span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"生成可执行文件过程及各个过程完成的事情：\"><a href=\"#生成可执行文件过程及各个过程完成的事情：\" class=\"headerlink\" title=\"生成可执行文件过程及各个过程完成的事情：\"></a>生成可执行文件过程及各个过程完成的事情：</h4><ol>\n<li>预编译处理(.c) : 将源文件<code>main.cc</code> 翻译成一个ASCII码的中间件文件 <code>main.i</code>  </li>\n<li>编译、优化程序（.s、.asm）： 将 <code>main.i</code>文件 翻译成一个 ASCII 汇编文件 <code>main.s</code>  </li>\n<li>汇编程序(<code>.obj、.o、.a、.ko</code>)  ：运行汇编器，将 <code>main.s</code> 翻译成一个可重定位目标文件<code>main.o</code>   </li>\n<li>链接程序（<code>.exe、.elf、.axf</code>等） ： 运行链接器，将<code>main.o</code> 中使用到的目标文件组合起来，创建一个可执行的文件<br> 为了构造可执行文件，这链接器必须完成两个主要任务：  <ul>\n<li>符号解析  ：目的是将每个符号引用正好和一个符号定义关联起来。每个符号对应于一个函数、全局变量、static变量等</li>\n<li>重定位：对于由编译器和汇编器生成的从地址0开始的代码和数据节，链接器将每个符号定义与一个内存位置关联起来，从而重定位这些数据节，然后修改所有对这些符号的引用，使得他们<strong>指向内存位置</strong>。<h4 id=\"静态库与动态库\"><a href=\"#静态库与动态库\" class=\"headerlink\" title=\"静态库与动态库\"></a>静态库与动态库</h4></li>\n</ul>\n</li>\n</ol>\n<p><strong>根本区别</strong>：是在编译期还是在是执行期完成链接、装入动作。链接的主要内容就是把各个模块之间相互引用的部分都处理好，<br>使得各个模块之间能够正确地衔接</p>\n<ul>\n<li><p>静态库：之所以叫做静态库，是因为在<strong>链接阶段</strong>，当使用链接器将由汇编生成的目标文件构造成一个可执行的输出文件时，它只是<strong>复制静态库中里这个即将生成的可执行文件所引用到的目标模块</strong>。静态库特点总结：</p>\n<ul>\n<li><p>静态库对函数库的链接是放在编译时期完成的。</p>\n</li>\n<li><p>程序在运行时与函数库再无瓜葛，移植方便。</p>\n</li>\n<li><p>浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。</p>\n</li>\n</ul>\n</li>\n<li><p>动态库：动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。<strong>不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例</strong>，规避了空间浪费问题。动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，<strong>增量更新</strong></p>\n<pre><code>+  动态库把对一些库函数的**链接载入**推迟到程序运行的时期。\n</code></pre><ul>\n<li><p>可以实现进程之间的资源共享。（因此动态库也称为共享库）</p>\n</li>\n<li><p>将一些程序升级变得简单。</p>\n</li>\n<li><p>甚至可以真正做到链接载入完全由程序员在程序代码中控制（<strong>显示调用</strong>）。</p>\n<h4 id=\"编译型语言和解释型语言的区别\"><a href=\"#编译型语言和解释型语言的区别\" class=\"headerlink\" title=\"编译型语言和解释型语言的区别\"></a>编译型语言和解释型语言的区别</h4></li>\n<li>编译型语言在运行前就生成可执行文件，运行时就没有编译了</li>\n<li>解释型语言在运行的时候才翻译<h4 id=\"static、extern、全局变量\"><a href=\"#static、extern、全局变量\" class=\"headerlink\" title=\"static、extern、全局变量\"></a>static、extern、全局变量</h4></li>\n<li>static全局变量与普通的全局变量有什么区别：static全局变量只初使化一次，防止在其他文件单元中被引用;</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>static局部变量和普通局部变量有什么区别：static局部变量只被初始化一次，下一次依据上一次结果值；</p>\n</li>\n<li><p>程序的局部变量存在于（堆栈）中，全局变量存在于（静态区 ）中，动态申请数据存在于（ 堆）中。</p>\n<p>extern全局变量(用extern修饰的变量只是说明该变量在其他地方定义，所以在其他地方一定要用明确的定义如int a，并且不能用static修饰）、static全局变量和static局部变量的生存期都是“永久”，区别只是可见域不同。extern全局变量可见区域是工程，static全局变量可见区域是文件，而static局部变量的可见区域是块。</p>\n</li>\n</ul>\n<h4 id=\"volatile\"><a href=\"#volatile\" class=\"headerlink\" title=\"volatile\"></a>volatile</h4><ul>\n<li><p>阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回。</p>\n</li>\n<li><p>阻止编译器调整操作<code>volatile</code>变量的指令顺序。</p>\n<p>注意：即使 <code>volatile</code> 能够阻止编译器调整顺序， 也无法阻止CPU动态调度换序（<code>reorder</code>）</p>\n<h4 id=\"assert\"><a href=\"#assert\" class=\"headerlink\" title=\"assert\"></a><em>assert</em></h4></li>\n</ul>\n<p>断言主要用于检查逻辑上不可能的情况。例如，它们可用于检查代码在开始运行之前所期望的状态，或者在运行完成后检查状态。<strong>与正常的错误处理不同，断言通常在运行时被禁用</strong>。</p>\n<p><em>assert</em> 是个宏而非函数，如果条件返回错误，则会抛出异常，最后会调用 <em>abort</em> 终止程序，发送的是 <em>SIGABRT</em>，可以通过宏 <strong><em>NODEBUG</em></strong> 来关闭 <em>assert</em>，但是需要设置在源代码的开头。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> assert(expr)\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">     (static_cast <span class=\"meta-string\">&lt;bool&gt;</span> (expr)\t\t\t\t\t\t \\</span></span><br><span class=\"line\"><span class=\"meta\">      ? void (0)\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">      : __assert_fail (#expr, __FILE__, __LINE__, __ASSERT_FUNCTION))</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">extern</span> </span><br><span class=\"line\"><span class=\"keyword\">void</span> __assert_fail (<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *__assertion, </span><br><span class=\"line\">                    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *__file,</span><br><span class=\"line\">                    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> __line, </span><br><span class=\"line\">                    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *__function)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">     __THROW __attribute__ ((__noreturn__));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>在判断失败时会调用 <em>__assert_fail</em> 来抛出异常，在C++中异常的底层是用 <em>abort</em> 实现的。</p>\n<h4 id=\"指针和引用的区别\"><a href=\"#指针和引用的区别\" class=\"headerlink\" title=\"指针和引用的区别\"></a>指针和引用的区别</h4><ul>\n<li>目的不同：指针是为了兼容 C 而存在，引用是为了操作符重载而存在</li>\n<li>在声明引用的的同时就要对它初始化，并且一经声明就不可以再和其它对象绑定在一起了。</li>\n<li>引用更像是常量指针，只能改变绑定对象的值，不能改变绑定的对象。</li>\n<li>引用它一定不为空，因此相对于指针，它不用检查它所指对象是否为空，更加安全也增加了效率<h4 id=\"new、malloc\"><a href=\"#new、malloc\" class=\"headerlink\" title=\"new、malloc\"></a>new、malloc</h4></li>\n<li><p>new：不仅仅是分配内存，还包括了对象类型转换以及初始化</p>\n<ul>\n<li>是先调用<em>operator new</em>分配内存空间，返回是<em>void</em> *类型；</li>\n<li>再将返回类型转换为指定类型，再调用类的构造函数。</li>\n<li>如果内存空间不足，会抛出<em>std::bad_alloc</em>异常</li>\n</ul>\n</li>\n<li><p>malloc</p>\n<ul>\n<li>返回 <code>void*</code>类型，并且在内存不足时，返回<code>NULL</code>指针</li>\n<li>当开辟的空间小于 <code>128K</code>时，调用<code>brk()</code> 函数，<code>malloc</code>的底层实现是系统调用函数 <code>brk()</code></li>\n<li><p>当开辟的空间大于 <code>128K</code>时，<code>mmap()</code> 系统调用函数来在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟</p>\n<p><code>operator new</code> 底层也是由<code>malloc</code>实现。 <code>malloc</code>底层是由<code>slab</code>实现。</p>\n<p>对于<code>POD</code>类型对象，使用<code>new</code> 创建的对象，也是可以使用<code>free</code>来释放销毁对象，原因就是在于这个对象是<code>POD</code> 类型。没有其他资源需要释放，或者文件描述符需要关闭，因此可以不调用析构函数而使用<code>free</code>来替代<code>delete</code>。尽管可以，但是不推荐，这样的代码并不健壮。</p>\n<p><code>new</code> 在C++里是可以用 <code>malloc + placement</code> 替代的，或者说等效于这两个。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 更好的展示 malloc 与 new 的区别与联系</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span> </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">Foo</span>(<span class=\"keyword\">int</span> a=<span class=\"number\">0</span>, <span class=\"keyword\">int</span> b=<span class=\"number\">0</span>): <span class=\"built_in\">a</span>(a),<span class=\"built_in\">b</span>(b) &#123; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ~<span class=\"built_in\">Foo</span>() &#123; std::cout&lt;&lt;<span class=\"string\">&quot;dtor&quot;</span>&lt;&lt;std::endl; &#125;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> b;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// new = placement new + malloc</span></span><br><span class=\"line\">    Foo* foo = <span class=\"keyword\">static_cast</span>&lt;Foo*&gt;(::<span class=\"built_in\">malloc</span>(<span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(Foo)));</span><br><span class=\"line\">    <span class=\"keyword\">new</span>(foo)<span class=\"built_in\">Foo</span>(<span class=\"number\">1</span>,<span class=\"number\">1</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// delete</span></span><br><span class=\"line\">    foo-&gt;~<span class=\"built_in\">Foo</span>();</span><br><span class=\"line\">    ::<span class=\"built_in\">free</span>(foo);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 运行结束，无内存泄露</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>除了<code>new</code>和<code>malloc</code>，还有什么方式可以在堆中分配内存么，以及怎么释放？<br> <strong><code>mmap</code>，<code>munmap</code></strong></p>\n<h4 id=\"多态\"><a href=\"#多态\" class=\"headerlink\" title=\"多态\"></a>多态</h4><p>多态的三个条件：继承，重写（<code>override</code>），基类引用指向派生类对象。</p>\n</li>\n<li><p>静态多态   </p>\n<ul>\n<li><p>重载，在编译时期就可以确定</p>\n</li>\n<li><p>模板技术：比如 <code>CRTP</code>，它是使用子类来作为基类的模板参数，在基类中调用子类的方法。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> Derived&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Base</span>&#123;</span> </span><br><span class=\"line\">      <span class=\"comment\">// 其他忽略</span></span><br><span class=\"line\">    <span class=\"function\">Derived&amp; <span class=\"title\">convert</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123; </span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> <span class=\"keyword\">static_cast</span>&lt;Derived&amp;&gt;(*<span class=\"keyword\">this</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>这个也从侧面说明<code>static_cast</code> 可以让子类转换为父类，要使得保证安全，前提是转换后调用子类的方法中没有使用子类独有的数据成员</p>\n</li>\n</ul>\n</li>\n<li><p>动态多态<br>运行时才确定调用的是哪个函数。核心关键在于虚函数：子类重写基类的虚方法，定义指向子类对象的基类指针。这个基类指针的行为直到运行时才能确定调用的是子类还是基类的方法，这就是多态。</p>\n<p>实现原理是：虚函数表和虚函数指针<code>vptr</code>。<a href=\"./3.虚拟成员函数.md\">详情</a></p>\n<h4 id=\"重载-overload-和重写-override\"><a href=\"#重载-overload-和重写-override\" class=\"headerlink\" title=\"重载(overload)和重写(override)\"></a>重载(<code>overload</code>)和重写(<code>override</code>)</h4></li>\n<li><p>重载：允许多个同名函数，而这些函数的参数列表不同，函数模板这么实现的，在编译期间就能确定。</p>\n<p>C++函数重载底层实现原理是C++利用 <strong><code>name mangling</code></strong> 技术，来改变函数名，区分参数不同的同名函数。编译器通过函数名和其参数类型识别重载函数。不能仅仅基于不同的返回类型而实现函数重载，是因为经过 <code>name mangling</code> 后得到的函数名与返回值类型是无关的。</p>\n  <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">int</span> a)</span> </span>&#123; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span>&#123; <span class=\"keyword\">return</span> a+b; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>  比如，如上的代码。在经过编译后，得到的符号表如下：</p>\n  <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ objdump -t main.o</span><br><span class=\"line\"><span class=\"number\">0000000000000000</span> g     F .text  <span class=\"number\">000000000000000</span>e _Z4funci</span><br><span class=\"line\"><span class=\"number\">000000000000000</span>e g     F .text  <span class=\"number\">0000000000000018</span> _Z4funcii</span><br><span class=\"line\"><span class=\"number\">0000000000000026</span> g     F .text  <span class=\"number\">0000000000000016</span> main</span><br></pre></td></tr></table></figure>\n<p>  其中， 前缀 <code>__z</code> 是规定，<code>4</code> 是函数名的字符个数，<code>i</code>是第一个函数的参数类型<code>int</code>，<code>ii</code>是第二个函数的参数类型<code>int, int</code>。由此可见也是与返回值无关的。</p>\n</li>\n<li><p>重写<code>override</code>：是指子类重新定义父类的方法，子类的函数名和参数列表以及返回值必须与父类的完全一致。对于虚函数的重写，c++11中新定义了一个关键词<code>override</code>，就是为了让子类在重写父类的虚函数方法时，如何参数列表发生更改可以让编译器报错。</p>\n<h4 id=\"static\"><a href=\"#static\" class=\"headerlink\" title=\"static\"></a><code>static</code></h4><p><code>static</code>变量都是在全局数据区分配内存,声明周期直到程序运行结束.</p>\n</li>\n<li><p>四类<code>static</code></p>\n<ul>\n<li>全局<code>static</code>变量和<code>static</code>函数：都已经被匿名命名空间取代，作用是不能外部文件使用</li>\n<li>局部<code>static</code>变量：在数据区<code>.data</code>分配内存，首次初始化以后，以后调用都不会再初始化，<strong>作用域仅局限于函数</strong>，生命周期直到程序运行结束</li>\n<li>静态数据成员:类对象共享，不能在类声明中定义，是因为在定义时就要分配空间，也是在<code>.data</code> </li>\n<li>静态成员函数:静态成员函数，<strong>不隐含this指针</strong>，不能调用非静态成员函数/变量，可以用作回调函数</li>\n</ul>\n</li>\n<li><p>为什么要引入<code>static</code>  </p>\n<p>需要一个数据对象为整个类而非某个对象服务，同时又不能破坏类的封装特性，因此将静态成员隐藏在类的内部,提供静态成员函数接口，因为共享,可以节省内存。</p>\n<h4 id=\"对象\"><a href=\"#对象\" class=\"headerlink\" title=\"对象\"></a>对象</h4></li>\n<li>空类有六个成员函数<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Empty</span> &#123;</span> </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Empty</span>(); </span><br><span class=\"line\">  <span class=\"built_in\">Empty</span>(<span class=\"keyword\">const</span> Empty&amp; );</span><br><span class=\"line\">  ~<span class=\"built_in\">Empty</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">  Empty&amp; <span class=\"keyword\">operator</span>=(consy Empty&amp; );</span><br><span class=\"line\">  Empty* <span class=\"keyword\">operator</span>&amp; ();               <span class=\"comment\">// 取地址运算符</span></span><br><span class=\"line\">  <span class=\"keyword\">const</span> Empty* <span class=\"keyword\">operator</span>&amp; () <span class=\"keyword\">const</span>;   <span class=\"comment\">// const 类型取地址运算符</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></li>\n<li><p>构造函数可以是虚函数吗？析构函数可以是虚函数吗？</p>\n<p>虚函数对应一个<code>vtbl</code>，这个<code>vtbl</code>实际是存储在对象的内存空间.如果构造函数是虚的,对象的构造就需要<code>vtbl</code>来调用，而虚函数表又是在对象构造后才能建立,因此构造函数不能是虚函数.</p>\n<p>而析构函数在使用多态的继承中一般都是虚析构函数.为的是能正确选择析构函数.</p>\n</li>\n<li><p><code>c++</code>的深拷贝如何理解 </p>\n<p>在类中有指针时并且内部分配资源.经过浅拷贝后,最终会造成资源一次分配,多次释放.造成系统崩溃.</p>\n<h4 id=\"C-中如何在main-函数之前执行操作\"><a href=\"#C-中如何在main-函数之前执行操作\" class=\"headerlink\" title=\"C++中如何在main()函数之前执行操作\"></a>C++中如何在main()函数之前执行操作</h4><p>main函数执行之前，主要就是初始化系统相关资源：</p>\n</li>\n<li>设置栈指针</li>\n<li>初始化静态<code>static</code>变量和<code>global</code>全局变量，即<code>.data</code>段的内容</li>\n<li>将未初始化部分的全局变量赋初值：数值型<code>short</code>，<code>int</code>，<code>long</code>等为<code>0</code>，<code>bool</code>为<code>FALSE</code>，指针为<code>NULL</code>等等，即<code>.bss</code>段的内容     </li>\n<li>全局对象初始化，在<code>main</code>之前调用构造函数</li>\n<li>将main函数的参数<code>argc</code>，<code>argv</code>等传递给<code>main</code>函数，然后才真正运行<code>main</code>函数</li>\n</ul>\n<p><strong>main函数执行之后</strong>：  </p>\n<ul>\n<li>全局对象的析构函数会在main函数之后执行； </li>\n<li><p>可以用 <strong><code>atexit</code></strong> 注册一个函数，它会在main 之后执行;</p>\n<h4 id=\"sizeof-和-strlen-区别\"><a href=\"#sizeof-和-strlen-区别\" class=\"headerlink\" title=\"sizeof  和 strlen 区别\"></a>sizeof  和 strlen 区别</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* str = <span class=\"string\">&quot;name&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(str); <span class=\"comment\">// 取的是指针str的长度，是8</span></span><br><span class=\"line\">    <span class=\"built_in\">strlen</span>(str); <span class=\"comment\">// 取的是这个字符串的长度，不包含结尾的 \\0。大小是4</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"strcpy、strncpy和mmemcpy的区别\"><a href=\"#strcpy、strncpy和mmemcpy的区别\" class=\"headerlink\" title=\"strcpy、strncpy和mmemcpy的区别\"></a>strcpy、strncpy和mmemcpy的区别</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span>* <span class=\"title\">strcpy</span><span class=\"params\">(<span class=\"keyword\">char</span>*  dest, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* src)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span>* <span class=\"title\">strncpy</span><span class=\"params\">(<span class=\"keyword\">char</span>* dest, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* src, <span class=\"keyword\">size_t</span> n)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">memcpy</span> <span class=\"params\">(<span class=\"keyword\">void</span>* dest, <span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* src, <span class=\"keyword\">size_t</span> n)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>前面两个函数是以字符为单位，而<code>mmemcpy</code>是以字节为单位。</p>\n<p><code>strcpy</code>和<code>memcpy</code>主要有以下3方面的区别。  </p>\n<ul>\n<li>复制的内容不同。<code>strcpy</code> 只能复制字符串，而<code>memcpy</code>可以复制任意内容，例如字符数组、整型、结构体、类等。</li>\n<li>复制的方法不同。<code>strcpy</code> 不需要指定长度，它遇到被复制字符的串结束符<code>&#39;\\0&#39;</code>才结束，所以容易溢出。<code>memcpy</code> 则是根据其第3个参数决定复制的长度，而且如果字符串数据中包含<code>&#39;\\0&#39;</code>，只能用<code>memcpy</code>。</li>\n<li>用途不同。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy</li>\n</ul>\n<p><code>strncpy</code> ：在复制字符串时，<code>memcpy</code>更加类似于<code>strncpy</code>。<br><code>strncpy</code>和<code>memcpy</code>很相似，只不过它在一个终止的空字符处停止。当 <code>n &gt; strlen(src)</code> 时，<code>dst[strlen(len)] ~ dst[n-1]</code>都是<code>\\0</code>；当 <code>n&lt;=strlen(src)</code>时，复制前<code>src</code>的n个字符。这里隐藏了一个事实，就是<code>dst</code>指向的内存一定会被写n个字符。</p>\n<p><code>memcpy</code>需要注意的是：   </p>\n<ul>\n<li><code>dest</code> 指针要分配足够的空间，也即大于等于 <code>n</code> 字节的空间。如果没有分配空间，会出现断错误。</li>\n<li><code>dest</code> 和 <code>src</code> 所指的内存空间不能重叠（如果发生了重叠，使用 <code>memmove()</code> 会更加安全）。</li>\n</ul>\n<p>动手实现 <code>memcpy</code>： </p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">myMemcpy</span><span class=\"params\">(<span class=\"keyword\">void</span>* dst, <span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* src, <span class=\"keyword\">size_t</span> n)</span> </span>&#123; </span><br><span class=\"line\">  <span class=\"keyword\">if</span>(dst ==<span class=\"literal\">nullptr</span> || src==<span class=\"literal\">nullptr</span>) <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(src == dst) retrun src;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">char</span>* pdst       = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">char</span>*&gt;(dst); </span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* psrc = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>*&gt;(src);</span><br><span class=\"line\">    <span class=\"comment\">// 发生重叠时，从后向前复制</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(psrc &lt;  pdst &amp;&amp; pdst &lt; psrc + n) </span><br><span class=\"line\">    &#123; </span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=n<span class=\"number\">-1</span>; i &gt;=<span class=\"number\">0</span>; --i)  pdst[i] = psrc[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> </span><br><span class=\"line\">    &#123; </span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i &lt; n; ++i) pdst[i] = psrc[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> pdst;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 使用</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> buf[<span class=\"number\">12</span>]=&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> str[]  = <span class=\"string\">&quot;hello world cpp&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">myMemcpy</span>(str, str+<span class=\"number\">6</span>, <span class=\"number\">9</span>);</span><br><span class=\"line\">    std::cout&lt;&lt;str&lt;&lt;std::endl;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"野指针和悬空指针\"><a href=\"#野指针和悬空指针\" class=\"headerlink\" title=\"野指针和悬空指针\"></a>野指针和悬空指针</h4><p>都是是指向无效内存区域(这里的无效指的是”不安全不可控”)的指针，访问行为将会导致未定义行为。</p>\n<ul>\n<li><p>野指针<br>野指针，指的是没有被初始化过的指针</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123; </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">int</span>* p;     <span class=\"comment\">// 未初始化</span></span><br><span class=\"line\">    std::cout&lt;&lt; *p &lt;&lt; std::endl; <span class=\"comment\">// 未初始化就被使用</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>因此，为了防止出错，对于指针初始化时都是赋值为 <code>nullptr</code>，这样在使用时编译器就会直接报错，产生非法内存访问。</p>\n</li>\n<li><p>悬空指针<br>悬空指针，指针最初指向的内存已经被释放了的一种指针。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123; </span><br><span class=\"line\">  <span class=\"keyword\">int</span> * p = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">int</span>* p2 = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>;</span><br><span class=\"line\">  </span><br><span class=\"line\">  p = p2;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">delete</span> p2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>此时 p和p2就是悬空指针，指向的内存已经被释放。继续使用这两个指针，行为不可预料。需要设置为<code>p=p2=nullptr</code>。此时再使用，编译器会直接保错。</p>\n<p>避免野指针比较简单，但悬空指针比较麻烦。c++引入了智能指针，C++智能指针的本质就是避免悬空指针的产生。</p>\n<h4 id=\"malloc、calloc、realloc\"><a href=\"#malloc、calloc、realloc\" class=\"headerlink\" title=\"malloc、calloc、realloc\"></a>malloc、calloc、realloc</h4><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> *<span class=\"title\">malloc</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> *<span class=\"title\">calloc</span><span class=\"params\">(<span class=\"keyword\">size_t</span> nmemb, <span class=\"keyword\">size_t</span> size)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> *<span class=\"title\">realloc</span><span class=\"params\">(<span class=\"keyword\">void</span> *ptr, <span class=\"keyword\">size_t</span> size)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">free</span><span class=\"params\">(<span class=\"keyword\">void</span> *ptr)</span></span>;</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><code>malloc</code><br>最常用的分配内存函数，分配<code>size</code>个字节。<strong>分配的内存是未初始化的</strong>，如果<code>size==0</code>，要么返回<code>NULL</code>，要么返回一个独一无二的指针，能被<code>free</code>释放。</li>\n<li><p><code>realloc</code>：用来改变已有内存区的大小，而不改变内容。新的大小为参数<code>size</code>，即newsize。</p>\n<ul>\n<li><code>ptr==NULL</code>：<code>realloc(NULL,size)</code>就相当于<code>malloc(size)</code></li>\n<li><code>size==0</code>：<code>realloc(ptr, 0)</code>就相当于<code>free(ptr)</code></li>\n<li><code>ptr==NULL &amp;&amp; size==0</code>：危险。</li>\n<li>如果<code>newsize &gt; oldsize</code>，那么增加的内存是未初始化的，原来的内存内容保持不变，即<code>[ptr, ptr+oldsize)</code>内部不变，<code>[ptr+oldsize, ptr+newsize)</code>是初始化的内容。</li>\n</ul>\n</li>\n<li><p>如果<code>newsize &lt; oldsize</code>，尾部的内容就被切去，释放，只是剩下前面。</p>\n<p><strong>因此 <code>realloc</code>之后不能给这个内存区初始化</strong>.</p>\n</li>\n<li><p><code>calloc</code><br>分配<code>nmemb</code>个元素，每个元素大小是<code>size</code>个字节的连续内存。</p>\n<ul>\n<li>内存大小是<code>nmemb*size</code>的连续内存区</li>\n<li><strong>这块内存被初始化为<code>0</code></strong>。</li>\n</ul>\n<p>如果<code>size==0</code>，要么返回<code>NULL</code>，要么返回一个独一无二的指针，能被<code>free</code>释放。</p>\n<h4 id=\"编译知识\"><a href=\"#编译知识\" class=\"headerlink\" title=\"编译知识\"></a>编译知识</h4><p>为了减小编译依赖加快编译速度和生成二进制文件的大小，C/C++ 项目中一般在 <em>.h 文件对于<em>*指针类型（包括智能指针）</em></em> 尽量使用前置声明，而不是直接包含对应类的头文件。例如：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//Test.h</span></span><br><span class=\"line\"><span class=\"comment\">//在这里使用A的前置声明，而不是直接包含A.h文件</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span>;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Test</span>();</span><br><span class=\"line\">  ~<span class=\"built_in\">Test</span>();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">  A*</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h4 id=\"Copy-Elision\"><a href=\"#Copy-Elision\" class=\"headerlink\" title=\"Copy Elision\"></a>Copy Elision</h4></li>\n</ul>\n<p>g++ 编译器是默认开启 <code>copy elison</code> 选项的。如果要关闭这个选项，使用 <code>-fno-elide-constructors</code>。<code>copy elision</code> 主要包括以下两项内容：</p>\n<font color=yellow>1. 返回值优化</font>  \n\n<p>即通过将返回对象所占空间的直接构造到他们本来要复制/移动到的对象中去，依次来避免拷贝/移动操作。返回值优化包括具名返回值优化 <code>NRVO</code> 与 匿名返回值优化 <code>URVO</code>，区别在于返回值是具名的局部变量（<code>NRVO</code>）还是无名的临时对象（<code>URVO</code>）</p>\n<ul>\n<li><p><code>URVO</code> 与 彻底 <code>Copy elision</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Copyable</span> &#123;</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Copyable</span>() &#123; std::cout&lt;&lt;<span class=\"string\">&quot;default ctor&quot;</span>&lt;&lt;std::endl; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">Copyable</span>(<span class=\"keyword\">const</span> Copyable&amp; rhs) = <span class=\"keyword\">delete</span>; </span><br><span class=\"line\">  <span class=\"built_in\">Copyable</span>(Copyable&amp;&amp; rhs) = <span class=\"keyword\">delete</span>;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Copyable <span class=\"title\">return_urvo_value</span><span class=\"params\">()</span> </span>&#123; </span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> Copyable&#123;&#125;; <span class=\"comment\">// since c++17 ok</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> x  = <span class=\"built_in\">return_urvo_value</span>();</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述代码在C++17中是可以编译通过的。在 C++17 之前，并没有明确的提出在什么情况下，可以彻底进行 <code>Copy Elision</code>（这里的彻底的指的是包括不进行检查是否有可用的 <em>copy/move</em> 构造函数）。在C++17中，对于匿名对象（or 临时对象）不论是传递参数，还是以返回值返回时，都不会调用拷贝/移动构造。因此上面的这段代码在C++17是可以正常编过的，而在C++14会编译出错。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ g++ main.cc -std=c++<span class=\"number\">14</span> -o main &amp;&amp; ./main</span><br><span class=\"line\">main.cc: In function ‘Copyable <span class=\"built_in\">return_urvo_value</span>()’:</span><br><span class=\"line\">main.cc:<span class=\"number\">29</span>:<span class=\"number\">19</span>: error: use of deleted function ‘Copyable::<span class=\"built_in\">Copyable</span>(Copyable&amp;&amp;)’</span><br><span class=\"line\">  <span class=\"number\">29</span> |   <span class=\"keyword\">return</span> Copyable&#123;&#125;;</span><br><span class=\"line\">     |                   ^</span><br><span class=\"line\">main.cc:<span class=\"number\">24</span>:<span class=\"number\">3</span>: note: declared here</span><br><span class=\"line\">  <span class=\"number\">24</span> |   <span class=\"built_in\">Copyable</span>(Copyable&amp;&amp; rhs) = <span class=\"keyword\">delete</span>;</span><br><span class=\"line\">     |   ^~~~~~~~</span><br><span class=\"line\">main.cc: In function ‘<span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span>, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>**)</span>’:</span></span><br><span class=\"line\"><span class=\"function\">main.cc:<span class=\"number\">34</span>:<span class=\"number\">31</span>: error: use of deleted function ‘Copyable::Copyable(Copyable&amp;&amp;)’</span></span><br><span class=\"line\"><span class=\"function\">  <span class=\"number\">34</span> |   auto x  =</span> <span class=\"built_in\">return_urvo_value</span>();</span><br><span class=\"line\">     |                               ^</span><br><span class=\"line\">main.cc:<span class=\"number\">24</span>:<span class=\"number\">3</span>: note: declared here</span><br><span class=\"line\">  <span class=\"number\">24</span> |   <span class=\"built_in\">Copyable</span>(Copyable&amp;&amp; rhs) = <span class=\"keyword\">delete</span>;</span><br><span class=\"line\">     |   ^~~~~~~~</span><br></pre></td></tr></table></figure>\n<p>  自然，只要将上面代码中的如下两行注释掉，即可正常编译，并且 <code>Copyable</code>的构造函数都是只被调用一次，即<code>copy elision</code> 起作用了。 注意：<code>Copyable</code>的复制/移动构造函数必须同时可访问。</p>\n  <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">Copyable</span>(<span class=\"keyword\">const</span> Copyable&amp; rhs) = <span class=\"keyword\">delete</span>; </span><br><span class=\"line\"><span class=\"built_in\">Copyable</span>(Copyable&amp;&amp; rhs) = <span class=\"keyword\">delete</span>;</span><br></pre></td></tr></table></figure>\n<p>  因此，在C++17以前，对于 <code>urvo</code> 不在乎是否返回的对象的复制/移动构造函数是否存在或者可访问，<code>copy elision</code> 都能生效。而在 <code>C++14</code> 之前，返回的对象可以没有复制/移动构造函数，但是必须可以访问。</p>\n</li>\n<li><p><code>nrvo</code><br>在 <code>nrvo</code>时，返回对象的复制/移动构造函数必须可访问。否则编译不过。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Copyable</span> &#123;</span> </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Copyable</span>() &#123; std::cout&lt;&lt;<span class=\"string\">&quot;default ctor&quot;</span>&lt;&lt;std::endl; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">Copyable</span>(<span class=\"keyword\">const</span> Copyable&amp; rhs) = <span class=\"keyword\">delete</span>;</span><br><span class=\"line\">  <span class=\"built_in\">Copyable</span>(Copyable&amp;&amp; rhs) = <span class=\"keyword\">delete</span>;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Copyable <span class=\"title\">return_urvo_value</span><span class=\"params\">()</span> </span>&#123; </span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> Copyable&#123;&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Copyable <span class=\"title\">return_nrvo_value</span><span class=\"params\">()</span> </span>&#123; </span><br><span class=\"line\">  Copyable local;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> local;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> x  = <span class=\"built_in\">return_urvo_value</span>();</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> y  = <span class=\"built_in\">return_nrvo_value</span>();</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如上代码，即使是C++17也会编译失败，必须将如下两行代码注释掉，使得 <code>Copyable</code> 对象的复制/移动构造函数可访问。<code>copy elision</code> 才能生效：<code>Copyable</code> 的默认构造函数只调用一次。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Copyable(const Copyable&amp; rhs) = delete;</span></span><br><span class=\"line\"><span class=\"comment\">// Copyable(Copyable&amp;&amp; rhs) = delete;</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<font color=yellow> 2. 右值拷贝优化 </font>  \n\n<p>右值拷贝优化，当某一个类的临时对象以值传递给该类的另一个对象时，也可以直接利用该临时对象的来避免拷贝/移动操作。在上面的基础上，加上如下的代码：<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">pass_by_value</span><span class=\"params\">(Copyable rhs)</span> </span>&#123; </span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> x  = <span class=\"built_in\">return_urvo_value</span>();</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> y  = <span class=\"built_in\">return_nrvo_value</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">pass_by_value</span>(<span class=\"built_in\">Copyable</span>());</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>最终的输出也是调用默认三次构造函数：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ g++ main.cc -std=c++11 -o main &amp;&amp; ./main</span><br><span class=\"line\">default ctor</span><br><span class=\"line\">default ctor</span><br><span class=\"line\">default ctor</span><br></pre></td></tr></table></figure></p>\n<p>到此，<code>copy elision</code> 基本分析结束。如果想查看没有<code>copy elision</code> 作用下的输出，开启<code>-fno-elide-constructors</code>。</p>\n<h4 id=\"Copy-Elision-作用\"><a href=\"#Copy-Elision-作用\" class=\"headerlink\" title=\"Copy Elision 作用\"></a>Copy Elision 作用</h4><p>对于一些没有拷贝/移动构造的对象，如 <code>unique_ptr</code>、 <code>atomic</code> 等。现在我们能够定义一个工厂函数，即使没有复制或移动构造函数都可以返回一个对象。例如，以下通用工厂函数:<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T, <span class=\"keyword\">typename</span>... Args&gt;</span><br><span class=\"line\"><span class=\"function\">T <span class=\"title\">make_instance</span><span class=\"params\">(Args&amp;&amp; ... args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> T&#123; std::forward&lt;Args&gt;(args)... &#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> i   = make_instance&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"number\">42</span>);</span><br><span class=\"line\">  <span class=\"comment\">// std::unique_ptr 实现了 移动构造函数，因此可以编译成功 </span></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> up = make_instance&lt;std::unique_ptr&lt;<span class=\"keyword\">int</span>&gt;&gt;(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>&#123; <span class=\"number\">42</span> &#125;); </span><br><span class=\"line\">  <span class=\"comment\">// 禁止了复制构造函数，但是也没有实现移动构造函数，因此要到 C++17 才能编译过</span></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> ai = make_instance&lt;std::atomic&lt;<span class=\"keyword\">int</span>&gt;&gt;(<span class=\"number\">42</span>);                  </span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><a href=\"https://blog.csdn.net/davidhopper/article/details/90696200\">参考</a></p>\n<h2 id=\"STL\"><a href=\"#STL\" class=\"headerlink\" title=\"STL\"></a>STL</h2><h3 id=\"std-vector\"><a href=\"#std-vector\" class=\"headerlink\" title=\"std::vector\"></a><em>std::vector</em></h3><ul>\n<li><em>std::vector</em> 在 <em>push_back</em> 以成倍增长可以在均摊后达到O(1)的事件复杂度，相对于增长指定大小的O(n)时间复杂度更好。</li>\n<li>为了防止申请内存的浪费，现在使用较多的有2倍与1.5倍的增长方式，而1.5倍的增长方式可以更好的实现对内存的重复利用，因为更好</li>\n<li><em>std::vector/std::list</em>的实现原理及其使用场景<br><em>std::vector</em>是用连续内存的数组实现的，<em>std::list</em>是通过指针之间的指向实现不连续内存的高效率使用.</li>\n</ul>\n<p><em>std::vector</em> 与 <em>std::list</em></p>\n<ul>\n<li>数组，最大的好处是能以 <em>O(1)</em> 用索引访问任意元素，次要好处是内存布局紧凑，省内存之余还有高缓存一致性（<em>cache coherence</em>）。但数组的缺点是不能快速插入元素，而且我们在解析 <em>JSON</em> 数组的时候，还不知道应该分配多大的数组才合适。</li>\n<li>链表，它的最大优点是可快速地插入元素（开端、末端或中间），但需要以 <em>O(n)</em> 时间去经索引取得内容。如果我们只需顺序遍历，那么是没有问题的。还有一个小缺点，就是相对数组而言，链表在存储每个元素时有额外内存开销（存储下一节点的指针），而且遍历时元素所在的内存可能不连续，令缓存不命中（<em>cache miss</em>）的机会上升。</li>\n</ul>\n<h3 id=\"std-bind\"><a href=\"#std-bind\" class=\"headerlink\" title=\"std::bind\"></a><em>std::bind</em></h3><p>对于如下代码，使用 <em>std::bind</em> 绑定类的成员函数并调用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span> </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Foo</span>()=<span class=\"keyword\">default</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; lhs, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; rhs)</span> </span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123; </span><br><span class=\"line\">    std::cout&lt;&lt; (lhs + rhs)&lt;&lt;std::endl;;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  Foo foo1;</span><br><span class=\"line\">   <span class=\"comment\">// 绑定并且执行</span></span><br><span class=\"line\">  std::<span class=\"built_in\">bind</span>(&amp;Foo::add, &amp;foo1, <span class=\"number\">1</span>, <span class=\"number\">2</span>)();</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>最后内部执行的代码如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Res, <span class=\"keyword\">typename</span> _MemFun, <span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span>... _Args&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Res</span><br><span class=\"line\">__invoke_impl(__invoke_memfun_deref, _MemFun&amp;&amp; __f, _Tp&amp;&amp; <span class=\"keyword\">__t</span>, _Args&amp;&amp;... __args)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> ((*std::forward&lt;_Tp&gt;(<span class=\"keyword\">__t</span>)).*__f)(std::forward&lt;_Args&gt;(__args)...);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中 </p>\n<ul>\n<li><code>_t</code> ，类型是 <code>Foo*&amp;</code> 函数对象指针，指向的<code>foo1</code>对象。</li>\n<li><code>_f</code>是函数指针，指向的就是<code>add</code>成员函数</li>\n<li><code>__invoke_memfun_deref</code>：是用来标记是哪种把绑定方式，比如上述代码中的绑定对象成员函数</li>\n</ul>\n<p>因此，最终，调用可以简化为如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo1.<span class=\"built_in\">add</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>);</span><br></pre></td></tr></table></figure>\n<p>整个<code>std::bind</code> 最终的执行代码如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 直接传入函数调用: std::bind(func, arg1, arg2); 或者静态成员函数</span></span><br><span class=\"line\"><span class=\"comment\">// 很明显，这里没有类对象</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Res, <span class=\"keyword\">typename</span> _Fn, <span class=\"keyword\">typename</span>... _Args&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Res</span><br><span class=\"line\">__invoke_impl(__invoke_other, _Fn&amp;&amp; __f, _Args&amp;&amp;... __args)</span><br><span class=\"line\">&#123; <span class=\"keyword\">return</span> std::forward&lt;_Fn&gt;(__f)(std::forward&lt;_Args&gt;(__args)...); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 上面介绍过</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Res, <span class=\"keyword\">typename</span> _MemFun, <span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span>... _Args&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Res</span><br><span class=\"line\">__invoke_impl(__invoke_memfun_deref, _MemFun&amp;&amp; __f, _Tp&amp;&amp; <span class=\"keyword\">__t</span>, _Args&amp;&amp;... __args)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> ((*std::forward&lt;_Tp&gt;(<span class=\"keyword\">__t</span>)).*__f)(std::forward&lt;_Args&gt;(__args)...);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 下面几种没见过调用</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Res, <span class=\"keyword\">typename</span> _MemFun, <span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span>... _Args&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Res</span><br><span class=\"line\">__invoke_impl(__invoke_memfun_ref, _MemFun&amp;&amp; __f, _Tp&amp;&amp; <span class=\"keyword\">__t</span>, _Args&amp;&amp;... __args)</span><br><span class=\"line\">&#123; <span class=\"keyword\">return</span> (__invfwd&lt;_Tp&gt;(<span class=\"keyword\">__t</span>).*__f)(std::forward&lt;_Args&gt;(__args)...); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Res, <span class=\"keyword\">typename</span> _MemPtr, <span class=\"keyword\">typename</span> _Tp&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Res</span><br><span class=\"line\">__invoke_impl(__invoke_memobj_ref, _MemPtr&amp;&amp; __f, _Tp&amp;&amp; <span class=\"keyword\">__t</span>)</span><br><span class=\"line\">&#123; <span class=\"keyword\">return</span> __invfwd&lt;_Tp&gt;(<span class=\"keyword\">__t</span>).*__f; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Res, <span class=\"keyword\">typename</span> _MemPtr, <span class=\"keyword\">typename</span> _Tp&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Res</span><br><span class=\"line\">__invoke_impl(__invoke_memobj_deref, _MemPtr&amp;&amp; __f, _Tp&amp;&amp; <span class=\"keyword\">__t</span>)</span><br><span class=\"line\">&#123; <span class=\"keyword\">return</span> (*std::forward&lt;_Tp&gt;(<span class=\"keyword\">__t</span>)).*__f; &#125;</span><br></pre></td></tr></table></figure>\n<p><em>Lambda</em></p>\n<p><em>lambda</em>可以理解为是仿函数的语法糖。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> add  = [](<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b) &#123; <span class=\"keyword\">return</span> a+b; &#125;;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> c = <span class=\"built_in\">add</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>对于上面的<code>lambda</code>函数，在gdb调试，经过编译的到的函数类型：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(gdb) s</span><br><span class=\"line\">&lt;<span class=\"built_in\">lambda</span>(<span class=\"keyword\">int</span>, <span class=\"keyword\">int</span>)&gt;::<span class=\"built_in\"><span class=\"keyword\">operator</span></span>()(<span class=\"keyword\">int</span>, <span class=\"keyword\">int</span>) <span class=\"built_in\"><span class=\"keyword\">const</span></span> (__closure=<span class=\"number\">0x7fffffffe6d3</span>, a=<span class=\"number\">1</span>, b=<span class=\"number\">2</span>) at main.cpp:<span class=\"number\">24</span></span><br><span class=\"line\"><span class=\"number\">24</span>        <span class=\"keyword\">auto</span> add  = [](<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b) &#123; <span class=\"keyword\">return</span> a+b; &#125;;</span><br></pre></td></tr></table></figure>\n<p><code>lambda</code>可以看作是匿名的函数对象，并且 <code>lambda</code>表达式默认是 <code>const</code>属性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span> </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Foo</span>() </span><br><span class=\"line\">  &#123; </span><br><span class=\"line\">    []()&#123;std::cout&lt;&lt;<span class=\"string\">&quot;123&quot;</span>&lt;&lt;std::endl; &#125;();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; </span><br><span class=\"line\">  Foo foo;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在类中调用<code>lambda</code>表达式，编译出来的类型如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Foo::<span class=\"built_in\">Foo</span>()::&#123;<span class=\"built_in\">lambda</span>()#<span class=\"number\">1</span>&#125;::<span class=\"built_in\"><span class=\"keyword\">operator</span></span>()() <span class=\"keyword\">const</span></span><br></pre></td></tr></table></figure>\n<p>而实际上，lambda与operator本质上也是一样的，如下代码：<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span> </span><br><span class=\"line\">   <span class=\"keyword\">public</span>:</span><br><span class=\"line\">     <span class=\"built_in\">Foo</span>() </span><br><span class=\"line\">     &#123; </span><br><span class=\"line\">       <span class=\"comment\">// 以下两个设计等价</span></span><br><span class=\"line\">       [<span class=\"keyword\">this</span>](<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* str)&#123;<span class=\"keyword\">this</span>-&gt;<span class=\"built_in\">print</span>(str); &#125;(<span class=\"string\">&quot;lambda&quot;</span>);</span><br><span class=\"line\">       <span class=\"built_in\">Unmaed</span>(<span class=\"keyword\">this</span>)(<span class=\"string\">&quot;operator&quot;</span>);</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* str)</span> </span>&#123; </span><br><span class=\"line\">       std::cout&lt;&lt;str&lt;&lt;std::endl;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">private</span>:</span><br><span class=\"line\">     <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Unmaed</span></span></span><br><span class=\"line\"><span class=\"class\">     &#123;</span></span><br><span class=\"line\">       <span class=\"built_in\">Unmaed</span>(Foo* foo): <span class=\"built_in\">foo_</span>(foo) &#123; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">operator</span><span class=\"params\">()</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* str)</span> <span class=\"keyword\">const</span></span></span><br><span class=\"line\"><span class=\"function\">       </span>&#123;</span><br><span class=\"line\">         foo_-&gt;<span class=\"built_in\">print</span>(str);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       Foo* foo_;</span><br><span class=\"line\">     &#125;;</span><br><span class=\"line\">   &#125;;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"std-bind-与-lambad区别\"><a href=\"#std-bind-与-lambad区别\" class=\"headerlink\" title=\"std::bind 与 lambad区别\"></a>std::bind 与 lambad区别</h4><ul>\n<li><p><code>lambda</code> 可以重载，但是 <code>std::bind</code> 无法区别重载</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f</span><span class=\"params\">(<span class=\"keyword\">int</span>)</span> </span>&#123;&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f</span><span class=\"params\">(<span class=\"keyword\">double</span>)</span> </span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> g = [] &#123; <span class=\"built_in\">f</span>(<span class=\"number\">1</span>); &#125;; <span class=\"comment\">// OK</span></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> g = std::<span class=\"built_in\">bind</span>(f, <span class=\"number\">1</span>); <span class=\"comment\">// 错误</span></span><br><span class=\"line\">  <span class=\"keyword\">auto</span> g = std::<span class=\"built_in\">bind</span>(<span class=\"keyword\">static_cast</span>&lt;<span class=\"built_in\"><span class=\"keyword\">void</span></span>(*)(<span class=\"keyword\">int</span>)&gt;(f), <span class=\"number\">1</span>); <span class=\"comment\">// OK</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>为此必须指定对应的函数指针类型。<code>lambda</code> 闭包类的 <code>operator()</code> 采用的是能被编译器内联的常规的函数调用。而<code>std::bind</code>采用的是一般不会被内联的函数指针调用，这意味着 <strong><code>lambda</code> 比 <code>std::bind</code> 运行得更快</strong>。</p>\n<ul>\n<li>传给 <code>std::bind</code> 的参数，绑定的是 <code>std::bind</code>，而不是<code>std::bind</code>内部管理的函数<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f</span><span class=\"params\">(std::chrono::steady_clock::time_point t, <span class=\"keyword\">int</span> i)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    std::this_thread::<span class=\"built_in\">sleep_until</span>(t);</span><br><span class=\"line\">    std::cout &lt;&lt; i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">auto</span> g = [](<span class=\"keyword\">int</span> i)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">f</span>(std::chrono::steady_clock::<span class=\"built_in\">now</span>() + std::chrono::<span class=\"built_in\">seconds</span>(<span class=\"number\">3</span>), i);</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">g</span>(<span class=\"number\">1</span>); <span class=\"comment\">// 3秒后打印1</span></span><br><span class=\"line\"><span class=\"comment\">// 用std::bind实现相同效果，但存在问题</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> h = std::<span class=\"built_in\">bind</span>(f,</span><br><span class=\"line\">                    std::chrono::steady_clock::<span class=\"built_in\">now</span>() + \t std::chrono::<span class=\"built_in\">seconds</span>(<span class=\"number\">3</span>),</span><br><span class=\"line\">                    std::placeholders::_1);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">h</span>(<span class=\"number\">1</span>); <span class=\"comment\">// 3秒后打印1，但3秒指的是调用std::bind后的3秒，而非调用f后的3秒</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>计算时间的表达式作为实参被传递给<code>std::bind</code>，因此计算发生在调用<code>std::bind</code>的时刻，而非调用其绑定的函数的时刻。</p>\n<p>在 <code>c++14</code> 中，完全没有理由使用 <code>std::bind</code>，<code>c++11</code>由于特性受限，存在两个使用场景：</p>\n<ul>\n<li>模拟<code>c++11</code>缺少的移动捕获</li>\n<li>函数对象 <code>operator()</code> 是模板时，如果将此函数作为参数使用，用 <code>std::bind</code> 绑定才能接受任意类型参数<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">X</span> &#123;</span></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span></span><br><span class=\"line\"><span class=\"function\">      <span class=\"keyword\">void</span> <span class=\"title\">operator</span><span class=\"params\">()</span><span class=\"params\">(<span class=\"keyword\">const</span> T&amp;)</span> <span class=\"keyword\">const</span></span>;</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">  </span><br><span class=\"line\">X x;</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> f = std::<span class=\"built_in\">bind</span>(x, _1); <span class=\"comment\">// f可以接受任意参数类型</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\">// c++14 做法</span></span><br><span class=\"line\">  X a;</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> f = [a](<span class=\"keyword\">const</span> <span class=\"keyword\">auto</span>&amp; x) &#123; <span class=\"built_in\">a</span>(x); &#125;;</span><br></pre></td></tr></table></figure>\n<h4 id=\"Lambda-与-std-bind-区别补充\"><a href=\"#Lambda-与-std-bind-区别补充\" class=\"headerlink\" title=\"Lambda 与 std::bind 区别补充\"></a><em>Lambda</em> 与 <em>std::bind</em> 区别补充</h4><code>std::bind</code> 传入的参数默认情况下是 “值传递”，想要使用引用传递需要<code>std::ref</code>。详细可以参考下面的代码：</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span> </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"built_in\">Foo</span>() </span><br><span class=\"line\">  &#123; </span><br><span class=\"line\">    std::cout&lt;&lt;<span class=\"string\">&quot;default&quot;</span>&lt;&lt;std::endl; </span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">Foo</span>(<span class=\"keyword\">const</span> Foo&amp; rhs)     </span><br><span class=\"line\">  &#123; </span><br><span class=\"line\">    std::cout&lt;&lt;<span class=\"string\">&quot;ctor&quot;</span>&lt;&lt;std::endl;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"keyword\">const</span> Foo&amp; lhs, <span class=\"keyword\">const</span> Foo&amp; rhs)</span> </span>&#123; </span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  std::cout&lt;&lt;std::boolalpha;</span><br><span class=\"line\"></span><br><span class=\"line\">  Foo foo1;</span><br><span class=\"line\">  Foo foo2;</span><br><span class=\"line\"></span><br><span class=\"line\">  std::cout&lt;&lt;<span class=\"string\">&quot;bind: pass by value&quot;</span>&lt;&lt;std::endl;</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> func = std::<span class=\"built_in\">bind</span>(add,  foo1, foo2);</span><br><span class=\"line\">  </span><br><span class=\"line\">  std::cout&lt;&lt;<span class=\"string\">&quot;bind: pass by ref&quot;</span>&lt;&lt;std::endl;</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> func = std::<span class=\"built_in\">bind</span>(add,  std::<span class=\"built_in\">ref</span>(foo1), std::<span class=\"built_in\">ref</span>(foo2));</span><br><span class=\"line\"></span><br><span class=\"line\">  std::cout&lt;&lt;<span class=\"string\">&quot;lambda &quot;</span>&lt;&lt;std::endl;</span><br><span class=\"line\">  [&amp;foo1, &amp;foo2]&#123; <span class=\"built_in\">add</span>(foo1, foo2);&#125;();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上面的代码输出：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ g++ -g  -O0 main.cc -o main &amp;&amp; ./main</span><br><span class=\"line\">default</span><br><span class=\"line\">default</span><br><span class=\"line\"><span class=\"built_in\">bind</span>: pass by value</span><br><span class=\"line\">ctor</span><br><span class=\"line\">ctor</span><br><span class=\"line\"><span class=\"built_in\">bind</span>: pass by ref</span><br><span class=\"line\">lambda </span><br></pre></td></tr></table></figure><br>可以看到<code>std::bind</code>在默认情况下，是依靠值传递，使用了<code>std::ref</code>来包裹传入参数才是使用引用传递。用 <code>gdb</code> 调试，可以跟踪到发生构造 <code>Foo</code> 对象的位置：<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _UHead&gt;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> _Head_base(_UHead&amp;&amp; __h) : _Head(std::forward&lt;_UHead&gt;(__h)) &#123; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 整个调用链如下：</span></span><br><span class=\"line\">#<span class=\"number\">0</span>  Foo::<span class=\"built_in\">Foo</span> (<span class=\"keyword\">this</span>=<span class=\"number\">0x7fffffffe068</span>, rhs=...) at main.cc:<span class=\"number\">13</span></span><br><span class=\"line\">#<span class=\"number\">1</span>  <span class=\"number\">0x0000555555555a8c</span> in std::_Head_base&lt;<span class=\"number\">1ul</span>, Foo, <span class=\"literal\">true</span>&gt;::_Head_base&lt;Foo&amp;&gt; (<span class=\"keyword\">this</span>=<span class=\"number\">0x7fffffffe068</span>, __h=...) at /usr/include/c++/<span class=\"number\">9</span>/tuple:<span class=\"number\">87</span></span><br><span class=\"line\">#<span class=\"number\">2</span>  <span class=\"number\">0x00005555555559e8</span> in std::_Tuple_impl&lt;<span class=\"number\">1ul</span>, Foo&gt;::_Tuple_impl&lt;Foo&amp;&gt; (<span class=\"keyword\">this</span>=<span class=\"number\">0x7fffffffe068</span>, __head=...) at /usr/include/c++/<span class=\"number\">9</span>/tuple:<span class=\"number\">349</span></span><br><span class=\"line\">#<span class=\"number\">3</span>  <span class=\"number\">0x00005555555558f3</span> in std::_Tuple_impl&lt;<span class=\"number\">0ul</span>, Foo, Foo&gt;::_Tuple_impl&lt;Foo&amp;, Foo&amp;, <span class=\"keyword\">void</span>&gt; (<span class=\"keyword\">this</span>=<span class=\"number\">0x7fffffffe068</span>, __head=...)</span><br><span class=\"line\">    at /usr/include/c++/<span class=\"number\">9</span>/tuple:<span class=\"number\">218</span></span><br><span class=\"line\">#<span class=\"number\">4</span>  <span class=\"number\">0x0000555555555815</span> in std::tuple&lt;Foo, Foo&gt;::tuple&lt;Foo&amp;, Foo&amp;, <span class=\"literal\">true</span>&gt; (<span class=\"keyword\">this</span>=<span class=\"number\">0x7fffffffe068</span>, __a1=..., __a2=...) at /usr/include/c++/<span class=\"number\">9</span>/tuple:<span class=\"number\">969</span></span><br><span class=\"line\">#<span class=\"number\">5</span>  <span class=\"number\">0x00005555555556fc</span> in std::_Bind&lt;<span class=\"built_in\"><span class=\"keyword\">void</span></span> (*(Foo, Foo))(Foo <span class=\"keyword\">const</span>&amp;, Foo <span class=\"keyword\">const</span>&amp;)&gt;::_Bind&lt;Foo&amp;, Foo&amp;&gt;(<span class=\"built_in\"><span class=\"keyword\">void</span></span> (*&amp;&amp;)(Foo <span class=\"keyword\">const</span>&amp;, Foo <span class=\"keyword\">const</span>&amp;), Foo&amp;, Foo&amp;)</span><br><span class=\"line\">    (<span class=\"keyword\">this</span>=<span class=\"number\">0x7fffffffe060</span>, __f=@<span class=\"number\">0x7fffffffe010</span>: <span class=\"number\">0x5555555551ea</span> &lt;<span class=\"built_in\">add</span>(Foo <span class=\"keyword\">const</span>&amp;, Foo <span class=\"keyword\">const</span>&amp;)&gt;) at /usr/include/c++/<span class=\"number\">9</span>/functional:<span class=\"number\">467</span></span><br><span class=\"line\">#<span class=\"number\">6</span>  <span class=\"number\">0x0000555555555571</span> in std::bind&lt;<span class=\"built_in\"><span class=\"keyword\">void</span></span> (&amp;)(Foo <span class=\"keyword\">const</span>&amp;, Foo <span class=\"keyword\">const</span>&amp;), Foo&amp;, Foo&amp;&gt; (__f=</span><br><span class=\"line\">    @<span class=\"number\">0x5555555551ea</span>: &#123;<span class=\"built_in\"><span class=\"keyword\">void</span></span> (<span class=\"keyword\">const</span> Foo &amp;, <span class=\"keyword\">const</span> Foo &amp;)&#125; <span class=\"number\">0x5555555551ea</span> &lt;<span class=\"built_in\">add</span>(Foo <span class=\"keyword\">const</span>&amp;, Foo <span class=\"keyword\">const</span>&amp;)&gt;) at /usr/include/c++/<span class=\"number\">9</span>/functional:<span class=\"number\">812</span></span><br><span class=\"line\">#<span class=\"number\">7</span>  <span class=\"number\">0x00005555555552b7</span> <span class=\"function\">in <span class=\"title\">main</span> <span class=\"params\">(argc=<span class=\"number\">1</span>, argv=<span class=\"number\">0x7fffffffe198</span>)</span> at main.cc:<span class=\"number\">30</span></span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"左值引用和右值引用区别\"><a href=\"#左值引用和右值引用区别\" class=\"headerlink\" title=\"左值引用和右值引用区别\"></a>左值引用和右值引用区别</h3><p> 左值引用，也就是“常规引用”，不能绑定到要转换的表达式，字面常量，或返回右值的表达式。而右值引用恰好相反，可以绑定到这类表达式，但不能绑定到一个左值上。</p>\n<p> 右值引用就是必须绑定到右值的引用，通过&amp;&amp;获得。右值引用只能绑定到一个将要销毁的对象上，因此可以自由地移动其资源。</p>\n<p> 返回左值的表达式包括返回左值引用的函数及赋值，下标，解引用和<strong>前置递增/递减运算符</strong>；<br> 返回右值的包括返回非引用类型的函数及算术，关系，位和后置递增/递减运算符。可以看到左值的特点是有持久的状态，而右值则是短暂的<br> <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">int</span>&amp;&amp; index, <span class=\"keyword\">int</span> idx)</span> </span>&#123; </span><br><span class=\"line\">  <span class=\"keyword\">if</span>(idx &gt; <span class=\"number\">3</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">func</span>(index++, ++idx);  <span class=\"comment\">// Ok </span></span><br><span class=\"line\">  <span class=\"built_in\">func</span>(++index, ++idx);  <span class=\"comment\">// Error</span></span><br><span class=\"line\"></span><br><span class=\"line\">  std::cout&lt;&lt; std::is_rvalue_reference&lt;<span class=\"keyword\">decltype</span>(index)&gt;::value &lt;&lt;std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> 在上面的代码中，<code>++index</code> 产生的是左值，而 <code>index++</code> 产生的是右值。因此上面的可以编译成功，下面的编译不过。</p>\n<p>【注意】：已经命名的右值，编译器会认为是左值。</p>\n<h3 id=\"左值与右值\"><a href=\"#左值与右值\" class=\"headerlink\" title=\"左值与右值\"></a>左值与右值</h3><p>变量都是左值，即使变量是右值引用类型<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>&amp;&amp; ref1 = <span class=\"number\">1</span>;     <span class=\"comment\">//  ok </span></span><br><span class=\"line\"><span class=\"keyword\">int</span>&amp;&amp; ref2 = ref1; <span class=\"comment\">// error </span></span><br></pre></td></tr></table></figure><br>因为 <code>ref2</code> 是右值引用类型的变量，不能将其绑定到左值<code>ref1</code>上。<strong><code>ref1</code> 与 <code>ref2</code> 是左值，因为他们都是变量，但是变量类型是右值引用类型，即这两个变量只能绑定到右值上</strong>。</p>\n<h3 id=\"四种类型转换总结\"><a href=\"#四种类型转换总结\" class=\"headerlink\" title=\"四种类型转换总结\"></a>四种类型转换总结</h3><h4 id=\"static-cast\"><a href=\"#static-cast\" class=\"headerlink\" title=\"static_cast\"></a><em>static_cast</em></h4><ul>\n<li><p>基类和子类之间转换：<br>  <code>static_cast</code> 的使用，当且仅当类型之间可隐式转化时，<code>static_cast</code> 的转化才是合法的。有一个例外，那就是类层次间的向下转型，<code>static_cast</code> 可以完成类层次间的向下转型，但是向下转型无法通过隐式转换完成。</p>\n<ul>\n<li><p>向上转换安全：子类指针转换成父类指针是安全的;</p>\n</li>\n<li><p>向下转换不安全：父类指针转换成子类指针是不安全的。</p>\n</li>\n<li><p><code>static_cast</code>不能进行无关类型(如非基类和子类)指针之间的转换。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Base</span>&#123;</span> &#125;;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Derived</span> :</span> <span class=\"keyword\">public</span> base&#123; <span class=\"comment\">/**....*/</span> &#125;;</span><br><span class=\"line\">  </span><br><span class=\"line\">    Base*    B = <span class=\"keyword\">new</span> Base;</span><br><span class=\"line\">    Derived* D = <span class=\"keyword\">static_cast</span>&lt;Drived*&gt;(B); <span class=\"comment\">// 不安全</span></span><br></pre></td></tr></table></figure>\n<p>为什么不安全？   </p>\n<p>D指向本质上还是B的对象模型，D指向的内存模型中可能存在B没有的成员变量。如果 <code>D-&gt;foo()</code> 中使用了 <code>D</code> 的成员变量，那么这个函数调用就是不安全的。因此，向下转换是安全的。</p>\n</li>\n</ul>\n</li>\n<li><p><code>static_cast</code> 还可以在左值和右值之间显示地转换。虽然不能隐式地将左值转换为右值，但是可以使用<code>static_cast</code>显示地将左值转换为右值。</p>\n</li>\n<li>基本数据类型转换: <code>enum</code>, <code>int</code>, <code>char</code>, <code>float</code>等。安全性问题由开发者来保证。</li>\n<li>把空指针转换成目标类型的空指针    <figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>* iptr = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>*&gt;(::<span class=\"built_in\">malloc</span>(<span class=\"built_in\">sizoef</span>(<span class=\"keyword\">int</span>)));</span><br></pre></td></tr></table></figure></li>\n<li>把任何类型的表达式转换成void类型：<code>static_cast&lt;void&gt;(iptr)</code></li>\n<li><code>static_cast</code> 不能去掉类型的<code>const、volitale</code>属性(用<code>const_cast</code>)</li>\n<li>隐式转换都建议使用 <code>static_cast</code> 进行标明和替换</li>\n</ul>\n<h4 id=\"dynamic-cast\"><a href=\"#dynamic-cast\" class=\"headerlink\" title=\"dynamic_cast\"></a><em>dynamic_cast</em></h4><p>专门用于将多态基类的指针或引用强制转换为派生类的指针或引用，而且能够检查转换的安全性。对于不安全的指针转换，转换结果返回 nullptr 指针。  </p>\n<p>使用特点：　　</p>\n<ul>\n<li><p>基类必须要有虚函数，因为<code>dynamic_cast</code>是运行时类型检查，需要运行时类型信息，而这个信息是存储在类的虚函数表中，只有一个类定义了虚函数，才会有虚函数表　　</p>\n</li>\n<li><p>对于下行转换，<code>dynamic_cast</code>是安全的（当类型不一致时，转换过来的是空指针），而<code>static_cast</code>是不安全的（当类型不一致时，转换过来的是错误意义的指针，可能造成踩内存，非法访问等各种问题), <code>reinterpreter_cast</code> 下行转换是可以转换，但是不安全。　</p>\n</li>\n<li><p>相同基类不同子类之间的交叉转换，转换结果是是 nullptr</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>: </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123; &#125; </span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Drived</span> :</span> <span class=\"keyword\">public</span> base &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  <span class=\"keyword\">int</span> i;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">Base     *Bptr = <span class=\"keyword\">new</span> <span class=\"built_in\">Drived</span>()；<span class=\"comment\">//语句0</span></span><br><span class=\"line\">Derived *Dptr1 = <span class=\"keyword\">static_cast</span>&lt;Derived*&gt;(Bptr);  <span class=\"comment\">//语句1；</span></span><br><span class=\"line\">Derived *Dptr2 = <span class=\"keyword\">dynamic_cast</span>&lt;Derived*&gt;(Bptr); <span class=\"comment\">//语句2；</span></span><br></pre></td></tr></table></figure>\n<p>此时语句1和语句2都是安全的，因为此时 <code>Bptr</code> 确实是指向的派生类的内存模型，所以两个类型转换都是安全的。<code>Dptr1</code> 和 <code>Dptr2</code> 可以尽情访问 <code>Drived</code> 类中的成员，绝对不会出问题。但是如果此时语句0更改为如下表达：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Base* Bptr = <span class=\"keyword\">new</span> <span class=\"built_in\">Base</span>(); `</span><br></pre></td></tr></table></figure>\n<p>那么 <code>Bptr</code> 指向的是<code>Base</code>对象内存模型。因此语句1是不安全的，因为如果访问子类的数据成员，其行为将是未定义。而语句2返回的是 <code>nullptr</code>，更加直观的告诉用户不安全。</p>\n</li>\n</ul>\n<h4 id=\"reinterpreter-cast\"><a href=\"#reinterpreter-cast\" class=\"headerlink\" title=\"reinterpreter_cast\"></a><em>reinterpreter_cast</em></h4><p>用于进行各种不同类型的指针之间、不同类型的引用之间以及指针和能容纳指针的整数类型之间的转换。转换时执行的是<strong>逐 <code>byte</code> 复制</strong>的操作。</p>\n<ul>\n<li><code>reinterpret_cast</code>是从底层对数据仅仅进行重新解释，但没有进行二进制的转换，依赖具体的平台，可移植性差；　　</li>\n<li><code>reinterpret_cast</code>可以将整型转换为指针，也可以把指针转换为数组；　　</li>\n<li><code>reinterpret_cast</code>可以在指针和引用里进行肆无忌惮的转换；</li>\n</ul>\n<h4 id=\"const-cast\"><a href=\"#const-cast\" class=\"headerlink\" title=\"const_cast\"></a><em>const_cast</em></h4><ul>\n<li>常量指针转换为非常量指针， 并且仍然指向原来的对象　　</li>\n<li>常量引用被转换为非常量引用，并且仍然指向原来的对象</li>\n</ul>\n<h3 id=\"自己实现一个非侵入式的智能指针\"><a href=\"#自己实现一个非侵入式的智能指针\" class=\"headerlink\" title=\"自己实现一个非侵入式的智能指针\"></a>自己实现一个非侵入式的智能指针</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// RAII 技术封装  </span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RefCount</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">      <span class=\"built_in\">RefCount</span>() : reference_&#123;<span class=\"number\">0</span>&#125; </span><br><span class=\"line\">      &#123; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      ~<span class=\"built_in\">RefCount</span>() &#123; </span><br><span class=\"line\">          <span class=\"keyword\">this</span>-&gt;<span class=\"built_in\">decrementRef</span>();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">IncrementRef</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">          ++reference_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">decrementRef</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> (--reference_ == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">delete</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">          <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      </span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">int64_t</span> <span class=\"title\">use_count</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">          <span class=\"keyword\">return</span> reference_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">private</span>:</span><br><span class=\"line\">      std::atomic&lt;<span class=\"keyword\">int64_t</span>&gt; reference_;</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SharedPtr</span></span></span><br><span class=\"line\"><span class=\"class\">  &#123;</span></span><br><span class=\"line\">  <span class=\"keyword\">public</span>:</span><br><span class=\"line\">      <span class=\"built_in\">SharedPtr</span>() : <span class=\"built_in\">ptr_</span>(<span class=\"literal\">nullptr</span>) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">SharedPtr</span><span class=\"params\">(T* ptr)</span> </span></span><br><span class=\"line\"><span class=\"function\">      : ptr_(ptr),</span></span><br><span class=\"line\"><span class=\"function\">        ref_(new RefCount)</span></span><br><span class=\"line\"><span class=\"function\">      &#123;</span></span><br><span class=\"line\">          <span class=\"keyword\">if</span> (ref_) ref_-&gt;<span class=\"built_in\">IncrementRef</span>();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"built_in\">SharedPtr</span>(<span class=\"keyword\">const</span> SharedPtr&amp; other) </span><br><span class=\"line\">      : <span class=\"built_in\">ptr_</span>(other.ptr_),</span><br><span class=\"line\">        <span class=\"built_in\">ref_</span>(other.ref_)</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> (ref_) ref_-&gt;<span class=\"built_in\">IncrementRef</span>();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"built_in\">SharedPtr</span>(SharedPtr&amp;&amp; other) <span class=\"keyword\">noexcept</span> &#123;</span><br><span class=\"line\">          ptr_ = other.ptr_;</span><br><span class=\"line\">          ref_ = other.ref_;</span><br><span class=\"line\">          other.ptr_ = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">          other.ref_ = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      SharedPtr&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> SharedPtr&amp; other) &#123;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span> == &amp;other || *<span class=\"keyword\">this</span> == other) </span><br><span class=\"line\">              <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">          <span class=\"built_in\">reset</span>();</span><br><span class=\"line\">          ptr_ = other.ptr_;</span><br><span class=\"line\">          ref_ = other.ref_;</span><br><span class=\"line\">          ref_-&gt;<span class=\"built_in\">IncrementRef</span>();</span><br><span class=\"line\">          <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      SharedPtr&amp; <span class=\"keyword\">operator</span>=(SharedPtr&amp;&amp; other) <span class=\"keyword\">noexcept</span> &#123;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span> == &amp;other || *<span class=\"keyword\">this</span> == other) <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">          <span class=\"built_in\">reset</span>();</span><br><span class=\"line\">          ptr_ = other.ptr_;</span><br><span class=\"line\">          ref_ = other.ref_;</span><br><span class=\"line\">          </span><br><span class=\"line\">          other.ptr_ = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">          other.ref_ = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">          <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      ~<span class=\"built_in\">SharedPtr</span>() </span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> (ref_) <span class=\"keyword\">this</span>-&gt;<span class=\"built_in\">decrementRef</span>(); </span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      T&amp; <span class=\"keyword\">operator</span>*()  <span class=\"keyword\">const</span> &#123; <span class=\"keyword\">return</span> *ptr_; &#125;</span><br><span class=\"line\">      T* <span class=\"keyword\">operator</span>-&gt;() <span class=\"keyword\">const</span> &#123; <span class=\"keyword\">return</span> ptr_; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"keyword\">operator</span> <span class=\"title\">bool</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"keyword\">return</span> !!ptr_; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\">T* <span class=\"title\">get</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"keyword\">return</span> ptr_; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">reset</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> (ptr_) &#123;</span><br><span class=\"line\">              <span class=\"keyword\">this</span>-&gt;<span class=\"built_in\">decrementRef</span>();</span><br><span class=\"line\">              <span class=\"comment\">// ptr_ = nullptr;</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">decrementRef</span><span class=\"params\">()</span> </span>&#123; </span><br><span class=\"line\">          <span class=\"keyword\">if</span>(ref_ &amp;&amp; ptr_) &#123; </span><br><span class=\"line\">              <span class=\"keyword\">if</span>(ref_-&gt;<span class=\"built_in\">decrementRef</span>()) &#123; </span><br><span class=\"line\">                  <span class=\"keyword\">delete</span> ptr_;</span><br><span class=\"line\">                  ptr_ = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">int64_t</span> <span class=\"title\">use_count</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">          <span class=\"keyword\">return</span>  ref_-&gt;<span class=\"built_in\">use_count</span>();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">unique</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">          <span class=\"keyword\">return</span> <span class=\"built_in\">use_count</span>() == <span class=\"number\">1</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(SharedPtr &amp; other)</span> </span>&#123;</span><br><span class=\"line\">          std::<span class=\"built_in\">swap</span>(ptr_, other.ptr_);</span><br><span class=\"line\">          std::<span class=\"built_in\">swap</span>(ref_, other.ref_);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">friend</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>==(SharedPtr <span class=\"keyword\">const</span>&amp; lhs, SharedPtr <span class=\"keyword\">const</span>&amp; rhs) &#123;</span><br><span class=\"line\">          <span class=\"keyword\">return</span> lhs.ptr_ == rhs.ptr_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">friend</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>!=(SharedPtr <span class=\"keyword\">const</span>&amp; lhs, SharedPtr <span class=\"keyword\">const</span>&amp; rhs) &#123;</span><br><span class=\"line\">          <span class=\"keyword\">return</span> lhs.ptr_ != rhs.ptr_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">friend</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(SharedPtr <span class=\"keyword\">const</span>&amp; lhs, SharedPtr <span class=\"keyword\">const</span>&amp; rhs) &#123;</span><br><span class=\"line\">          <span class=\"keyword\">return</span> lhs.ptr_ &lt; rhs.ptr_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">private</span>:</span><br><span class=\"line\">      T*        ptr_; </span><br><span class=\"line\">      RefCount* ref_;</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> <span class=\"keyword\">const</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">      <span class=\"function\">SharedPtr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">iptr</span> <span class=\"params\">(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>)</span></span>;</span><br><span class=\"line\">      <span class=\"function\">SharedPtr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">iptr2</span><span class=\"params\">(iptr)</span></span>;</span><br><span class=\"line\">      <span class=\"function\">SharedPtr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">iptr3</span><span class=\"params\">(std::move(iptr))</span></span>;</span><br><span class=\"line\">      SharedPtr&lt;<span class=\"keyword\">int</span>&gt; iptr4 = iptr2;</span><br><span class=\"line\">      SharedPtr&lt;<span class=\"keyword\">int</span>&gt; iptr5 = std::<span class=\"built_in\">move</span>(iptr3);</span><br><span class=\"line\"></span><br><span class=\"line\">      std::cout&lt;&lt;iptr5.<span class=\"built_in\">use_count</span>()&lt;&lt;std::endl; <span class=\"comment\">// 3</span></span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"迭代器失效的场景\"><a href=\"#迭代器失效的场景\" class=\"headerlink\" title=\"迭代器失效的场景\"></a>迭代器失效的场景</h3><ul>\n<li><p>序列式容器<br>  序列式容器会失效的原因是因为其存储都是连续的，因此删除或者插入一个元素都有可能导致其他元素的迭代器失效。</p>\n<ul>\n<li><p><code>vector</code></p>\n<ul>\n<li>在遍历时，执行<code>erase</code>会导致删除节点之后的全部失效</li>\n<li>在<code>push_back</code>时，之前的<code>end()</code>操作得到的迭代器失效<ul>\n<li><code>insert/push_back</code>导致<code>capacity()</code>改变，那么之前的<code>first()/end()</code>得到的迭代器会失效</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><code>insert</code>一个元素，如果空间没有分配，那么插入节点之前的迭代器位置有效，之后的失效。</p>\n<p>  简而言之：导致内存分配的全会失效，导致元素移动的会局部失效</p>\n</li>\n<li><code>deque</code><ul>\n<li>在首尾添加元素，会导致迭代器失效，但是指针、引用不会失效</li>\n<li>其余位置插入元素，迭代器、指针、引用都是失效</li>\n<li>在首尾之外的位置删除元素，那么其他位置的迭代器都失效</li>\n<li>在首尾删除元素，只是会导致被指向的删除元素的迭代器失效</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>关联式容器<ul>\n<li>基于哈希表实现的<em>std::unordered_map/std::set</em> 导致迭代器失效，一般是插入元素导致 <em>reshash</em> 产生，如果是删除只是会导致被删除元素的迭代器失效。<br><img src=\"image/unorder_map非法化.jpg\" alt=\"case\"><h3 id=\"std-unordered-map\"><a href=\"#std-unordered-map\" class=\"headerlink\" title=\"std::unordered_map\"></a><em>std::unordered_map</em></h3><h4 id=\"底层实现及其解决-hash-冲突方法\"><a href=\"#底层实现及其解决-hash-冲突方法\" class=\"headerlink\" title=\"底层实现及其解决 hash 冲突方法\"></a>底层实现及其解决 <em>hash</em> 冲突方法</h4></li>\n</ul>\n</li>\n</ul>\n<p><em>std::unorder_map</em>  解决冲突方式是 <strong>拉链法</strong>（数组的每个元素都连着一个链表？）：将所有产生冲突的关键字所对应的数据全部存储在同一个线性链表中（<em>bucket</em>）。这个方法解决数据存储位置发生冲突的哈希表，整个存储结构如图 1 所示。</p>\n<div align=center><img src=./image/hashtable.gif> </div>\n\n<p>  其中 p_i表示存储的各个键值对。</p>\n<p>当使用无序容器存储键值对时，会先申请一整块连续的存储空间，但此空间并不用来直接存储键值对，而是存储各个链表的头指针，各键值对真正的存储位置是各个链表的节点。<code>STL</code> 标准库默认选用<code>vector</code>容器存储各个链表的头指针。<code>STL</code> 标准库中，将图 1 中的各个链表称为桶 <em>bucket</em>，每个桶都有自己的编号（从 0 开始）。当有新键值对存储到无序容器中时，整个存储过程分为如下几步：</p>\n<ul>\n<li>将该键值对中 <code>key</code> 的值带入设计好的哈希函数，会得到一个哈希值: <em>H = hash(key)</em>；</li>\n<li>将 H 和无序容器拥有桶的数量 n 做整除运算（即<code>H % n</code>），该结果即表示应将此键值对存储到的桶的编号；</li>\n<li><p>建立一个新节点存储此键值对，同时将该节点链接到相应编号的桶上</p>\n<p><strong>其他解决冲突的方法</strong></p>\n</li>\n<li>开放地址法：<script type=\"math/tex; mode=display\">\nH =(hash(key) + d)  \\%  m</script></li>\n</ul>\n<pre><code> 其中`m`是哈希表的表长，`d`是一个增量，当产生冲突时，选择以下三种方法一种获取d的值，然后计算，直到计算出的*hash* 值不存在冲突。\n\n+  线性探测法：d = 1,2,3,...\n+  二次探测法：d = 12,-12, 22, -22...\n+  伪随机数探测法: d = 伪随机数\n</code></pre><ul>\n<li>再哈希法<code>rehasp</code><br>当通过哈希函数求得的哈希地址同其他关键字产生冲突时，使用另一个哈希函数计算，直到冲突不再发生</li>\n</ul>\n<h4 id=\"rehashp\"><a href=\"#rehashp\" class=\"headerlink\" title=\"rehashp\"></a>rehashp</h4><p>上述的拉链法解决了哈希冲突的问题，但是当插入元素很多，产生了严重哈希冲突时，就会导致某个链表长度越来越长，进而导致哈希表的查找就会退化为链表，效率降低为O(n)的时间复杂度。</p>\n<p> 哈希表存储结构还有一个重要的属性，称为负载因子<code>load factor</code>，用于衡量容器存储键值对的空/满程度：即负载因子越大，意味着容器越满，即各链表中挂载着越多的键值对，这无疑会降低容器查找目标键值对的效率；反之，负载因子越小，容器肯定越空，但并不一定各个链表中挂载的键值对就越少。</p>\n<blockquote>\n<p> 负载因子的计算方法为：负载因子 = 容器存储的总键值对 / 桶数</p>\n</blockquote>\n<p><code>STL</code> 中默认情况下，无序容器的最大负载因子为 1.0。如果操作无序容器过程中，使得最大复杂因子超过了默认值，则容器会自动增加桶数，并重新进行哈希，以此来减小负载因子的值。需要注意的是，此过程会导致容器迭代器失效，但指向单个键值对的引用或者指针仍然有效。</p>\n<p>因此当插入元素过多，使得负载因子的大于1.0，就会产生<em>rehash</em>行为，来改善即将下降的效率。</p>\n<p> <strong>STL中的 <em>unordered_map</em> 的 <em>rehash</em> 策略</strong><br>一下代码节选自g++的<em>STL</em>库：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// __n_bkt is current bucket count, __n_elt is current element count,</span></span><br><span class=\"line\"><span class=\"comment\">// and __n_ins is number of elements to be inserted.  Do we need to</span></span><br><span class=\"line\"><span class=\"comment\">// increase bucket count?  If so, return make_pair(true, n), where n</span></span><br><span class=\"line\"><span class=\"comment\">// is the new bucket count.  If not, return make_pair(false, 0).</span></span><br><span class=\"line\">std::pair&lt;<span class=\"keyword\">bool</span>, <span class=\"keyword\">size_t</span>&gt;</span><br><span class=\"line\"> _M_need_rehash(<span class=\"keyword\">size_t</span> __n_bkt, <span class=\"keyword\">size_t</span> __n_elt, <span class=\"keyword\">size_t</span> __n_ins) <span class=\"keyword\">noexcept</span> &#123;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (__n_elt + __n_ins &gt;= _M_next_resize) &#123;</span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">long</span> <span class=\"keyword\">double</span> __min_bkts = (__n_elt + __n_ins) / (<span class=\"keyword\">long</span> <span class=\"keyword\">double</span>)_M_max_load_factor;</span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">if</span> (__min_bkts &gt;= __n_bkt)</span><br><span class=\"line\">      <span class=\"comment\">//  这个是需要rehash 时返回的策略</span></span><br><span class=\"line\">      <span class=\"keyword\">return</span> std::<span class=\"built_in\">make_pair</span>(<span class=\"literal\">true</span>, </span><br><span class=\"line\">                            _M_next_bkt(std::max&lt;<span class=\"keyword\">size_t</span>&gt;(__builtin_floor(__min_bkts) + <span class=\"number\">1</span>,</span><br><span class=\"line\">                                                         __n_bkt * _S_growth_factor)));</span><br><span class=\"line\"></span><br><span class=\"line\">        _M_next_resize  = __builtin_floor(__n_bkt * (<span class=\"keyword\">long</span> <span class=\"keyword\">double</span>)_M_max_load_factor);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> std::<span class=\"built_in\">make_pair</span>(<span class=\"literal\">false</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">     </span><br><span class=\"line\">      <span class=\"keyword\">return</span> std::<span class=\"built_in\">make_pair</span>(<span class=\"literal\">false</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">size_t</span> _M_next_bkt(<span class=\"keyword\">size_t</span> __n) <span class=\"keyword\">noexcept</span> &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">auto</span> __max_width = std::min&lt;<span class=\"keyword\">size_t</span>&gt;(<span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(<span class=\"keyword\">size_t</span>), <span class=\"number\">8</span>);           <span class=\"comment\">// 8 个字节</span></span><br><span class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">auto</span> __max_bkt   = <span class=\"built_in\">size_t</span>(<span class=\"number\">1</span>) &lt;&lt; (__max_width * __CHAR_BIT__ - <span class=\"number\">1</span>); <span class=\"comment\">// 2 ^ 63</span></span><br><span class=\"line\">  <span class=\"keyword\">size_t</span> __res           = __clp2(__n);        <span class=\"comment\">// 计算大于等于 n 的最小的2的幂</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (__res == __n) __res &lt;&lt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (__res == <span class=\"number\">0</span>) __res = __max_bkt;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// Set next resize to the max value so that we never try to rehash again</span></span><br><span class=\"line\">  <span class=\"comment\">// as we already reach the biggest possible bucket number.</span></span><br><span class=\"line\">  <span class=\"comment\">// Note that it might result in max_load_factor not being respected.</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (__res == __max_bkt)</span><br><span class=\"line\">    _M_next_resize = <span class=\"built_in\">size_t</span>(<span class=\"number\">-1</span>);</span><br><span class=\"line\">  <span class=\"keyword\">else</span></span><br><span class=\"line\">    _M_next_resize = __builtin_ceil(__res * (<span class=\"keyword\">long</span> <span class=\"keyword\">double</span>)_M_max_load_factor);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> __res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中，在这个类的前面有定义：</p>\n<blockquote>\n<ul>\n<li><strong><em>_M_max_load_factor</em></strong> 初始化为 1.0</li>\n<li><strong><em>static const size_t _S_growth_factor = 2;</em></strong></li>\n</ul>\n</blockquote>\n<p>整个扩容的策略大致是按照2倍的策略增长，但是并不严格按照。在MSVC中按照的是8倍的扩充策略。</p>\n<h4 id=\"多线程下的-std-unordered-map\"><a href=\"#多线程下的-std-unordered-map\" class=\"headerlink\" title=\"多线程下的 std::unordered_map\"></a>多线程下的 <em>std::unordered_map</em></h4><p><code>STL</code>中的 哈希表 是线程不安全的（其实 <code>STL</code> 库都是线程不安全的）。 比如两个线程同时向 <em>std::unordered_map</em> 中插入数据，当发生<em>rehash</em>时，如果不加锁，可能导致两个线程都会产生<em>rehash</em>。</p>\n<p><strong>如何优化 多线程读写操作？这里要借鉴下java的分段锁。</strong></p>\n<h4 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h4><ul>\n<li><a href=\"http://c.biancheng.net/view/3437.html\">hash</a></li>\n<li><a href=\"http://c.biancheng.net/view/7235.html\">std::unordered_map底层原理</a></li>\n<li>g++ 中 <em>std::unordered_map</em> 的实现</li>\n</ul>\n<h3 id=\"map-与-红黑树\"><a href=\"#map-与-红黑树\" class=\"headerlink\" title=\"map 与 红黑树.\"></a><em>map</em> 与 红黑树.</h3><ul>\n<li><p>红黑树的规则</p>\n<ol>\n<li>树根始终为黑色</li>\n<li>外部节点均为黑色</li>\n<li>其余节点若为红色，则器孩子节点必为黑色</li>\n<li>从任一外部外部节点到根节点的沿途，黑色节点的数目相等</li>\n</ol>\n<p>条件1和2说明，红色节点均是内部节点，其父节点及左、右孩子节点必然存在；另外条件3说明，红节点之父必为黑色，因此树中任一通路都不含相邻的红节点</p>\n</li>\n<li><p>红黑树的效率为什么比AVL树高?如果只有查询操作哪种树的效率高?</p>\n<p>红黑树的效率高,是因为不需要像<code>AVL</code>树那样,为了维护高度平衡性,而不断地动态调整以维护左右子树高度差不超过1.红黑树降低了对平衡度的要求,以减少每次插入/删除操作时的动态调整次数.但是就查询效率而言,是不如<code>AVL</code>树的.</p>\n</li>\n</ul>\n<h2 id=\"工具\"><a href=\"#工具\" class=\"headerlink\" title=\"工具\"></a>工具</h2><h4 id=\"如何进行性能排查？找出性能瓶颈？性能测试？有什么工具：\"><a href=\"#如何进行性能排查？找出性能瓶颈？性能测试？有什么工具：\" class=\"headerlink\" title=\"如何进行性能排查？找出性能瓶颈？性能测试？有什么工具：\"></a>如何进行性能排查？找出性能瓶颈？性能测试？有什么工具：</h4><ul>\n<li><em>valgrind</em> :可以查找代码问题<h4 id=\"GDB学习参考链接\"><a href=\"#GDB学习参考链接\" class=\"headerlink\" title=\"GDB学习参考链接\"></a>GDB学习参考链接</h4></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2879\">GDB学习1</a></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2880\">GDB学习2</a></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2881\">GDB学习3</a></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2882\">GDB学习4</a></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2883\">GDB学习5</a></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2884\">GDB学习6</a></li>\n<li><a href=\"https://blog.csdn.net/haoel/article/details/2885\">GDB学习7</a></li>\n</ul>\n","slug":"Cpp","updated":"2020-08-28T15:15:24.627Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/08/28/Cpp/","excerpt":"","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"notebook","slug":"notebook","permalink":"https://blog.providencezhang.cn/tags/notebook/"}]},{"title":"C++_boost_library","date":"2020-07-28T18:15:03.000Z","path":"2020/07/29/C-boost-library/","text":"C++ boost library 使用指北目前版本：1.73.0 Window boost official getting startedOfficial document Signals2 解读观察者模式代码实现：","raw":"---\ntitle: C++_boost_library\ndate: 2020-07-29 02:15:03\ntags:\n    - C++\n    - boost\n---\n\n# C++ boost library 使用指北\n\n目前版本：1.73.0  \n\n[Window boost official getting started](https://www.boost.org/doc/libs/1_73_0/more/getting_started/windows.html)  \n[Official document](https://www.boost.org/doc/libs/1_73_0)  \n\n## Signals2 解读\n\n观察者模式代码实现：\n\n","content":"<h1 id=\"C-boost-library-使用指北\"><a href=\"#C-boost-library-使用指北\" class=\"headerlink\" title=\"C++ boost library 使用指北\"></a>C++ boost library 使用指北</h1><p>目前版本：1.73.0  </p>\n<p><a href=\"https://www.boost.org/doc/libs/1_73_0/more/getting_started/windows.html\">Window boost official getting started</a><br><a href=\"https://www.boost.org/doc/libs/1_73_0\">Official document</a>  </p>\n<h2 id=\"Signals2-解读\"><a href=\"#Signals2-解读\" class=\"headerlink\" title=\"Signals2 解读\"></a>Signals2 解读</h2><p>观察者模式代码实现：</p>\n","slug":"C-boost-library","updated":"2020-08-06T07:05:28.078Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/07/29/C-boost-library/","excerpt":"","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"boost","slug":"boost","permalink":"https://blog.providencezhang.cn/tags/boost/"}]},{"title":"stl-implements && code practices","date":"2020-07-06T03:13:02.000Z","path":"2020/07/06/stl-implement/","text":"自己实现部分STL（Standard Template Library）容器部分List智能指针SharedPtr ver11234567891011121314151617181920// mysharedptr.h#pragma onceusing namespace std;template&lt;class T&gt;class MySharedPtr&#123;public: MySharedPtr(T* _p); MySharedPtr(const MySharedPtr&amp; r); MySharedPtr&amp; operator=(const MySharedPtr&amp; r); T operator*(); ~MySharedPtr(); int use_count();private: T* p; int* count;&#125;; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// mysharedptr.cpp#include &quot;mysharedptr.h&quot;#include &lt;iostream&gt;using namespace std;template&lt;class T&gt;MySharedPtr&lt;T&gt;::MySharedPtr(T* _p):p(_p)&#123; cout &lt;&lt; &quot;constructor&quot; &lt;&lt; endl; count = new int(0); if (p != nullptr) *count = 1;&#125;template MySharedPtr&lt;int&gt;::MySharedPtr(int* _p); // declaration和definition如果不放在一起的写法，这里只用到了构造和析构，如果用别的方法也应该加上这个声明template&lt;class T&gt;MySharedPtr&lt;T&gt;::MySharedPtr(const MySharedPtr&amp; r) &#123; cout &lt;&lt; &quot;copy constructor&quot; &lt;&lt; endl; p = r.p; count = r.count; *r.count++;&#125;template&lt;class T&gt;MySharedPtr&lt;T&gt;&amp; MySharedPtr&lt;T&gt;::operator=(const MySharedPtr&amp; r) &#123; if (-- * count == 0) &#123; delete p; delete count; &#125; p = r.p; count = r.count; *r.count++; return *this;&#125;template&lt;class T&gt;T MySharedPtr&lt;T&gt;::operator*() &#123; return *p;&#125;template&lt;class T&gt;MySharedPtr&lt;T&gt;::~MySharedPtr()&#123; if (-- * count == 0) &#123; delete p; delete count; &#125;&#125;template MySharedPtr&lt;int&gt;::~MySharedPtr(); // declaration和definition如果不放在一起的写法template&lt;class T&gt;int MySharedPtr&lt;T&gt;::use_count() &#123; return *count;&#125; 类模板的声明和定义应该放在一起，这里是不放在一起的写法 SharedPtr ver212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273template&lt;class T&gt;class SharedPtr&#123;public: SharedPtr(); SharedPtr(T* p); SharedPtr(SharedPtr&amp; sp); ~SharedPtr(); SharedPtr&amp; operator= (const SharedPtr&amp; sp); int use_count();private: T* p; int* refCount;&#125;;template&lt;class T&gt;SharedPtr&lt;T&gt;::SharedPtr():p(nullptr),refCount(new int(0))&#123;&#125;template&lt;class T&gt;SharedPtr&lt;T&gt;::SharedPtr(T* _p) : p(_p), refCount(new int(1))&#123;&#125;template&lt;class T&gt;SharedPtr&lt;T&gt;::SharedPtr(SharedPtr&amp; sp) : p(sp.p), refCount(&amp;(++*(sp.refCount)))&#123;&#125;template&lt;class T&gt;SharedPtr&lt;T&gt;::~SharedPtr()&#123; if (p &amp;&amp; --*refCount == 0) &#123; delete p; delete refCount; &#125;&#125;template&lt;class T&gt;SharedPtr&lt;T&gt;&amp; SharedPtr&lt;T&gt;::operator= (const SharedPtr&amp; other) &#123; if (this == &amp;other) return *this; ++* other.refCount; if (-- * refCount == 0) &#123; delete p; delete refCount; &#125; p = other.p; refCount = other.refCount; return *this;&#125;template&lt;class T&gt;int SharedPtr&lt;T&gt;::use_count()&#123; return *refCount;&#125;int main() &#123; int* p = new int(3); SharedPtr&lt;int&gt; sp(p); SharedPtr&lt;int&gt; ssp(p); SharedPtr&lt;int&gt; sssp(sp); cout &lt;&lt; sp.use_count() &lt;&lt; &quot; &quot; &lt;&lt; ssp.use_count() &lt;&lt; &quot; &quot; &lt;&lt; sssp.use_count() &lt;&lt; endl; // output: 2 1 2 return 0;&#125; C++11多线程参考资料参考资料2参考资料3","raw":"---\ntitle: stl-implements && code practices\ndate: 2020-07-06 11:13:02\ntags:\n    - stl\n    - C/C++\n    - 智能指针\n    - 多线程\n---\n\n# 自己实现部分STL（Standard Template Library）\n\n## 容器部分\n\n### List\n\n## 智能指针\n\n### SharedPtr ver1\n\n``` C++\n// mysharedptr.h\n\n#pragma once\nusing namespace std;\n\ntemplate<class T>\nclass MySharedPtr\n{\npublic:\n\tMySharedPtr(T* _p);\n\tMySharedPtr(const MySharedPtr& r);\n\tMySharedPtr& operator=(const MySharedPtr& r);\n\tT operator*();\n\t~MySharedPtr();\n\tint use_count();\n\nprivate:\n\tT* p;\n\tint* count;\n};\n```\n\n``` C++\n// mysharedptr.cpp\n\n#include \"mysharedptr.h\"\n#include <iostream>\nusing namespace std;\n\ntemplate<class T>\nMySharedPtr<T>::MySharedPtr(T* _p):p(_p){\n\tcout << \"constructor\" << endl;\n\tcount = new int(0);\n\tif (p != nullptr)\n\t\t*count = 1;\n}\ntemplate MySharedPtr<int>::MySharedPtr(int* _p); // declaration和definition如果不放在一起的写法，这里只用到了构造和析构，如果用别的方法也应该加上这个声明\n\ntemplate<class T>\nMySharedPtr<T>::MySharedPtr(const MySharedPtr& r) {\n\tcout << \"copy constructor\" << endl;\n\tp = r.p;\n\tcount = r.count;\n\t*r.count++;\n}\n\ntemplate<class T>\nMySharedPtr<T>& MySharedPtr<T>::operator=(const MySharedPtr& r) {\n\tif (-- * count == 0) {\n\t\tdelete p;\n\t\tdelete count;\n\t}\n\tp = r.p;\n\tcount = r.count;\n\t*r.count++;\n\treturn *this;\n}\n\ntemplate<class T>\nT MySharedPtr<T>::operator*() {\n\treturn *p;\n}\n\ntemplate<class T>\nMySharedPtr<T>::~MySharedPtr(){\n\tif (-- * count == 0) {\n\t\tdelete p;\n\t\tdelete count;\n\t}\n}\n\ntemplate MySharedPtr<int>::~MySharedPtr(); // declaration和definition如果不放在一起的写法\n\ntemplate<class T>\nint MySharedPtr<T>::use_count() {\n\treturn *count;\n}\n```\n类模板的声明和定义应该放在一起，这里是不放在一起的写法\n\n\n### SharedPtr ver2\n\n``` C++\ntemplate<class T>\nclass SharedPtr\n{\npublic:\n\tSharedPtr();\n    SharedPtr(T* p);\n    SharedPtr(SharedPtr& sp);\n\t~SharedPtr();\n\n    SharedPtr& operator= (const SharedPtr& sp);\n    int use_count();\n\nprivate:\n    T* p;\n    int* refCount;\n};\n\ntemplate<class T>\nSharedPtr<T>::SharedPtr():p(nullptr),refCount(new int(0))\n{\n}\n\ntemplate<class T>\nSharedPtr<T>::SharedPtr(T* _p) : p(_p), refCount(new int(1))\n{\n}\n\ntemplate<class T>\nSharedPtr<T>::SharedPtr(SharedPtr& sp) : p(sp.p), refCount(&(++*(sp.refCount)))\n{\n}\n\ntemplate<class T>\nSharedPtr<T>::~SharedPtr()\n{\n    if (p && --*refCount == 0) {\n        delete p;\n        delete refCount;\n    }\n}\n\ntemplate<class T>\nSharedPtr<T>& SharedPtr<T>::operator= (const SharedPtr& other) {\n    if (this == &other)\n        return *this;\n\n    ++* other.refCount;\n    if (-- * refCount == 0) {\n        delete p;\n        delete refCount;\n    }\n\n    p = other.p;\n    refCount = other.refCount;\n    return *this;\n}\n\ntemplate<class T>\nint SharedPtr<T>::use_count(){\n    return *refCount;\n}\n\n\nint main() {\n    int* p = new int(3);\n    SharedPtr<int> sp(p);\n    SharedPtr<int> ssp(p);\n    SharedPtr<int> sssp(sp);\n    cout << sp.use_count() << \" \" << ssp.use_count() << \" \" << sssp.use_count() << endl;\n\t// output: 2 1 2\n    return 0;\n}\n\n```\n\n\n## C++11多线程\n\n[参考资料](https://www.cnblogs.com/DOMLX/p/10945309.html)\n[参考资料2](https://zhuanlan.zhihu.com/p/77999255)\n[参考资料3](https://www.jianshu.com/u/88ad4f76eb79)","content":"<h1 id=\"自己实现部分STL（Standard-Template-Library）\"><a href=\"#自己实现部分STL（Standard-Template-Library）\" class=\"headerlink\" title=\"自己实现部分STL（Standard Template Library）\"></a>自己实现部分STL（Standard Template Library）</h1><h2 id=\"容器部分\"><a href=\"#容器部分\" class=\"headerlink\" title=\"容器部分\"></a>容器部分</h2><h3 id=\"List\"><a href=\"#List\" class=\"headerlink\" title=\"List\"></a>List</h3><h2 id=\"智能指针\"><a href=\"#智能指针\" class=\"headerlink\" title=\"智能指针\"></a>智能指针</h2><h3 id=\"SharedPtr-ver1\"><a href=\"#SharedPtr-ver1\" class=\"headerlink\" title=\"SharedPtr ver1\"></a>SharedPtr ver1</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// mysharedptr.h</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> once</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MySharedPtr</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"built_in\">MySharedPtr</span>(T* _p);</span><br><span class=\"line\">\t<span class=\"built_in\">MySharedPtr</span>(<span class=\"keyword\">const</span> MySharedPtr&amp; r);</span><br><span class=\"line\">\tMySharedPtr&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> MySharedPtr&amp; r);</span><br><span class=\"line\">\tT <span class=\"keyword\">operator</span>*();</span><br><span class=\"line\">\t~<span class=\"built_in\">MySharedPtr</span>();</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">use_count</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">\tT* p;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span>* count;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// mysharedptr.cpp</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;mysharedptr.h&quot;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">MySharedPtr&lt;T&gt;::<span class=\"built_in\">MySharedPtr</span>(T* _p):<span class=\"built_in\">p</span>(_p)&#123;</span><br><span class=\"line\">\tcout &lt;&lt; <span class=\"string\">&quot;constructor&quot;</span> &lt;&lt; endl;</span><br><span class=\"line\">\tcount = <span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (p != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">\t\t*count = <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">template</span> MySharedPtr&lt;<span class=\"keyword\">int</span>&gt;::<span class=\"built_in\">MySharedPtr</span>(<span class=\"keyword\">int</span>* _p); <span class=\"comment\">// declaration和definition如果不放在一起的写法，这里只用到了构造和析构，如果用别的方法也应该加上这个声明</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">MySharedPtr&lt;T&gt;::<span class=\"built_in\">MySharedPtr</span>(<span class=\"keyword\">const</span> MySharedPtr&amp; r) &#123;</span><br><span class=\"line\">\tcout &lt;&lt; <span class=\"string\">&quot;copy constructor&quot;</span> &lt;&lt; endl;</span><br><span class=\"line\">\tp = r.p;</span><br><span class=\"line\">\tcount = r.count;</span><br><span class=\"line\">\t*r.count++;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">MySharedPtr&lt;T&gt;&amp; MySharedPtr&lt;T&gt;::<span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> MySharedPtr&amp; r) &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (-- * count == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> p;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> count;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tp = r.p;</span><br><span class=\"line\">\tcount = r.count;</span><br><span class=\"line\">\t*r.count++;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">T MySharedPtr&lt;T&gt;::<span class=\"keyword\">operator</span>*() &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> *p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">MySharedPtr&lt;T&gt;::~<span class=\"built_in\">MySharedPtr</span>()&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (-- * count == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> p;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> count;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> MySharedPtr&lt;<span class=\"keyword\">int</span>&gt;::~<span class=\"built_in\">MySharedPtr</span>(); <span class=\"comment\">// declaration和definition如果不放在一起的写法</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> MySharedPtr&lt;T&gt;::<span class=\"built_in\">use_count</span>() &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> *count;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>类模板的声明和定义应该放在一起，这里是不放在一起的写法</p>\n<h3 id=\"SharedPtr-ver2\"><a href=\"#SharedPtr-ver2\" class=\"headerlink\" title=\"SharedPtr ver2\"></a>SharedPtr ver2</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SharedPtr</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"built_in\">SharedPtr</span>();</span><br><span class=\"line\">    <span class=\"built_in\">SharedPtr</span>(T* p);</span><br><span class=\"line\">    <span class=\"built_in\">SharedPtr</span>(SharedPtr&amp; sp);</span><br><span class=\"line\">\t~<span class=\"built_in\">SharedPtr</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    SharedPtr&amp; <span class=\"keyword\">operator</span>= (<span class=\"keyword\">const</span> SharedPtr&amp; sp);</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">use_count</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    T* p;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>* refCount;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">SharedPtr&lt;T&gt;::<span class=\"built_in\">SharedPtr</span>():<span class=\"built_in\">p</span>(<span class=\"literal\">nullptr</span>),<span class=\"built_in\">refCount</span>(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>))</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">SharedPtr&lt;T&gt;::<span class=\"built_in\">SharedPtr</span>(T* _p) : <span class=\"built_in\">p</span>(_p), <span class=\"built_in\">refCount</span>(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">1</span>))</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">SharedPtr&lt;T&gt;::<span class=\"built_in\">SharedPtr</span>(SharedPtr&amp; sp) : <span class=\"built_in\">p</span>(sp.p), <span class=\"built_in\">refCount</span>(&amp;(++*(sp.refCount)))</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">SharedPtr&lt;T&gt;::~<span class=\"built_in\">SharedPtr</span>()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p &amp;&amp; --*refCount == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> p;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> refCount;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\">SharedPtr&lt;T&gt;&amp; SharedPtr&lt;T&gt;::<span class=\"keyword\">operator</span>= (<span class=\"keyword\">const</span> SharedPtr&amp; other) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span> == &amp;other)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    ++* other.refCount;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (-- * refCount == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> p;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> refCount;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    p = other.p;</span><br><span class=\"line\">    refCount = other.refCount;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">T</span>&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> SharedPtr&lt;T&gt;::<span class=\"built_in\">use_count</span>()&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> *refCount;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>* p = <span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"function\">SharedPtr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">sp</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">SharedPtr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">ssp</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">SharedPtr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">sssp</span><span class=\"params\">(sp)</span></span>;</span><br><span class=\"line\">    cout &lt;&lt; sp.<span class=\"built_in\">use_count</span>() &lt;&lt; <span class=\"string\">&quot; &quot;</span> &lt;&lt; ssp.<span class=\"built_in\">use_count</span>() &lt;&lt; <span class=\"string\">&quot; &quot;</span> &lt;&lt; sssp.<span class=\"built_in\">use_count</span>() &lt;&lt; endl;</span><br><span class=\"line\">\t<span class=\"comment\">// output: 2 1 2</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"C-11多线程\"><a href=\"#C-11多线程\" class=\"headerlink\" title=\"C++11多线程\"></a>C++11多线程</h2><p><a href=\"https://www.cnblogs.com/DOMLX/p/10945309.html\">参考资料</a><br><a href=\"https://zhuanlan.zhihu.com/p/77999255\">参考资料2</a><br><a href=\"https://www.jianshu.com/u/88ad4f76eb79\">参考资料3</a></p>\n","slug":"stl-implement","updated":"2020-10-13T07:46:49.365Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/07/06/stl-implement/","excerpt":"","categories":[],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://blog.providencezhang.cn/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"stl","slug":"stl","permalink":"https://blog.providencezhang.cn/tags/stl/"},{"name":"C/C++","slug":"C-C","permalink":"https://blog.providencezhang.cn/tags/C-C/"},{"name":"智能指针","slug":"智能指针","permalink":"https://blog.providencezhang.cn/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"}]},{"title":"C++中的设计模式","date":"2020-06-14T07:39:46.000Z","path":"2020/06/14/C-Singleton/","text":"1.单例模式下面的代码为C++中单例模式的实现，需要注意的是instance的初始化，这是因为类的成员变量在使用前必须先初始化。懒汉模式： 123456789101112131415161718192021222324252627class Singleton &#123;private: static Singleton* instance; Singleton() &#123;&#125;;public: static Singleton* GetInstance(); void func();&#125;;Singleton* Singleton::GetInstance() &#123; if (!instance) &#123; instance = new Singleton(); &#125; return instance;&#125;void Singleton::func() &#123; cout &lt;&lt; &quot;hello&quot; &lt;&lt; endl;&#125;Singleton* Singleton::instance = nullptr; // 记得初始化int main() &#123; Singleton* ins = Singleton::GetInstance(); ins-&gt;func(); return 0;&#125; 为了避免多线程创建出多个instance实例（C++的new非线程安全），应使用饿汉模式：12345678910111213141516171819202122232425class Singleton &#123;private: static Singleton* instance; Singleton() &#123;&#125;;public: static Singleton* GetInstance(); void func();&#125;;Singleton* Singleton::GetInstance() &#123; // 不再需要判空创建 return instance;&#125;void Singleton::func() &#123; cout &lt;&lt; &quot;hello&quot; &lt;&lt; endl;&#125;Singleton* Singleton::instance = new Singleton(); // 最开始就初始化实例int main() &#123; Singleton* ins = Singleton::GetInstance(); ins-&gt;func(); return 0;&#125; 2.命令模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Command&#123;public: string name; virtual void Execute() &#123; cout &lt;&lt; &quot;execute:&quot; &lt;&lt; name &lt;&lt; endl; &#125; void Recall() &#123; cout &lt;&lt; &quot;recall:&quot; &lt;&lt; name &lt;&lt; endl; &#125;&#125;;class AddCommand : public Command &#123;public: virtual void Execute() &#123; cout &lt;&lt; &quot;addcommand execute&quot; &lt;&lt; endl; &#125; void Recall() &#123; cout &lt;&lt; &quot;addcommand recall&quot; &lt;&lt; endl; &#125;&#125;;class CommandManager &#123;public: void Do(Command c) &#123; c.Execute(); if (dq.size() == capacity) dq.pop_front(); dq.push_back(c); &#125; void Undo() &#123; Command tmp = dq.back(); tmp.Recall(); dq.pop_back(); &#125; void Redo() &#123; &#125;private: int capacity = 10; deque&lt;Command&gt; dq;&#125;;int main() &#123; Command* cp = new AddCommand(); cp-&gt;name = &quot;ac&quot;; cp-&gt;Execute(); cp-&gt;Recall(); return 0;&#125;","raw":"---\ntitle: C++中的设计模式\ndate: 2020-06-14 15:39:46\ntags:\n    - 设计模式\n    - C++\n    - 单例模式\n    - 命令模式\n---\n\n# 1.单例模式\n\n下面的代码为C++中单例模式的实现，需要注意的是instance的初始化，这是因为类的成员变量在使用前必须先初始化。\n懒汉模式：\n\n``` C++\nclass Singleton {\nprivate:\n\tstatic Singleton* instance;\n\tSingleton() {};\npublic:\n\tstatic Singleton* GetInstance();\n\tvoid func();\n};\n\nSingleton* Singleton::GetInstance() {\n\tif (!instance) {\n\t\tinstance = new Singleton();\n\t}\n\treturn instance;\n}\n\nvoid Singleton::func() {\n\tcout << \"hello\" << endl;\n}\n\nSingleton* Singleton::instance = nullptr; // 记得初始化\n\nint main() {\n\tSingleton* ins = Singleton::GetInstance();\n\tins->func();\n\treturn 0;\n}\n```\n\n为了避免多线程创建出多个instance实例（C++的new非线程安全），应使用饿汉模式：\n``` C++\nclass Singleton {\nprivate:\n\tstatic Singleton* instance;\n\tSingleton() {};\npublic:\n\tstatic Singleton* GetInstance();\n\tvoid func();\n};\n\nSingleton* Singleton::GetInstance() {\n    // 不再需要判空创建\n\treturn instance;\n}\n\nvoid Singleton::func() {\n\tcout << \"hello\" << endl;\n}\n\nSingleton* Singleton::instance = new Singleton(); // 最开始就初始化实例\n\nint main() {\n\tSingleton* ins = Singleton::GetInstance();\n\tins->func();\n\treturn 0;\n}\n```\n\n\n# 2.命令模式\n\n``` C++\nclass Command\n{\npublic:\n\tstring name;\n\tvirtual void Execute() {\n\t\tcout << \"execute:\" << name << endl;\n\t}\n\n\tvoid Recall() {\n\t\tcout << \"recall:\" << name << endl;\n\t}\n};\n\nclass AddCommand : public Command {\npublic:\n\tvirtual void Execute() {\n\t\tcout << \"addcommand execute\" << endl;\n\t}\n\n\tvoid Recall() {\n\t\tcout << \"addcommand recall\" << endl;\n\t}\n};\n\nclass CommandManager {\npublic:\n\tvoid Do(Command c) {\n\t\tc.Execute();\n\t\tif (dq.size() == capacity) dq.pop_front();\n\t\tdq.push_back(c);\n\t}\n\n\tvoid Undo() {\n\t\tCommand tmp = dq.back();\n\t\ttmp.Recall();\n\t\tdq.pop_back();\n\t}\n\n\tvoid Redo() {\n\n\t}\nprivate:\n\tint capacity = 10;\n\tdeque<Command> dq;\n};\n\n\nint main() {\n\tCommand* cp = new AddCommand();\n\tcp->name = \"ac\";\n\tcp->Execute();\n\tcp->Recall();\n\treturn 0;\n}\n```","content":"<h1 id=\"1-单例模式\"><a href=\"#1-单例模式\" class=\"headerlink\" title=\"1.单例模式\"></a>1.单例模式</h1><p>下面的代码为C++中单例模式的实现，需要注意的是instance的初始化，这是因为类的成员变量在使用前必须先初始化。<br>懒汉模式：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Singleton</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">static</span> Singleton* instance;</span><br><span class=\"line\">\t<span class=\"built_in\">Singleton</span>() &#123;&#125;;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">static</span> Singleton* <span class=\"title\">GetInstance</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Singleton* <span class=\"title\">Singleton::GetInstance</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (!instance) &#123;</span><br><span class=\"line\">\t\tinstance = <span class=\"keyword\">new</span> <span class=\"built_in\">Singleton</span>();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Singleton::func</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tcout &lt;&lt; <span class=\"string\">&quot;hello&quot;</span> &lt;&lt; endl;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Singleton* Singleton::instance = <span class=\"literal\">nullptr</span>; <span class=\"comment\">// 记得初始化</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tSingleton* ins = Singleton::<span class=\"built_in\">GetInstance</span>();</span><br><span class=\"line\">\tins-&gt;<span class=\"built_in\">func</span>();</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>为了避免多线程创建出多个instance实例（C++的new非线程安全），应使用饿汉模式：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Singleton</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">static</span> Singleton* instance;</span><br><span class=\"line\">\t<span class=\"built_in\">Singleton</span>() &#123;&#125;;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">static</span> Singleton* <span class=\"title\">GetInstance</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Singleton* <span class=\"title\">Singleton::GetInstance</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 不再需要判空创建</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Singleton::func</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tcout &lt;&lt; <span class=\"string\">&quot;hello&quot;</span> &lt;&lt; endl;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Singleton* Singleton::instance = <span class=\"keyword\">new</span> <span class=\"built_in\">Singleton</span>(); <span class=\"comment\">// 最开始就初始化实例</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tSingleton* ins = Singleton::<span class=\"built_in\">GetInstance</span>();</span><br><span class=\"line\">\tins-&gt;<span class=\"built_in\">func</span>();</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"2-命令模式\"><a href=\"#2-命令模式\" class=\"headerlink\" title=\"2.命令模式\"></a>2.命令模式</h1><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Command</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\tstring name;</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">Execute</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\tcout &lt;&lt; <span class=\"string\">&quot;execute:&quot;</span> &lt;&lt; name &lt;&lt; endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Recall</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\tcout &lt;&lt; <span class=\"string\">&quot;recall:&quot;</span> &lt;&lt; name &lt;&lt; endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AddCommand</span> :</span> <span class=\"keyword\">public</span> Command &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">Execute</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\tcout &lt;&lt; <span class=\"string\">&quot;addcommand execute&quot;</span> &lt;&lt; endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Recall</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\tcout &lt;&lt; <span class=\"string\">&quot;addcommand recall&quot;</span> &lt;&lt; endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CommandManager</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Do</span><span class=\"params\">(Command c)</span> </span>&#123;</span><br><span class=\"line\">\t\tc.<span class=\"built_in\">Execute</span>();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (dq.<span class=\"built_in\">size</span>() == capacity) dq.<span class=\"built_in\">pop_front</span>();</span><br><span class=\"line\">\t\tdq.<span class=\"built_in\">push_back</span>(c);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Undo</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\tCommand tmp = dq.<span class=\"built_in\">back</span>();</span><br><span class=\"line\">\t\ttmp.<span class=\"built_in\">Recall</span>();</span><br><span class=\"line\">\t\tdq.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Redo</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> capacity = <span class=\"number\">10</span>;</span><br><span class=\"line\">\tdeque&lt;Command&gt; dq;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tCommand* cp = <span class=\"keyword\">new</span> <span class=\"built_in\">AddCommand</span>();</span><br><span class=\"line\">\tcp-&gt;name = <span class=\"string\">&quot;ac&quot;</span>;</span><br><span class=\"line\">\tcp-&gt;<span class=\"built_in\">Execute</span>();</span><br><span class=\"line\">\tcp-&gt;<span class=\"built_in\">Recall</span>();</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","slug":"C-Singleton","updated":"2020-08-27T08:29:10.266Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/06/14/C-Singleton/","excerpt":"","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"设计模式","slug":"设计模式","permalink":"https://blog.providencezhang.cn/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://blog.providencezhang.cn/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"命令模式","slug":"命令模式","permalink":"https://blog.providencezhang.cn/tags/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/"}]},{"title":"Unity中的多线程与线程池应用","date":"2020-06-05T05:00:19.000Z","path":"2020/06/05/UnityMultiThreading/","text":"Part 1 Unity中的多线程 FileStream读取本地文件 1234567891011byte[] buffer;void LoadFiletoBuffer()&#123; // 假如很卡 Thread.Sleep(3000); // 通过路径加载本地图片 FileStream fs = new FileStream(&quot;C:\\\\Users\\\\Administrator\\\\Downloads\\\\pic.jpg&quot;, FileMode.Open); buffer = new byte[fs.Length]; fs.Read(buffer, 0, buffer.Length); fs.Close();&#125; buffer—&gt;Unity texture2d—&gt;Unity sprite，使用UnityEngine中组件的动作必须在主线程完成，所以这段逻辑不能放到LoadFiletoBuffer中这里使用协程的目的是异步（在buffer加载进来之后）创建texture以及sprite 123456789101112131415161718IEnumerator OnLoad()&#123; while (buffer == null) &#123; yield return 0; &#125; Debug.Log(&quot;load tex&quot;); Texture2D tex = new Texture2D(2, 2); var iSLoad = tex.LoadImage(buffer); tex.Apply(); if (!iSLoad) &#123; Debug.Log(&quot;Texture存在但生成Texture失败!&quot;); &#125; img.sprite = Sprite.Create(tex, new Rect(0, 0, 5939, 3341), Vector2.zero);&#125; 最外层接口，两种方法的区别在于load file这3000ms主线程是否卡死 12345678910111213141516/// &lt;summary&gt;/// 文件流加载图片/// &lt;/summary&gt;void FileStreamLoadTexture()&#123; // load file by sub thread Thread childThread = new Thread(new ThreadStart(LoadFiletoBuffer)); childThread.Start(); //// load file by main thread //LoadFiletoBuffer(); Debug.Log(&quot;start coroutine&quot;); StartCoroutine(&quot;OnLoad&quot;); Debug.Log(&quot;end coroutine&quot;);&#125; Part 2 线程池C# System.Threading.ThreadPool类提供了线程池的实现，都是静态方法，不需要实例化PS： CLR指公共语言运行时(Common Language Runtime)线程池初始化时是没有线程的，线程池里的线程的初始化与其他线程一样，但是在完成任务以后，该线程不会自行销毁，而是以挂起的状态返回到线程池。直到应用程序再次向线程池发出请求时，线程池里挂起的线程就会再度激活执行任务。 参考资料 12345678910111213141516171819202122/// &lt;summary&gt;/// 文件流加载图片/// &lt;/summary&gt;void FileStreamLoadTexture()&#123; //// load file by sub thread //Thread childThread = new Thread(new ThreadStart(LoadFiletoBuffer)); //childThread.Start(); // use thread pool ThreadPool.GetAvailableThreads(out int workerThreads, out int completionProtThreads); // 800 200；out/ref的区别：out不需要初始化 Debug.Log(&quot;Thread Pool1: &quot; + workerThreads + &quot; &quot; + completionProtThreads); ThreadPool.QueueUserWorkItem(new WaitCallback(LoadFiletoBuffer), null); //// load file by main thread //LoadFiletoBuffer(); Debug.Log(&quot;start coroutine&quot;); StartCoroutine(&quot;OnLoad&quot;); Debug.Log(&quot;end coroutine&quot;);&#125; part 3 C#中的async和await属于System.Threading.Task，async/await Task是C#中更先进的，也是微软大力推广的特性，我们在开发中可以尝试使用Task来替代Thread/ThreadPool，处理本地IO和网络IO任务是尽量使用async/await来提高任务执行效率。await后边是个异步方法，也就是说async自定义的异步方法中有一个或者多个await，每个await后边还是一个返回值为 Task\\（返回值为T类型） Task（没有返回值，但是可以查看异步调用的状态） void（调用完就不关心了，没有互动了）的异步方法 最底层这个异步方法往往来自BCL（C#的基础类库，例如WebClient.DownloadStringTaskAsync(url)） 123456789async Task&lt;int&gt; CountCharactersAsync(int id, string site)&#123; Console.WriteLine(&quot;starting countingcharacters&quot;); WebClient wc = new WebClient(); string result = await wc.DownloadStringTaskAsync(new Uri(site)); Console.WriteLine(&quot;countingcharacters completed&quot;); return result.Length;&#125; 20.3.5 Wait()/WaitAll()/WaitAny()20.10 BeginInvoke()和EndInvoke()——《C#图解教程》","raw":"---\ntitle: Unity中的多线程与线程池应用\ndate: 2020-06-05 13:00:19\ntags:\n    - Unity\n    - 多线程\n    - 线程池\n---\n\n# Part 1 Unity中的多线程\n\n* FileStream读取本地文件\n``` C#\nbyte[] buffer;\nvoid LoadFiletoBuffer()\n{\n    // 假如很卡\n    Thread.Sleep(3000);\n    // 通过路径加载本地图片\n    FileStream fs = new FileStream(\"C:\\\\Users\\\\Administrator\\\\Downloads\\\\pic.jpg\", FileMode.Open);\n    buffer = new byte[fs.Length];\n    fs.Read(buffer, 0, buffer.Length);\n    fs.Close();\n}\n```\n\n* buffer-->Unity texture2d-->Unity sprite，使用UnityEngine中组件的动作必须在主线程完成，所以这段逻辑不能放到LoadFiletoBuffer中\n这里使用协程的目的是异步（在buffer加载进来之后）创建texture以及sprite\n``` C#\nIEnumerator OnLoad()\n{\n    while (buffer == null)\n    {\n        yield return 0;\n    }\n    Debug.Log(\"load tex\");\n\n    Texture2D tex = new Texture2D(2, 2);\n    var iSLoad = tex.LoadImage(buffer);\n    tex.Apply();\n    if (!iSLoad)\n    {\n        Debug.Log(\"Texture存在但生成Texture失败!\");\n    }\n\n    img.sprite = Sprite.Create(tex, new Rect(0, 0, 5939, 3341), Vector2.zero);\n}\n```\n\n* 最外层接口，两种方法的区别在于load file这3000ms主线程是否卡死\n``` C#\n/// <summary>\n/// 文件流加载图片\n/// </summary>\nvoid FileStreamLoadTexture()\n{\n    // load file by sub thread\n    Thread childThread = new Thread(new ThreadStart(LoadFiletoBuffer));\n    childThread.Start();\n\n    //// load file by main thread\n    //LoadFiletoBuffer();\n\n    Debug.Log(\"start coroutine\");\n    StartCoroutine(\"OnLoad\");\n    Debug.Log(\"end coroutine\");\n}\n```\n\n# Part 2 线程池\n\nC# System.Threading.ThreadPool类提供了线程池的实现，都是静态方法，不需要实例化  \nPS： CLR指公共语言运行时(Common Language Runtime)  \n线程池初始化时是没有线程的，线程池里的线程的初始化与其他线程一样，但是在完成任务以后，该线程不会自行销毁，而是以挂起的状态返回到线程池。直到应用程序再次向线程池发出请求时，线程池里挂起的线程就会再度激活执行任务。  \n\n[参考资料](https://www.cnblogs.com/scmail81/archive/2018/08/19/9503266.html)\n\n``` C#\n/// <summary>\n/// 文件流加载图片\n/// </summary>\nvoid FileStreamLoadTexture()\n{\n    //// load file by sub thread\n    //Thread childThread = new Thread(new ThreadStart(LoadFiletoBuffer));\n    //childThread.Start();\n\n    // use thread pool\n    ThreadPool.GetAvailableThreads(out int workerThreads, out int completionProtThreads); // 800 200；out/ref的区别：out不需要初始化\n    Debug.Log(\"Thread Pool1: \" + workerThreads + \" \" + completionProtThreads);\n\n    ThreadPool.QueueUserWorkItem(new WaitCallback(LoadFiletoBuffer), null);\n\n    //// load file by main thread\n    //LoadFiletoBuffer();\n\n    Debug.Log(\"start coroutine\");\n    StartCoroutine(\"OnLoad\");\n    Debug.Log(\"end coroutine\");\n}\n```\n\n# part 3 C#中的async和await\n\n属于System.Threading.Task，async/await Task是C#中更先进的，也是微软大力推广的特性，我们在开发中可以尝试使用Task来替代Thread/ThreadPool，处理本地IO和网络IO任务是尽量使用async/await来提高任务执行效率。  \nawait后边是个异步方法，也就是说async自定义的异步方法中有一个或者多个await，每个await后边还是一个返回值为\n* Task\\<T>（返回值为T类型）\n* Task（没有返回值，但是可以查看异步调用的状态）\n* void（调用完就不关心了，没有互动了）的异步方法\n\n最底层这个异步方法往往来自BCL（C#的基础类库，例如WebClient.DownloadStringTaskAsync(url)）  \n\n``` C#\nasync Task<int> CountCharactersAsync(int id, string site){\n    Console.WriteLine(\"starting countingcharacters\");\n    WebClient wc = new WebClient();\n\n    string result = await wc.DownloadStringTaskAsync(new Uri(site));\n\n    Console.WriteLine(\"countingcharacters completed\");\n    return result.Length;\n}\n```\n\n20.3.5 Wait()/WaitAll()/WaitAny()  \n20.10 BeginInvoke()和EndInvoke()  \n——《C#图解教程》","content":"<h1 id=\"Part-1-Unity中的多线程\"><a href=\"#Part-1-Unity中的多线程\" class=\"headerlink\" title=\"Part 1 Unity中的多线程\"></a>Part 1 Unity中的多线程</h1><ul>\n<li><p>FileStream读取本地文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">byte[] buffer;</span><br><span class=\"line\">void LoadFiletoBuffer()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    // 假如很卡</span><br><span class=\"line\">    Thread.Sleep(3000);</span><br><span class=\"line\">    // 通过路径加载本地图片</span><br><span class=\"line\">    FileStream fs = new FileStream(&quot;C:\\\\Users\\\\Administrator\\\\Downloads\\\\pic.jpg&quot;, FileMode.Open);</span><br><span class=\"line\">    buffer = new byte[fs.Length];</span><br><span class=\"line\">    fs.Read(buffer, 0, buffer.Length);</span><br><span class=\"line\">    fs.Close();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>buffer—&gt;Unity texture2d—&gt;Unity sprite，使用UnityEngine中组件的动作必须在主线程完成，所以这段逻辑不能放到LoadFiletoBuffer中<br>这里使用协程的目的是异步（在buffer加载进来之后）创建texture以及sprite</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">IEnumerator OnLoad()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    while (buffer == null)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        yield return 0;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Debug.Log(&quot;load tex&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    Texture2D tex = new Texture2D(2, 2);</span><br><span class=\"line\">    var iSLoad = tex.LoadImage(buffer);</span><br><span class=\"line\">    tex.Apply();</span><br><span class=\"line\">    if (!iSLoad)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Debug.Log(&quot;Texture存在但生成Texture失败!&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    img.sprite = Sprite.Create(tex, new Rect(0, 0, 5939, 3341), Vector2.zero);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>最外层接口，两种方法的区别在于load file这3000ms主线程是否卡死</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/// &lt;summary&gt;</span><br><span class=\"line\">/// 文件流加载图片</span><br><span class=\"line\">/// &lt;/summary&gt;</span><br><span class=\"line\">void FileStreamLoadTexture()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    // load file by sub thread</span><br><span class=\"line\">    Thread childThread = new Thread(new ThreadStart(LoadFiletoBuffer));</span><br><span class=\"line\">    childThread.Start();</span><br><span class=\"line\"></span><br><span class=\"line\">    //// load file by main thread</span><br><span class=\"line\">    //LoadFiletoBuffer();</span><br><span class=\"line\"></span><br><span class=\"line\">    Debug.Log(&quot;start coroutine&quot;);</span><br><span class=\"line\">    StartCoroutine(&quot;OnLoad&quot;);</span><br><span class=\"line\">    Debug.Log(&quot;end coroutine&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h1 id=\"Part-2-线程池\"><a href=\"#Part-2-线程池\" class=\"headerlink\" title=\"Part 2 线程池\"></a>Part 2 线程池</h1><p>C# System.Threading.ThreadPool类提供了线程池的实现，都是静态方法，不需要实例化<br>PS： CLR指公共语言运行时(Common Language Runtime)<br>线程池初始化时是没有线程的，线程池里的线程的初始化与其他线程一样，但是在完成任务以后，该线程不会自行销毁，而是以挂起的状态返回到线程池。直到应用程序再次向线程池发出请求时，线程池里挂起的线程就会再度激活执行任务。  </p>\n<p><a href=\"https://www.cnblogs.com/scmail81/archive/2018/08/19/9503266.html\">参考资料</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/// &lt;summary&gt;</span><br><span class=\"line\">/// 文件流加载图片</span><br><span class=\"line\">/// &lt;/summary&gt;</span><br><span class=\"line\">void FileStreamLoadTexture()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    //// load file by sub thread</span><br><span class=\"line\">    //Thread childThread = new Thread(new ThreadStart(LoadFiletoBuffer));</span><br><span class=\"line\">    //childThread.Start();</span><br><span class=\"line\"></span><br><span class=\"line\">    // use thread pool</span><br><span class=\"line\">    ThreadPool.GetAvailableThreads(out int workerThreads, out int completionProtThreads); // 800 200；out/ref的区别：out不需要初始化</span><br><span class=\"line\">    Debug.Log(&quot;Thread Pool1: &quot; + workerThreads + &quot; &quot; + completionProtThreads);</span><br><span class=\"line\"></span><br><span class=\"line\">    ThreadPool.QueueUserWorkItem(new WaitCallback(LoadFiletoBuffer), null);</span><br><span class=\"line\"></span><br><span class=\"line\">    //// load file by main thread</span><br><span class=\"line\">    //LoadFiletoBuffer();</span><br><span class=\"line\"></span><br><span class=\"line\">    Debug.Log(&quot;start coroutine&quot;);</span><br><span class=\"line\">    StartCoroutine(&quot;OnLoad&quot;);</span><br><span class=\"line\">    Debug.Log(&quot;end coroutine&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"part-3-C-中的async和await\"><a href=\"#part-3-C-中的async和await\" class=\"headerlink\" title=\"part 3 C#中的async和await\"></a>part 3 C#中的async和await</h1><p>属于System.Threading.Task，async/await Task是C#中更先进的，也是微软大力推广的特性，我们在开发中可以尝试使用Task来替代Thread/ThreadPool，处理本地IO和网络IO任务是尽量使用async/await来提高任务执行效率。<br>await后边是个异步方法，也就是说async自定义的异步方法中有一个或者多个await，每个await后边还是一个返回值为</p>\n<ul>\n<li>Task\\<T>（返回值为T类型）</li>\n<li>Task（没有返回值，但是可以查看异步调用的状态）</li>\n<li>void（调用完就不关心了，没有互动了）的异步方法</li>\n</ul>\n<p>最底层这个异步方法往往来自BCL（C#的基础类库，例如WebClient.DownloadStringTaskAsync(url)）  </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">async Task&lt;int&gt; CountCharactersAsync(int id, string site)&#123;</span><br><span class=\"line\">    Console.WriteLine(&quot;starting countingcharacters&quot;);</span><br><span class=\"line\">    WebClient wc = new WebClient();</span><br><span class=\"line\"></span><br><span class=\"line\">    string result = await wc.DownloadStringTaskAsync(new Uri(site));</span><br><span class=\"line\"></span><br><span class=\"line\">    Console.WriteLine(&quot;countingcharacters completed&quot;);</span><br><span class=\"line\">    return result.Length;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>20.3.5 Wait()/WaitAll()/WaitAny()<br>20.10 BeginInvoke()和EndInvoke()<br>——《C#图解教程》</p>\n","slug":"UnityMultiThreading","updated":"2020-06-28T09:11:21.882Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/06/05/UnityMultiThreading/","excerpt":"","categories":[],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://blog.providencezhang.cn/tags/Unity/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.providencezhang.cn/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"线程池","slug":"线程池","permalink":"https://blog.providencezhang.cn/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"可编程渲染管线","date":"2020-04-14T07:49:36.000Z","path":"2020/04/14/hardware3d/","text":"Hardware 3DCOM： framebuffer: 双重缓冲是一个画（用户操作），一个已经画好的传输给显示器做显示，一个称为front，另一个称为back buffer。还可以有多重缓冲，缓冲层数越多，会导致画面延迟加重，但是更加连贯顺滑。原因是有时候front没花完，显示器已经逐像素扫描完一个frame，显示器就得等front buffer。vsync：防tearing，就是等显示器一个frame完成再载入下一个buffer constant buffer: 用来存变换矩阵，目的是用shader控制图形旋转，而不是改变vertices的坐标 shader中对于matric的修饰词 row_major会降低速度 DirectX Math： SIMD(single instruction multiple data) depth buffer shares memory with stencil buffer(模板缓冲): masking like mirror,portals. depth buffer optimized for depth direct toolkit for loading texture会省掉很多工作，所以这里用了GDI+ hlsl intrinsic functions attenuation imGUI使用方法：根目录的header和source文件 + examples里的对应平台文件（例如dx11+win32的四个文件） 3D Fundamentalrasterization rule: left-top rule; 《Unity shader 入门精要》概念合集NDC与视锥体剪裁：视锥体剪裁在cpu中进行，gpu流水线中还有一次culling，是按NDC空间进行剪裁（超出-1到1就裁剪，dx的z-axis是0-1）。这两次剪裁功能相似，第一次的目的是减轻gpu负担。 模板测试（stencil test）：可以理解为深度测试中的深度这个概念有开发者人为设定。 blend（混合）/output merger early-z 数学相关点坐标：\\left[ \\begin{matrix} x \\\\ y \\\\ z \\\\ 1 \\end{matrix} \\right] （如果是行向量，下边变换矩阵要转置）方向矢量：\\left[ \\begin{matrix} x \\\\ y \\\\ z \\\\ 0 \\end{matrix} \\right]基础变换矩阵：\\left[ \\begin{matrix} M_{3*3} & t_{3*1} \\\\ 0_{1*3} & 1 \\end{matrix} \\right]之所以这样设置是为了使变换矩阵的计算结果正确；顶点变换中如果存在平移需要四维矩阵，方向矢量变换使用三维即可 M：旋转缩放；t：平移（如果坐标点或向量是行向量，t的位置要换到左下角） 复合变换依赖顺序，本质原因是矩阵乘法不满足交换律：$P{new} = M{translation} M{rotation} M{scale} P_{old}$ 执行顺序为从右到左，绝大多数情况按照缩放，旋转，平移的顺序 空间变换流程：模型空间-&gt;世界空间-&gt;观察（相机）空间-&gt;剪裁空间（视锥体剔除）-&gt;屏幕空间（剪裁空间转NDC转屏幕像素） 一般来说，模型空间到剪裁空间会合并为MVP矩阵（Model-View-Projection） 光照模型 BRDF（bidirectional reflection distribution function） BRDF经验模型（能量不守恒，简化的数学公式）： Lambert：反射强度不受角度影响，反射角度受平面影响 标准光照模型（Phong）：自发光，高光反射，漫反射，环境光（需要入射光，反射光，表面法线，视角方向） blinn-phong：与phong相比不需要计算反射方向，取而代之的是视角和入射光线的平均值归一化后的结果 基于物理的BRDF模型（判断条件：是否满足交换律，即光路可逆；是否能量守恒）： cook-torrance BRDF：微面元模型用来表示pbs（physical based shading）中的高光，D是法线分布函数，G是阴影遮蔽函数，F是菲涅尔反射函数 ward BRDF 实现细节： 漫反射符合兰伯特定律，即反射光线强度与表面法线和光源方向之间夹角的余弦值成正比 纹理映射纹理放大缩小的问题需要调整Filter Mode（Point,Bilinear,Trilinear）；缩小时最常使用mipmapping（多级渐远纹理技术）：典型的用空间换时间（多33%的空间） bump mapping（凹凸映射）：分为两种，高度纹理（height map）模拟表面位移（displacement），得到一个修改后的法线值，称之为高度映射；另一种是法线纹理（normal map），直接做法线映射 1.在切线空间下进行光照计算；2.在世界空间下计算，前者效率往往优于后者 albedo是tex2D（CG的函数，对纹理进行采样）的结果；ambient是环境光diffuse是漫反射specular是高光 法线纹理（normal map）可以使用DXT5nm的压缩格式，因为相比较普通图，法线纹理只有两个通道必不可少，第三个通道可以通过前两个推导出来，这种压缩方法可以减少内存占用 透明效果Alpha Test/Alpha Blending：透明度测试只有完全透明和完全不透两种可能；透明度混合可以实现半透明 半透物体是开启深度测试但是关闭深度写入的，这导致渲染顺序变得十分重要（因为关闭了深度写入）；应该渲染不透明物体之后再渲染半透明物体；如果都是半透明，按相机距离排序，从后往前渲染，开启深度测试，但是关闭深度写入 双面渲染：unity的Cull指令默认是Back，也就是背对相机的渲染图元不会被渲染 渲染路径更复杂的光照： 前向渲染：颜色缓冲区和深度缓冲区；unity的前向渲染有三种，逐像素处理（最强平行光和重要光源用这种方式），逐顶点处理，球谐函数（spherical harmonics）前向渲染的问题是，场景内有大量光源的情况下性能急剧下降，因为每个光源都要计算一次光照结果（一个光源一个pass） 延迟渲染：G-buffer（Geometry），包含两个pass，第一个使用深度缓冲计算哪些片元可见；第二个计算片元信息，即光照计算不支持抗锯齿；不能处理半透明；对硬件有要求MRT（multiple render targets）Unity的延迟渲染需要提供两个pass：第一个用于渲染G-buffer；第二个用于计算真正的光照模型 APIUnity shader中的矩阵是按行优先的，Unity脚本中有个Matrix4x4是按列优先 UnityRoot/Data/CGIncludes/ 里边有官方提供的.cginc文件，其中例如UnityCG.cginc十分值得学习 《Direct12 3D游戏开发实战》——龙书数学相关view transform矩阵，观察空间到世界空间的坐标变化矩阵为： W = \\left[ \\begin{matrix} u_{x} & u_{y} & u_{z} & 0 \\\\ v_{x} & v_{y} & v_{z} & 0 \\\\ w_{x} & w_{y} & w_{z} & 0 \\\\ Q_{x} & Q_{y} & Q_{z} & 1 \\end{matrix} \\right]其中，Q_{w} = (Q_{x},Q_{y},Q_{z},1)，u_{w} = (u_{x},u_{y},u_{z},0)，v_{w}还有w_{w}分别表示了观察空间中原点，x轴，y轴，z轴相对于世界空间的齐次坐标。相对的，世界空间到观察空间的变化矩阵为W^{-1}，世界矩阵可以分解为一个旋转矩阵和一个平移矩阵的乘积，即W=RT。 V=W^{-1}=(RT)^{-1}=T^{-1}R^{-1}=T^{-1}R^{T}= \\left[ \\begin{matrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ -Q_{x} & -Q_{y} & -Q_{z} & 1 \\end{matrix} \\right] \\left[ \\begin{matrix} u_{x} & u_{y} & u_{z} & 0 \\\\ v_{x} & v_{y} & v_{z} & 0 \\\\ w_{x} & w_{y} & w_{z} & 0 \\\\ 0 & 0 & 0 & 1 \\end{matrix} \\right] = \\left[ \\begin{matrix} u_{x} & u_{y} & u_{z} & 0 \\\\ v_{x} & v_{y} & v_{z} & 0 \\\\ w_{x} & w_{y} & w_{z} & 0 \\\\ -Q_{x} \\cdot u & -Q_{y} \\cdot v & -Q_{z} \\cdot w & 1 \\end{matrix} \\right]由此得到， V= \\left[ \\begin{matrix} u_{x} & u_{y} & u_{z} & 0 \\\\ v_{x} & v_{y} & v_{z} & 0 \\\\ w_{x} & w_{y} & w_{z} & 0 \\\\ -Q_{x} \\cdot u & -Q_{y} \\cdot v & -Q_{z} \\cdot w & 1 \\end{matrix} \\right]Unreal source code review","raw":"---\ntitle: 可编程渲染管线\ndate: 2020-04-14 15:49:36\nmathjax: true\ntags: \n    - Dx12\n    - WindowsApp\n    - COM\n    - Shader\n---\n\n# Hardware 3D\n\nCOM：\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ut5zYcDKGwk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nframebuffer: 双重缓冲是一个画（用户操作），一个已经画好的传输给显示器做显示，一个称为front，另一个称为back buffer。  \n还可以有多重缓冲，缓冲层数越多，会导致画面延迟加重，但是更加连贯顺滑。原因是有时候front没花完，显示器已经逐像素扫描完一个frame，显示器就得等front buffer。  \nvsync：防tearing，就是等显示器一个frame完成再载入下一个buffer  \n\nconstant buffer: 用来存变换矩阵，目的是用shader控制图形旋转，而不是改变vertices的坐标  \n\nshader中对于matric的修饰词 row_major会降低速度  \n\nDirectX Math： SIMD(single instruction multiple data)  \n\ndepth buffer shares memory with stencil buffer(模板缓冲): masking like mirror,portals. depth buffer optimized for depth  \n\ndirect toolkit for loading texture会省掉很多工作，所以这里用了GDI+  \n\n[hlsl intrinsic functions](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-intrinsic-functions)  \n\n[attenuation](http://wiki.ogre3d.org/-Point+Light+Attenuation)\n\n## imGUI\n\n使用方法：根目录的header和source文件 + examples里的对应平台文件（例如dx11+win32的四个文件）  \n\n# 3D Fundamental\n\nrasterization rule: left-top rule;\n\n# 《Unity shader 入门精要》\n\n## 概念合集\n\n[NDC与视锥体剪裁](https://www.zhihu.com/question/304277310)：视锥体剪裁在cpu中进行，gpu流水线中还有一次culling，是按NDC空间进行剪裁（超出-1到1就裁剪，dx的z-axis是0-1）。这两次剪裁功能相似，第一次的目的是减轻gpu负担。  \n\n模板测试（stencil test）：可以理解为深度测试中的深度这个概念有开发者人为设定。  \n\nblend（混合）/output merger\n\nearly-z\n\n## 数学相关\n\n点坐标：$$\\left[ \\begin{matrix}\n        x \\\\\n        y \\\\\n        z \\\\\n        1 \\end{matrix} \\right]$$ （如果是行向量，下边变换矩阵要转置）\n方向矢量：$$\\left[ \\begin{matrix}\n        x \\\\\n        y \\\\\n        z \\\\\n        0 \\end{matrix} \\right]$$\n基础变换矩阵：$$\n\\left[  \\begin{matrix}\n        M_{3*3} & t_{3*1} \\\\\n        0_{1*3} & 1 \n        \\end{matrix}\n\\right]$$\n之所以这样设置是为了使变换矩阵的计算结果正确；顶点变换中如果存在平移需要四维矩阵，方向矢量变换使用三维即可  \n\nM：旋转缩放；t：平移（如果坐标点或向量是行向量，t的位置要换到左下角）  \n\n复合变换依赖顺序，本质原因是矩阵乘法不满足交换律：$P_{new} = M_{translation} M_{rotation} M_{scale} P_{old}$ 执行顺序为从右到左，绝大多数情况按照缩放，旋转，平移的顺序  \n\n空间变换流程：模型空间->世界空间->观察（相机）空间->剪裁空间（视锥体剔除）->屏幕空间（剪裁空间转NDC转屏幕像素）  \n\n一般来说，模型空间到剪裁空间会合并为MVP矩阵（Model-View-Projection） \n\n## 光照模型\n\n* BRDF（bidirectional reflection distribution function）\n* BRDF经验模型（能量不守恒，简化的数学公式）：\n  * Lambert：反射强度不受角度影响，反射角度受平面影响\n  * 标准光照模型（Phong）：自发光，高光反射，漫反射，环境光（需要入射光，反射光，表面法线，视角方向）\n  * blinn-phong：与phong相比不需要计算反射方向，取而代之的是视角和入射光线的平均值归一化后的结果\n* 基于物理的BRDF模型（判断条件：是否满足交换律，即光路可逆；是否能量守恒）：\n  * cook-torrance BRDF：微面元模型用来表示pbs（physical based shading）中的高光，D是法线分布函数，G是阴影遮蔽函数，F是菲涅尔反射函数\n  * ward BRDF\n\n实现细节：\n* 漫反射符合兰伯特定律，即反射光线强度与表面法线和光源方向之间夹角的余弦值成正比  \n\n## 纹理映射\n\n纹理放大缩小的问题需要调整Filter Mode（Point,Bilinear,Trilinear）；\n缩小时最常使用mipmapping（多级渐远纹理技术）：典型的用空间换时间（多33%的空间）  \n\nbump mapping（凹凸映射）：分为两种，高度纹理（height map）模拟表面位移（displacement），得到一个修改后的法线值，称之为高度映射；另一种是法线纹理（normal map），直接做法线映射  \n\n1.在切线空间下进行光照计算；2.在世界空间下计算，前者效率往往优于后者  \n\nalbedo是tex2D（CG的函数，对纹理进行采样）的结果；  \nambient是环境光  \ndiffuse是漫反射  \nspecular是高光  \n\n法线纹理（normal map）可以使用DXT5nm的压缩格式，因为相比较普通图，法线纹理只有两个通道必不可少，第三个通道可以通过前两个推导出来，这种压缩方法可以减少内存占用  \n\n## 透明效果\n\nAlpha Test/Alpha Blending：透明度测试只有完全透明和完全不透两种可能；透明度混合可以实现半透明    \n\n半透物体是开启深度测试但是关闭深度写入的，这导致渲染顺序变得十分重要（因为关闭了深度写入）；应该**渲染不透明物体之后再渲染半透明物体**；如果都是半透明，按相机距离排序，从后往前渲染，开启深度测试，但是关闭深度写入  \n\n双面渲染：unity的Cull指令默认是Back，也就是背对相机的渲染图元不会被渲染  \n\n## 渲染路径\n\n更复杂的光照：\n* 前向渲染：颜色缓冲区和深度缓冲区；unity的前向渲染有三种，逐像素处理（最强平行光和重要光源用这种方式），逐顶点处理，球谐函数（spherical harmonics）  \n前向渲染的问题是，场景内有大量光源的情况下性能急剧下降，因为每个光源都要计算一次光照结果（一个光源一个pass）\n* 延迟渲染：G-buffer（Geometry），包含两个pass，第一个使用深度缓冲计算哪些片元可见；第二个计算片元信息，即光照计算  \n不支持抗锯齿；不能处理半透明；对硬件有要求MRT（multiple render targets）  \nUnity的延迟渲染需要提供两个pass：第一个用于渲染G-buffer；第二个用于计算真正的光照模型\n\n## API\n\nUnity shader中的矩阵是按行优先的，Unity脚本中有个Matrix4x4是按列优先  \n\nUnityRoot/Data/CGIncludes/ 里边有官方提供的.cginc文件，其中例如UnityCG.cginc十分值得学习  \n\n# 《Direct12 3D游戏开发实战》——龙书\n\n## 数学相关\n\nview transform矩阵，观察空间到世界空间的坐标变化矩阵为：\n$$\nW = \n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        Q_{x} & Q_{y} & Q_{z} & 1\n        \\end{matrix}\n\\right]\n$$\n其中，$$Q_{w} = (Q_{x},Q_{y},Q_{z},1)$$，$$u_{w} = (u_{x},u_{y},u_{z},0)$$，$$v_{w}$$还有$$w_{w}$$分别表示了观察空间中原点，x轴，y轴，z轴相对于世界空间的齐次坐标。  \n相对的，世界空间到观察空间的变化矩阵为$$W^{-1}$$，世界矩阵可以分解为一个旋转矩阵和一个平移矩阵的乘积，即$$W=RT$$。\n$$\nV=W^{-1}=(RT)^{-1}=T^{-1}R^{-1}=T^{-1}R^{T}=\n$$\n$$\n\\left[  \\begin{matrix}\n        1 & 0 & 0 & 0 \\\\\n        0 & 1 & 0 & 0 \\\\\n        0 & 0 & 1 & 0 \\\\\n        -Q_{x} & -Q_{y} & -Q_{z} & 1\n        \\end{matrix}\n\\right]\n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        0 & 0 & 0 & 1\n        \\end{matrix}\n\\right]\n=\n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        -Q_{x} \\cdot u & -Q_{y} \\cdot v & -Q_{z} \\cdot w & 1\n        \\end{matrix}\n\\right]\n$$\n由此得到，\n$$\nV=\n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        -Q_{x} \\cdot u & -Q_{y} \\cdot v & -Q_{z} \\cdot w & 1\n        \\end{matrix}\n\\right]\n$$\n\n# Unreal source code review\n\n","content":"<h1 id=\"Hardware-3D\"><a href=\"#Hardware-3D\" class=\"headerlink\" title=\"Hardware 3D\"></a>Hardware 3D</h1><p>COM：</p>\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ut5zYcDKGwk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n<p>framebuffer: 双重缓冲是一个画（用户操作），一个已经画好的传输给显示器做显示，一个称为front，另一个称为back buffer。<br>还可以有多重缓冲，缓冲层数越多，会导致画面延迟加重，但是更加连贯顺滑。原因是有时候front没花完，显示器已经逐像素扫描完一个frame，显示器就得等front buffer。<br>vsync：防tearing，就是等显示器一个frame完成再载入下一个buffer  </p>\n<p>constant buffer: 用来存变换矩阵，目的是用shader控制图形旋转，而不是改变vertices的坐标  </p>\n<p>shader中对于matric的修饰词 row_major会降低速度  </p>\n<p>DirectX Math： SIMD(single instruction multiple data)  </p>\n<p>depth buffer shares memory with stencil buffer(模板缓冲): masking like mirror,portals. depth buffer optimized for depth  </p>\n<p>direct toolkit for loading texture会省掉很多工作，所以这里用了GDI+  </p>\n<p><a href=\"https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-intrinsic-functions\">hlsl intrinsic functions</a>  </p>\n<p><a href=\"http://wiki.ogre3d.org/-Point+Light+Attenuation\">attenuation</a></p>\n<h2 id=\"imGUI\"><a href=\"#imGUI\" class=\"headerlink\" title=\"imGUI\"></a>imGUI</h2><p>使用方法：根目录的header和source文件 + examples里的对应平台文件（例如dx11+win32的四个文件）  </p>\n<h1 id=\"3D-Fundamental\"><a href=\"#3D-Fundamental\" class=\"headerlink\" title=\"3D Fundamental\"></a>3D Fundamental</h1><p>rasterization rule: left-top rule;</p>\n<h1 id=\"《Unity-shader-入门精要》\"><a href=\"#《Unity-shader-入门精要》\" class=\"headerlink\" title=\"《Unity shader 入门精要》\"></a>《Unity shader 入门精要》</h1><h2 id=\"概念合集\"><a href=\"#概念合集\" class=\"headerlink\" title=\"概念合集\"></a>概念合集</h2><p><a href=\"https://www.zhihu.com/question/304277310\">NDC与视锥体剪裁</a>：视锥体剪裁在cpu中进行，gpu流水线中还有一次culling，是按NDC空间进行剪裁（超出-1到1就裁剪，dx的z-axis是0-1）。这两次剪裁功能相似，第一次的目的是减轻gpu负担。  </p>\n<p>模板测试（stencil test）：可以理解为深度测试中的深度这个概念有开发者人为设定。  </p>\n<p>blend（混合）/output merger</p>\n<p>early-z</p>\n<h2 id=\"数学相关\"><a href=\"#数学相关\" class=\"headerlink\" title=\"数学相关\"></a>数学相关</h2><p>点坐标：<script type=\"math/tex\">\\left[ \\begin{matrix}\n        x \\\\\n        y \\\\\n        z \\\\\n        1 \\end{matrix} \\right]</script> （如果是行向量，下边变换矩阵要转置）<br>方向矢量：<script type=\"math/tex\">\\left[ \\begin{matrix}\n        x \\\\\n        y \\\\\n        z \\\\\n        0 \\end{matrix} \\right]</script><br>基础变换矩阵：<script type=\"math/tex\">\\left[  \\begin{matrix}\n        M_{3*3} & t_{3*1} \\\\\n        0_{1*3} & 1 \n        \\end{matrix}\n\\right]</script><br>之所以这样设置是为了使变换矩阵的计算结果正确；顶点变换中如果存在平移需要四维矩阵，方向矢量变换使用三维即可  </p>\n<p>M：旋转缩放；t：平移（如果坐标点或向量是行向量，t的位置要换到左下角）  </p>\n<p>复合变换依赖顺序，本质原因是矩阵乘法不满足交换律：$P<em>{new} = M</em>{translation} M<em>{rotation} M</em>{scale} P_{old}$ 执行顺序为从右到左，绝大多数情况按照缩放，旋转，平移的顺序  </p>\n<p>空间变换流程：模型空间-&gt;世界空间-&gt;观察（相机）空间-&gt;剪裁空间（视锥体剔除）-&gt;屏幕空间（剪裁空间转NDC转屏幕像素）  </p>\n<p>一般来说，模型空间到剪裁空间会合并为MVP矩阵（Model-View-Projection） </p>\n<h2 id=\"光照模型\"><a href=\"#光照模型\" class=\"headerlink\" title=\"光照模型\"></a>光照模型</h2><ul>\n<li>BRDF（bidirectional reflection distribution function）</li>\n<li>BRDF经验模型（能量不守恒，简化的数学公式）：<ul>\n<li>Lambert：反射强度不受角度影响，反射角度受平面影响</li>\n<li>标准光照模型（Phong）：自发光，高光反射，漫反射，环境光（需要入射光，反射光，表面法线，视角方向）</li>\n<li>blinn-phong：与phong相比不需要计算反射方向，取而代之的是视角和入射光线的平均值归一化后的结果</li>\n</ul>\n</li>\n<li>基于物理的BRDF模型（判断条件：是否满足交换律，即光路可逆；是否能量守恒）：<ul>\n<li>cook-torrance BRDF：微面元模型用来表示pbs（physical based shading）中的高光，D是法线分布函数，G是阴影遮蔽函数，F是菲涅尔反射函数</li>\n<li>ward BRDF</li>\n</ul>\n</li>\n</ul>\n<p>实现细节：</p>\n<ul>\n<li>漫反射符合兰伯特定律，即反射光线强度与表面法线和光源方向之间夹角的余弦值成正比  </li>\n</ul>\n<h2 id=\"纹理映射\"><a href=\"#纹理映射\" class=\"headerlink\" title=\"纹理映射\"></a>纹理映射</h2><p>纹理放大缩小的问题需要调整Filter Mode（Point,Bilinear,Trilinear）；<br>缩小时最常使用mipmapping（多级渐远纹理技术）：典型的用空间换时间（多33%的空间）  </p>\n<p>bump mapping（凹凸映射）：分为两种，高度纹理（height map）模拟表面位移（displacement），得到一个修改后的法线值，称之为高度映射；另一种是法线纹理（normal map），直接做法线映射  </p>\n<p>1.在切线空间下进行光照计算；2.在世界空间下计算，前者效率往往优于后者  </p>\n<p>albedo是tex2D（CG的函数，对纹理进行采样）的结果；<br>ambient是环境光<br>diffuse是漫反射<br>specular是高光  </p>\n<p>法线纹理（normal map）可以使用DXT5nm的压缩格式，因为相比较普通图，法线纹理只有两个通道必不可少，第三个通道可以通过前两个推导出来，这种压缩方法可以减少内存占用  </p>\n<h2 id=\"透明效果\"><a href=\"#透明效果\" class=\"headerlink\" title=\"透明效果\"></a>透明效果</h2><p>Alpha Test/Alpha Blending：透明度测试只有完全透明和完全不透两种可能；透明度混合可以实现半透明    </p>\n<p>半透物体是开启深度测试但是关闭深度写入的，这导致渲染顺序变得十分重要（因为关闭了深度写入）；应该<strong>渲染不透明物体之后再渲染半透明物体</strong>；如果都是半透明，按相机距离排序，从后往前渲染，开启深度测试，但是关闭深度写入  </p>\n<p>双面渲染：unity的Cull指令默认是Back，也就是背对相机的渲染图元不会被渲染  </p>\n<h2 id=\"渲染路径\"><a href=\"#渲染路径\" class=\"headerlink\" title=\"渲染路径\"></a>渲染路径</h2><p>更复杂的光照：</p>\n<ul>\n<li>前向渲染：颜色缓冲区和深度缓冲区；unity的前向渲染有三种，逐像素处理（最强平行光和重要光源用这种方式），逐顶点处理，球谐函数（spherical harmonics）<br>前向渲染的问题是，场景内有大量光源的情况下性能急剧下降，因为每个光源都要计算一次光照结果（一个光源一个pass）</li>\n<li>延迟渲染：G-buffer（Geometry），包含两个pass，第一个使用深度缓冲计算哪些片元可见；第二个计算片元信息，即光照计算<br>不支持抗锯齿；不能处理半透明；对硬件有要求MRT（multiple render targets）<br>Unity的延迟渲染需要提供两个pass：第一个用于渲染G-buffer；第二个用于计算真正的光照模型</li>\n</ul>\n<h2 id=\"API\"><a href=\"#API\" class=\"headerlink\" title=\"API\"></a>API</h2><p>Unity shader中的矩阵是按行优先的，Unity脚本中有个Matrix4x4是按列优先  </p>\n<p>UnityRoot/Data/CGIncludes/ 里边有官方提供的.cginc文件，其中例如UnityCG.cginc十分值得学习  </p>\n<h1 id=\"《Direct12-3D游戏开发实战》——龙书\"><a href=\"#《Direct12-3D游戏开发实战》——龙书\" class=\"headerlink\" title=\"《Direct12 3D游戏开发实战》——龙书\"></a>《Direct12 3D游戏开发实战》——龙书</h1><h2 id=\"数学相关-1\"><a href=\"#数学相关-1\" class=\"headerlink\" title=\"数学相关\"></a>数学相关</h2><p>view transform矩阵，观察空间到世界空间的坐标变化矩阵为：</p>\n<script type=\"math/tex; mode=display\">\nW = \n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        Q_{x} & Q_{y} & Q_{z} & 1\n        \\end{matrix}\n\\right]</script><p>其中，<script type=\"math/tex\">Q_{w} = (Q_{x},Q_{y},Q_{z},1)</script>，<script type=\"math/tex\">u_{w} = (u_{x},u_{y},u_{z},0)</script>，<script type=\"math/tex\">v_{w}</script>还有<script type=\"math/tex\">w_{w}</script>分别表示了观察空间中原点，x轴，y轴，z轴相对于世界空间的齐次坐标。<br>相对的，世界空间到观察空间的变化矩阵为<script type=\"math/tex\">W^{-1}</script>，世界矩阵可以分解为一个旋转矩阵和一个平移矩阵的乘积，即<script type=\"math/tex\">W=RT</script>。</p>\n<script type=\"math/tex; mode=display\">\nV=W^{-1}=(RT)^{-1}=T^{-1}R^{-1}=T^{-1}R^{T}=</script><script type=\"math/tex; mode=display\">\n\\left[  \\begin{matrix}\n        1 & 0 & 0 & 0 \\\\\n        0 & 1 & 0 & 0 \\\\\n        0 & 0 & 1 & 0 \\\\\n        -Q_{x} & -Q_{y} & -Q_{z} & 1\n        \\end{matrix}\n\\right]\n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        0 & 0 & 0 & 1\n        \\end{matrix}\n\\right]\n=\n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        -Q_{x} \\cdot u & -Q_{y} \\cdot v & -Q_{z} \\cdot w & 1\n        \\end{matrix}\n\\right]</script><p>由此得到，</p>\n<script type=\"math/tex; mode=display\">\nV=\n\\left[  \\begin{matrix}\n        u_{x} & u_{y} & u_{z} & 0 \\\\\n        v_{x} & v_{y} & v_{z} & 0 \\\\\n        w_{x} & w_{y} & w_{z} & 0 \\\\\n        -Q_{x} \\cdot u & -Q_{y} \\cdot v & -Q_{z} \\cdot w & 1\n        \\end{matrix}\n\\right]</script><h1 id=\"Unreal-source-code-review\"><a href=\"#Unreal-source-code-review\" class=\"headerlink\" title=\"Unreal source code review\"></a>Unreal source code review</h1>","slug":"hardware3d","updated":"2020-07-08T13:51:39.323Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/04/14/hardware3d/","excerpt":"","categories":[],"tags":[{"name":"Dx12","slug":"Dx12","permalink":"https://blog.providencezhang.cn/tags/Dx12/"},{"name":"WindowsApp","slug":"WindowsApp","permalink":"https://blog.providencezhang.cn/tags/WindowsApp/"},{"name":"COM","slug":"COM","permalink":"https://blog.providencezhang.cn/tags/COM/"},{"name":"Shader","slug":"Shader","permalink":"https://blog.providencezhang.cn/tags/Shader/"}]},{"title":"IEEE ICIP 2020","date":"2020-03-31T04:45:53.000Z","path":"2020/03/31/ICIP/","text":"SEE THROUGH OCCLUSIONS:DETAILED HUMAN SHAPE ESTIMATION FROM A SINGLE IMAGE WITH OCCLUSIONSAbstract3D human body shape and pose reconstructing from a single RGB image is a challenging task in the field of computer vision and computer graphics. Since occlusions are prevalent in real application scenarios, it’s important to develop 3D human body reconstruction algorithms with occlusions. However, existing methods didn’t take this problem into account. In this paper, we present a novel depth estimation Neural Network, named Detailed Human Depth Network(DHDNet), which aims to reconstruct the detailed and completed depth map from a single RGB image contains occlusions of human body. Inspired by the previous works [1, 2], we propose an end-to-end method to obtain the fine detailed 3D human mesh. The proposed method follows a coarse-to-fine refinement scheme. Using the depth information generated from DHDNet, the coarse 3D mesh can recover detailed spatial structure, even the part behind occlusions. We also construct DepthHuman, a 2D in-the-wild human dataset containing over 18000 synthetic human depth maps and corresponding RGB images. Extensive experimental results demonstrate that our approach has significant improvement in 3D mesh reconstruction accuracy on the occluded parts. StatusICIP under review — 2020.1.31ACCEPTED — 2020.5.16 Links","raw":"---\ntitle: IEEE ICIP 2020\ndate: 2020-03-31 12:45:53\ntags:\n    - ICIP\n    - 三维人体重建\n    - 深度学习\n    - shift_net\n    - hmd\n---\n\n# SEE THROUGH OCCLUSIONS:DETAILED HUMAN SHAPE ESTIMATION FROM A SINGLE IMAGE WITH OCCLUSIONS\n\n## Abstract\n\n3D human body shape and pose reconstructing from a single RGB image is a challenging task in the field of computer vision and computer graphics. Since occlusions are prevalent in real application scenarios, it’s important to develop 3D human body reconstruction algorithms with occlusions. However, existing methods didn’t take this problem into account. In this paper, we present a novel depth estimation Neural Network, named Detailed Human Depth Network(DHDNet), which aims to reconstruct the detailed and completed depth map from a single RGB image contains occlusions of human body. Inspired by the previous works [1, 2], we propose an end-to-end method to obtain the fine detailed 3D human mesh. The proposed method follows a coarse-to-fine refinement scheme. Using the depth information generated from DHDNet, the coarse 3D mesh can recover detailed spatial structure, even the part behind occlusions. We also construct DepthHuman, a 2D in-the-wild human dataset containing over 18000 synthetic human depth maps and corresponding RGB images. Extensive experimental results demonstrate that our approach has significant improvement in 3D mesh reconstruction accuracy on the occluded parts.\n\n## Status\n\nICIP under review -- 2020.1.31  \nACCEPTED          -- 2020.5.16  \n\n{% asset_img accepted.png review %}  \n\n## Links\n\n{% pdf ICIP.pdf %}\n\n{% asset_img 6.PNG details %}  \n{% asset_img 7.PNG depth %}  \n{% asset_img Capture.PNG comparison %}  \n{% asset_img system6.png end-to-end system %}  ","content":"<h1 id=\"SEE-THROUGH-OCCLUSIONS-DETAILED-HUMAN-SHAPE-ESTIMATION-FROM-A-SINGLE-IMAGE-WITH-OCCLUSIONS\"><a href=\"#SEE-THROUGH-OCCLUSIONS-DETAILED-HUMAN-SHAPE-ESTIMATION-FROM-A-SINGLE-IMAGE-WITH-OCCLUSIONS\" class=\"headerlink\" title=\"SEE THROUGH OCCLUSIONS:DETAILED HUMAN SHAPE ESTIMATION FROM A SINGLE IMAGE WITH OCCLUSIONS\"></a>SEE THROUGH OCCLUSIONS:DETAILED HUMAN SHAPE ESTIMATION FROM A SINGLE IMAGE WITH OCCLUSIONS</h1><h2 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h2><p>3D human body shape and pose reconstructing from a single RGB image is a challenging task in the field of computer vision and computer graphics. Since occlusions are prevalent in real application scenarios, it’s important to develop 3D human body reconstruction algorithms with occlusions. However, existing methods didn’t take this problem into account. In this paper, we present a novel depth estimation Neural Network, named Detailed Human Depth Network(DHDNet), which aims to reconstruct the detailed and completed depth map from a single RGB image contains occlusions of human body. Inspired by the previous works [1, 2], we propose an end-to-end method to obtain the fine detailed 3D human mesh. The proposed method follows a coarse-to-fine refinement scheme. Using the depth information generated from DHDNet, the coarse 3D mesh can recover detailed spatial structure, even the part behind occlusions. We also construct DepthHuman, a 2D in-the-wild human dataset containing over 18000 synthetic human depth maps and corresponding RGB images. Extensive experimental results demonstrate that our approach has significant improvement in 3D mesh reconstruction accuracy on the occluded parts.</p>\n<h2 id=\"Status\"><a href=\"#Status\" class=\"headerlink\" title=\"Status\"></a>Status</h2><p>ICIP under review — 2020.1.31<br>ACCEPTED          — 2020.5.16  </p>\n  \n<h2 id=\"Links\"><a href=\"#Links\" class=\"headerlink\" title=\"Links\"></a>Links</h2>\n\n\t<div class=\"row\">\n    <embed src=\"ICIP.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n\n  \n  \n  \n  ","slug":"ICIP","updated":"2020-12-29T08:13:21.227Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/03/31/ICIP/","excerpt":"","categories":[],"tags":[{"name":"ICIP","slug":"ICIP","permalink":"https://blog.providencezhang.cn/tags/ICIP/"},{"name":"三维人体重建","slug":"三维人体重建","permalink":"https://blog.providencezhang.cn/tags/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA/"},{"name":"深度学习","slug":"深度学习","permalink":"https://blog.providencezhang.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"shift_net","slug":"shift-net","permalink":"https://blog.providencezhang.cn/tags/shift-net/"},{"name":"hmd","slug":"hmd","permalink":"https://blog.providencezhang.cn/tags/hmd/"}]},{"title":"DOTS & ECS & RP","date":"2020-03-04T10:19:17.000Z","path":"2020/03/04/DOTSandECS/","text":"About ECSOLD: GameObjects &amp; MonoBehaviours Object-oriented create一个叫Player的GameObject，用若干MonoBehaviour作为Player的组件，实现功能（例如renderer,physics,movement）。 NEW: Entities &amp; Components &amp; Systems data-oriented group together components contain data (只是数据结构，不包含逻辑) contain behaviour （逻辑只在这里） 就是数据和逻辑分开了，这样cpu可以读到连续的内存，不需要每个GO来回在内存里跳 DOTSDATA ORIENTED TECHNOLOGY STACK三部分组成： C# Job system 多线程，unity的性能问题主要来源于主循环update线程是单线程的 C#创建线程并管理每个线程的工作很困难，job system来管理线程，并且分配任务（assigns jobs） entity component system burst compiler 把C#编译成高度适用于Job system的机器码 Render PipelineScriptable render pipeline SRPUniversal render pipeline URP(LWRP)High definition render pipeline(HDRP) Build-in renderer TutorialQuadrant System in Unity ECS (Find Target/Obstacle Avoidance/Boids) Note1234World.Active.EntityManager; // desperatedWorld.DefaultGameObjectInjectionWorld.EntityManager; // use thistypeof(RenderBounds); // make the mesh visable URP下需要用unlit/transparent材质","raw":"---\ntitle: DOTS & ECS & RP\ndate: 2020-03-04 18:19:17\ntags:\n    - Unity\n    - ECS\n    - DOTS\n---\n\n## About ECS\nOLD:  \n    GameObjects & MonoBehaviours  \n    Object-oriented  \n    create一个叫Player的GameObject，用若干MonoBehaviour作为Player的组件，实现功能（例如renderer,physics,movement）。\n\nNEW:  \n    Entities & Components & Systems  \n    data-oriented  \n1. group together components\n2. contain data (只是数据结构，不包含逻辑)\n3. contain behaviour （逻辑只在这里）\n\n就是数据和逻辑分开了，这样cpu可以读到连续的内存，不需要每个GO来回在内存里跳\n\n## DOTS\nDATA ORIENTED TECHNOLOGY STACK  \n三部分组成：\n1. C# Job system\n   1. 多线程，unity的性能问题主要来源于主循环update线程是单线程的\n   2. C#创建线程并管理每个线程的工作很困难，job system来管理线程，并且分配任务（assigns jobs）\n2. entity component system\n3. burst compiler\n   1. 把C#编译成高度适用于Job system的机器码\n\n\n## Render Pipeline\nScriptable render pipeline SRP  \nUniversal render pipeline URP(LWRP)  \nHigh definition render pipeline(HDRP)  \n\nBuild-in renderer\n\n### Tutorial\n\nQuadrant System in Unity ECS (Find Target/Obstacle Avoidance/Boids)  \n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hP4Vu6JbzSo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>  \n\n\n### Note\n``` C#\nWorld.Active.EntityManager; // desperated\nWorld.DefaultGameObjectInjectionWorld.EntityManager; // use this\n\ntypeof(RenderBounds); // make the mesh visable\n```\n\nURP下需要用unlit/transparent材质  \n\n","content":"<h2 id=\"About-ECS\"><a href=\"#About-ECS\" class=\"headerlink\" title=\"About ECS\"></a>About ECS</h2><p>OLD:<br>    GameObjects &amp; MonoBehaviours<br>    Object-oriented<br>    create一个叫Player的GameObject，用若干MonoBehaviour作为Player的组件，实现功能（例如renderer,physics,movement）。</p>\n<p>NEW:<br>    Entities &amp; Components &amp; Systems<br>    data-oriented  </p>\n<ol>\n<li>group together components</li>\n<li>contain data (只是数据结构，不包含逻辑)</li>\n<li>contain behaviour （逻辑只在这里）</li>\n</ol>\n<p>就是数据和逻辑分开了，这样cpu可以读到连续的内存，不需要每个GO来回在内存里跳</p>\n<h2 id=\"DOTS\"><a href=\"#DOTS\" class=\"headerlink\" title=\"DOTS\"></a>DOTS</h2><p>DATA ORIENTED TECHNOLOGY STACK<br>三部分组成：</p>\n<ol>\n<li>C# Job system<ol>\n<li>多线程，unity的性能问题主要来源于主循环update线程是单线程的</li>\n<li>C#创建线程并管理每个线程的工作很困难，job system来管理线程，并且分配任务（assigns jobs）</li>\n</ol>\n</li>\n<li>entity component system</li>\n<li>burst compiler<ol>\n<li>把C#编译成高度适用于Job system的机器码</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"Render-Pipeline\"><a href=\"#Render-Pipeline\" class=\"headerlink\" title=\"Render Pipeline\"></a>Render Pipeline</h2><p>Scriptable render pipeline SRP<br>Universal render pipeline URP(LWRP)<br>High definition render pipeline(HDRP)  </p>\n<p>Build-in renderer</p>\n<h3 id=\"Tutorial\"><a href=\"#Tutorial\" class=\"headerlink\" title=\"Tutorial\"></a>Tutorial</h3><p>Quadrant System in Unity ECS (Find Target/Obstacle Avoidance/Boids)  </p>\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hP4Vu6JbzSo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>  \n\n\n<h3 id=\"Note\"><a href=\"#Note\" class=\"headerlink\" title=\"Note\"></a>Note</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">World.Active.EntityManager; // desperated</span><br><span class=\"line\">World.DefaultGameObjectInjectionWorld.EntityManager; // use this</span><br><span class=\"line\"></span><br><span class=\"line\">typeof(RenderBounds); // make the mesh visable</span><br></pre></td></tr></table></figure>\n<p>URP下需要用unlit/transparent材质  </p>\n","slug":"DOTSandECS","updated":"2020-03-18T06:36:52.090Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/03/04/DOTSandECS/","excerpt":"","categories":[],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://blog.providencezhang.cn/tags/Unity/"},{"name":"ECS","slug":"ECS","permalink":"https://blog.providencezhang.cn/tags/ECS/"},{"name":"DOTS","slug":"DOTS","permalink":"https://blog.providencezhang.cn/tags/DOTS/"}]},{"title":"云服务器相关","date":"2020-02-12T12:00:24.000Z","path":"2020/02/12/CloudServer/","text":"云上项目Hotfixxlua到webgl的坑 1xlua.hotfix ChatRoomMirror聊天室 Mysql更改user的host地址：1update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;; 改成linux之后要重新做server了 Homehttp://providencezhang.cnvuejs+node+nginx link三者的关系简单来说，nginx可以反向代理多个node项目，做负载均衡等。如果没有服务端逻辑无需node，vuejs+nginx即可 Blogblog.providencezhang.cn 解析到了 taye310.github.iohexo + github pages只能提供静态页面，unity webgl需要网页服务器能解析.unityweb文件，在IIS上需要在mapping上单独设置（mimetype），这个可能是导致不能在github pages上部署unity webgl项目的原因。 计划要不要直接换skynet - 需要Ubuntu环境 √消息机制是不是可以自己实现一套，看skynet吧 xlua热更demo实现C#这个attribute到底怎么用 日志2020.2.10服务器win版本，客户端webgl，IIS部署成功 2020.2.12业务：增加聊天记录；实现：不论是用streamasset还是加mysql数据库，服务器和客户端内容都需要分开server记聊天记录 client是不用记的command不能有返回值，传入参数类型也有限制，正确的方法：12345678910111213but yeah you cant do that, I use ClientRpc&#x27;s so for example if i have a float that&#x27;s called &quot;exampleValue&quot; and want to update it on the client you could something like this:[Command]public void CmdRecuestNewValues()&#123;RpcGiveNewValues(exampleValue);&#125;[ClientRpc]public void RpcGiveNewValues(float value)&#123;exampleValue = value;&#125;then if you call the CmdRecuestNewValues(); command you will update you values. 2020.2.14unity URP vs HDRP 2020.2.19刷leetcode，首页整好看点！！！找个模板，后端用wordpress集成什么意思？？域名备案终于下来咯 2020.3.9ubuntu上不要用系统代理（更新conda包会报错未知sock版本），chrome用Omega插件，命令行用proxychain4Skynet腾讯云上想用skynet的话要用ubuntu这样的话主页要换成nginx，不想装图形界面了，用共享文件夹samba远程写脚本，到linux下build 2020.3.10云服务器重装了ubuntu，用vscode remote development就可以远程调试，ssh添加了两对，一是新建的Home，二是github用的在.ssh里的一对samba配置教程传文件用sftp就好，局域网可以用samba 2020.3.11nginx -s reloadconfNginx location设置二级域名时 root下边要有这个名字的文件夹123456789101112131415server&#123; listen 80; #1.你想让你的这个项目跑在哪个端口 server_name providencezhang.cn; #2.当前服务器ip location / &#123; root /home/ubuntu/ftp/www/home; #3.dist文件的位置(我是直接放在home目录下了) # try_files $uri $uri/ /index.html; #4.重定向,内部文件的指向(照写) &#125; location /static &#123; alias /home/ubuntu/github/simpleweb; #3.dist文件的位置(我是直接放在home目录下了) # try_files $uri $uri/ /index.html; #4.重定向,内部文件的指向(照写) &#125; location /api &#123; #4.当请求跨域时配置端口转发 proxy_pass http://175.24.57.128:8848/api; #5.转发地址 &#125; &#125; 2020.3.12用firewall-cmd开nginx的80端口 2020.3.13最终目标：多人在线游戏，用dots skynet源码 简单demo跑通逻辑（登陆，心跳，消息机制） 客户端开发 前后端连接 2020.3.14git代理设置 2020.3.26dots到webgl 会出现问题 link12sudo nginx -t # 测试配置是否成功sudo nginx -s reload # 重启服务xlua的热更到webgl有问题 2020.9.15做games-cn的作业需要图形界面，用vnc+xfce 连接不到server：原因是防火墙策略 保存防火墙规则命令：iptables-save &gt; /opt/iprules_all.txt清除策略iptables -F后续需要恢复原本的防火墙策略，通过如下命令恢复：iptables-restore &lt; /opt/iprules_all.txt vncviewer登录后显示叉：~/.vnc/xstartup配置文件有问题（权限或者内容），查看vnc log解决 常用命令： ps -ef|grep vncvncserver -kill :1vncserver :1","raw":"---\ntitle: 云服务器相关\ndate: 2020-02-12 20:00:24\ntags: \n    - 云服务\n    - 腾讯云\n---\n\n# 云上项目\n\n## Hotfix\n\n[xlua到webgl的坑](http://blog.okbase.net/unity3d/archive/56120.html)  \n\n``` lua\nxlua.hotfix\n```\n\n## ChatRoom\n\nMirror聊天室\n\nMysql更改user的host地址：\n``` sql\nupdate user set host = '%' where user = 'root';\n```\n\n改成linux之后要重新做server了  \n\n## Home\n\nhttp://providencezhang.cn  \nvuejs+node+nginx [link](https://segmentfault.com/a/1190000018099632)  \n[三者的关系](https://www.zhihu.com/question/294219455?sort=created)  \n简单来说，nginx可以反向代理多个node项目，做负载均衡等。如果没有服务端逻辑无需node，vuejs+nginx即可  \n\n## Blog\n\nblog.providencezhang.cn 解析到了 taye310.github.io  \nhexo + github pages只能提供静态页面，unity webgl需要网页服务器能解析.unityweb文件，在IIS上需要在mapping上单独设置（mimetype），这个可能是导致不能在github pages上部署unity webgl项目的原因。\n\n## 计划\n\n要不要直接换skynet - 需要Ubuntu环境 √\n消息机制是不是可以自己实现一套，看skynet吧  \n\nxlua热更demo实现  \nC#这个attribute到底怎么用\n\n## 日志\n\n### 2020.2.10\n服务器win版本，客户端webgl，IIS部署成功\n\n### 2020.2.12\n业务：增加聊天记录；实现：不论是用streamasset还是加mysql数据库，服务器和客户端内容都需要分开  \nserver记聊天记录 client是不用记的  \ncommand不能有返回值，传入参数类型也有限制，正确的方法：\n```\nbut yeah you cant do that, I use ClientRpc's so for example if i have a float that's called \"exampleValue\" and want to update it on the client you could something like this:\n\n[Command]\npublic void CmdRecuestNewValues(){\nRpcGiveNewValues(exampleValue);\n}\n\n[ClientRpc]\npublic void RpcGiveNewValues(float value){\nexampleValue = value;\n}\n\nthen if you call the CmdRecuestNewValues(); command you will update you values.\n```\n\n### 2020.2.14\nunity URP vs HDRP\n\n### 2020.2.19\n刷leetcode，首页整好看点！！！找个模板，后端用wordpress集成什么意思？？  \n域名备案终于下来咯\n\n### 2020.3.9\nubuntu上不要用系统代理（更新conda包会报错未知sock版本），chrome用Omega插件，命令行用proxychain4  \nSkynet  \n腾讯云上想用skynet的话要用ubuntu  \n这样的话主页要换成nginx，不想装图形界面了，用共享文件夹samba远程写脚本，到linux下build  \n\n### 2020.3.10\n云服务器重装了ubuntu，用vscode remote development就可以远程调试，ssh添加了两对，一是新建的Home，二是github用的在.ssh里的一对  \n[samba配置教程](https://blog.csdn.net/qq_28719743/article/details/84872396)  \n传文件用sftp就好，局域网可以用samba\n\n### 2020.3.11\n``` nginx -s reload ```  \n[conf](https://blog.csdn.net/WanJiaBaoBao/article/details/83349622)  \nNginx location设置二级域名时 root下边要有这个名字的文件夹  \n``` bash\nserver{\n        listen 80;     #1.你想让你的这个项目跑在哪个端口\n        server_name providencezhang.cn;     #2.当前服务器ip\n       \tlocation / {\n        \troot /home/ubuntu/ftp/www/home;     #3.dist文件的位置(我是直接放在home目录下了) \n            # try_files $uri $uri/ /index.html;     #4.重定向,内部文件的指向(照写)\n        }\n\t\tlocation /static {\n        \talias /home/ubuntu/github/simpleweb;     #3.dist文件的位置(我是直接放在home目录下了) \n            # try_files $uri $uri/ /index.html;     #4.重定向,内部文件的指向(照写)\n        }\n        location /api {  #4.当请求跨域时配置端口转发\n            proxy_pass http://175.24.57.128:8848/api; #5.转发地址\n        } \n    }\n```\n\n### 2020.3.12\n用firewall-cmd开nginx的80端口\n\n### 2020.3.13\n最终目标：多人在线游戏，用dots  \n1. skynet源码  \n2. 简单demo跑通逻辑（登陆，心跳，消息机制）\n3. 客户端开发\n4. 前后端连接\n\n### 2020.3.14\n[git代理设置](https://echo.xuchaoji.com/index.php/archives/110/)\n\n### 2020.3.26\ndots到webgl 会出现问题 [link](https://forum.unity.com/threads/bug-crash-with-a-fresh-project-on-ios-monopinvokecallback.827634/)  \n``` conf\nsudo nginx -t         # 测试配置是否成功\nsudo nginx -s reload  # 重启服务\n```\nxlua的热更到webgl有问题\n\n### 2020.9.15\n做games-cn的作业需要图形界面，用vnc+xfce  \n\n连接不到server：原因是防火墙策略  \n> 保存防火墙规则命令：iptables-save > /opt/iprules_all.txt\n> 清除策略iptables -F\n> 后续需要恢复原本的防火墙策略，通过如下命令恢复：iptables-restore < /opt/iprules_all.txt\n\nvncviewer登录后显示叉：~/.vnc/xstartup配置文件有问题（权限或者内容），查看vnc log解决  \n\n常用命令：  \n> ps -ef|grep vnc\n> vncserver -kill :1\n> vncserver :1","content":"<h1 id=\"云上项目\"><a href=\"#云上项目\" class=\"headerlink\" title=\"云上项目\"></a>云上项目</h1><h2 id=\"Hotfix\"><a href=\"#Hotfix\" class=\"headerlink\" title=\"Hotfix\"></a>Hotfix</h2><p><a href=\"http://blog.okbase.net/unity3d/archive/56120.html\">xlua到webgl的坑</a>  </p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xlua.hotfix</span><br></pre></td></tr></table></figure>\n<h2 id=\"ChatRoom\"><a href=\"#ChatRoom\" class=\"headerlink\" title=\"ChatRoom\"></a>ChatRoom</h2><p>Mirror聊天室</p>\n<p>Mysql更改user的host地址：<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update <span class=\"keyword\">user</span> <span class=\"keyword\">set</span> host <span class=\"operator\">=</span> <span class=\"string\">&#x27;%&#x27;</span> <span class=\"keyword\">where</span> <span class=\"keyword\">user</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>;</span><br></pre></td></tr></table></figure></p>\n<p>改成linux之后要重新做server了  </p>\n<h2 id=\"Home\"><a href=\"#Home\" class=\"headerlink\" title=\"Home\"></a>Home</h2><p><a href=\"http://providencezhang.cn\">http://providencezhang.cn</a><br>vuejs+node+nginx <a href=\"https://segmentfault.com/a/1190000018099632\">link</a><br><a href=\"https://www.zhihu.com/question/294219455?sort=created\">三者的关系</a><br>简单来说，nginx可以反向代理多个node项目，做负载均衡等。如果没有服务端逻辑无需node，vuejs+nginx即可  </p>\n<h2 id=\"Blog\"><a href=\"#Blog\" class=\"headerlink\" title=\"Blog\"></a>Blog</h2><p>blog.providencezhang.cn 解析到了 taye310.github.io<br>hexo + github pages只能提供静态页面，unity webgl需要网页服务器能解析.unityweb文件，在IIS上需要在mapping上单独设置（mimetype），这个可能是导致不能在github pages上部署unity webgl项目的原因。</p>\n<h2 id=\"计划\"><a href=\"#计划\" class=\"headerlink\" title=\"计划\"></a>计划</h2><p>要不要直接换skynet - 需要Ubuntu环境 √<br>消息机制是不是可以自己实现一套，看skynet吧  </p>\n<p>xlua热更demo实现<br>C#这个attribute到底怎么用</p>\n<h2 id=\"日志\"><a href=\"#日志\" class=\"headerlink\" title=\"日志\"></a>日志</h2><h3 id=\"2020-2-10\"><a href=\"#2020-2-10\" class=\"headerlink\" title=\"2020.2.10\"></a>2020.2.10</h3><p>服务器win版本，客户端webgl，IIS部署成功</p>\n<h3 id=\"2020-2-12\"><a href=\"#2020-2-12\" class=\"headerlink\" title=\"2020.2.12\"></a>2020.2.12</h3><p>业务：增加聊天记录；实现：不论是用streamasset还是加mysql数据库，服务器和客户端内容都需要分开<br>server记聊天记录 client是不用记的<br>command不能有返回值，传入参数类型也有限制，正确的方法：<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">but yeah you cant do that, I use ClientRpc&#x27;s so for example if i have a float that&#x27;s called &quot;exampleValue&quot; and want to update it on the client you could something like this:</span><br><span class=\"line\"></span><br><span class=\"line\">[Command]</span><br><span class=\"line\">public void CmdRecuestNewValues()&#123;</span><br><span class=\"line\">RpcGiveNewValues(exampleValue);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[ClientRpc]</span><br><span class=\"line\">public void RpcGiveNewValues(float value)&#123;</span><br><span class=\"line\">exampleValue = value;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">then if you call the CmdRecuestNewValues(); command you will update you values.</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2020-2-14\"><a href=\"#2020-2-14\" class=\"headerlink\" title=\"2020.2.14\"></a>2020.2.14</h3><p>unity URP vs HDRP</p>\n<h3 id=\"2020-2-19\"><a href=\"#2020-2-19\" class=\"headerlink\" title=\"2020.2.19\"></a>2020.2.19</h3><p>刷leetcode，首页整好看点！！！找个模板，后端用wordpress集成什么意思？？<br>域名备案终于下来咯</p>\n<h3 id=\"2020-3-9\"><a href=\"#2020-3-9\" class=\"headerlink\" title=\"2020.3.9\"></a>2020.3.9</h3><p>ubuntu上不要用系统代理（更新conda包会报错未知sock版本），chrome用Omega插件，命令行用proxychain4<br>Skynet<br>腾讯云上想用skynet的话要用ubuntu<br>这样的话主页要换成nginx，不想装图形界面了，用共享文件夹samba远程写脚本，到linux下build  </p>\n<h3 id=\"2020-3-10\"><a href=\"#2020-3-10\" class=\"headerlink\" title=\"2020.3.10\"></a>2020.3.10</h3><p>云服务器重装了ubuntu，用vscode remote development就可以远程调试，ssh添加了两对，一是新建的Home，二是github用的在.ssh里的一对<br><a href=\"https://blog.csdn.net/qq_28719743/article/details/84872396\">samba配置教程</a><br>传文件用sftp就好，局域网可以用samba</p>\n<h3 id=\"2020-3-11\"><a href=\"#2020-3-11\" class=\"headerlink\" title=\"2020.3.11\"></a>2020.3.11</h3><p><code>nginx -s reload</code><br><a href=\"https://blog.csdn.net/WanJiaBaoBao/article/details/83349622\">conf</a><br>Nginx location设置二级域名时 root下边要有这个名字的文件夹<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server&#123;</span><br><span class=\"line\">        listen 80;     <span class=\"comment\">#1.你想让你的这个项目跑在哪个端口</span></span><br><span class=\"line\">        server_name providencezhang.cn;     <span class=\"comment\">#2.当前服务器ip</span></span><br><span class=\"line\">       \tlocation / &#123;</span><br><span class=\"line\">        \troot /home/ubuntu/ftp/www/home;     <span class=\"comment\">#3.dist文件的位置(我是直接放在home目录下了) </span></span><br><span class=\"line\">            <span class=\"comment\"># try_files $uri $uri/ /index.html;     #4.重定向,内部文件的指向(照写)</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">\t\tlocation /static &#123;</span><br><span class=\"line\">        \t<span class=\"built_in\">alias</span> /home/ubuntu/github/simpleweb;     <span class=\"comment\">#3.dist文件的位置(我是直接放在home目录下了) </span></span><br><span class=\"line\">            <span class=\"comment\"># try_files $uri $uri/ /index.html;     #4.重定向,内部文件的指向(照写)</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        location /api &#123;  <span class=\"comment\">#4.当请求跨域时配置端口转发</span></span><br><span class=\"line\">            proxy_pass http://175.24.57.128:8848/api; <span class=\"comment\">#5.转发地址</span></span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2020-3-12\"><a href=\"#2020-3-12\" class=\"headerlink\" title=\"2020.3.12\"></a>2020.3.12</h3><p>用firewall-cmd开nginx的80端口</p>\n<h3 id=\"2020-3-13\"><a href=\"#2020-3-13\" class=\"headerlink\" title=\"2020.3.13\"></a>2020.3.13</h3><p>最终目标：多人在线游戏，用dots  </p>\n<ol>\n<li>skynet源码  </li>\n<li>简单demo跑通逻辑（登陆，心跳，消息机制）</li>\n<li>客户端开发</li>\n<li>前后端连接</li>\n</ol>\n<h3 id=\"2020-3-14\"><a href=\"#2020-3-14\" class=\"headerlink\" title=\"2020.3.14\"></a>2020.3.14</h3><p><a href=\"https://echo.xuchaoji.com/index.php/archives/110/\">git代理设置</a></p>\n<h3 id=\"2020-3-26\"><a href=\"#2020-3-26\" class=\"headerlink\" title=\"2020.3.26\"></a>2020.3.26</h3><p>dots到webgl 会出现问题 <a href=\"https://forum.unity.com/threads/bug-crash-with-a-fresh-project-on-ios-monopinvokecallback.827634/\">link</a><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nginx -t         # 测试配置是否成功</span><br><span class=\"line\">sudo nginx -s reload  # 重启服务</span><br></pre></td></tr></table></figure><br>xlua的热更到webgl有问题</p>\n<h3 id=\"2020-9-15\"><a href=\"#2020-9-15\" class=\"headerlink\" title=\"2020.9.15\"></a>2020.9.15</h3><p>做games-cn的作业需要图形界面，用vnc+xfce  </p>\n<p>连接不到server：原因是防火墙策略  </p>\n<blockquote>\n<p>保存防火墙规则命令：iptables-save &gt; /opt/iprules_all.txt<br>清除策略iptables -F<br>后续需要恢复原本的防火墙策略，通过如下命令恢复：iptables-restore &lt; /opt/iprules_all.txt</p>\n</blockquote>\n<p>vncviewer登录后显示叉：~/.vnc/xstartup配置文件有问题（权限或者内容），查看vnc log解决  </p>\n<p>常用命令：  </p>\n<blockquote>\n<p>ps -ef|grep vnc<br>vncserver -kill :1<br>vncserver :1</p>\n</blockquote>\n","slug":"CloudServer","updated":"2020-09-15T02:21:43.420Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2020/02/12/CloudServer/","excerpt":"","categories":[],"tags":[{"name":"云服务","slug":"云服务","permalink":"https://blog.providencezhang.cn/tags/%E4%BA%91%E6%9C%8D%E5%8A%A1/"},{"name":"腾讯云","slug":"腾讯云","permalink":"https://blog.providencezhang.cn/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"}]},{"title":"互联网体系结构总结","date":"2019-05-08T17:25:57.000Z","path":"2019/05/09/互联网体系结构总结/","text":"The Design Philosophy of the DARPA Internet Protocols（1988） 读书笔记TCP/IP协议在（1988-15）年提出，本文目的是解释出于何种原因互联网协议采用了TCP/IP设计。事实上，互联网的设计哲学是从最初的协议逐步进化而来，直至现如今的标准。例如IP和TCP的层级结构， 看起来是如今互联网协议设计的基础，但在最初的协议中并不存在。 DARPA互联网架构的最高目标是研究出一个可以高效多路复用现有内联网络的技术。最初的目标是通过ARPA分组无线电网络将ARPANET连接到一起，另一种选择是设计一个统一的系统（多媒体网络），用以连接多种传输媒介。同时，分组交换技术用以实现多路复用，其他的技术，例如电路交换，也曾被考虑使用。但是考虑到应用场景的支持等原因，分组交换最终成为了互联网架构的基础。最终形成了互联网的基本结构：一个分组交换通信设施，其中不同网络通过网关（分组通信处理器：用以实现存储和分组转发算法）相连。 文中列出了七条次级目标，这些目标是影响互联网架构设计的重要因素。其中，最重要的一条是即使网络和网关失效，互联网也应该继续提供通信服务。为达到这一目标，就必须保护正在进行的会话的状态信息。需要强调的是虽然“生存能力”次级目标中最重要的一条，它的优先级仍然低于顶级目标。第二目标是互联网架构应该在传输服务层支持多种服务类型。不同的服务类型是通过不同的传输需求区分的，例如传输速度，延迟和可靠性。TCP协议在设计之初试图支持所有类型的网络服务，但显然是十分困难的。TCP/IP的出现是为了让互联网架构能够承受并行传输，并最小化依赖性，延迟以及对带宽的需求。第三，一个成功的互联网架构需要能够容纳多种网络技术，从军方到商用范围。其余优先级较低的目标，或效率较低，或没有完全在工程中实现。 总之，当时的互联网架构是非常成功的，网络协议被广泛使用并且衍生出了许多类似的架构。理论上存在着比数据报（datagram）更好的模块，用以得到更好的生存性以及灵活性，同时满足资源管理以及问责机制的需要。是当时DARPA组织的研究方向。 Named Data Networking of Things（2016）读书笔记全面部署物联网面临两大挑战，一是如何使不同种类的电子设备进行通讯，二是在建立通讯后如何保持其连续性和安全性。这篇文章讨论了NDN可以如何改善和简化物联网通讯，主要针对目前IP网络无法解决的问题。这些问题包括： 简单的通讯任务需要复杂的解决方案 通道和会话机制造成的安全问题 本地通讯有严重缺陷物联网中的每一个“物”都会按照层次结构分配一个名字，这种命名方式与NDN根据数据名检索的检索模式恰好吻合，使得NDN十分适用于物联网网络。NDN在网络层加密命名数据，从而保证数据只被授权用户获取，以数据为中心的机制解决了物联网应用中安全性的问题。基于命名的传输方式也适用于物联网，例如对延迟的容忍度高，快速恢复丢失的本地内容以及逐跳阻塞控制。网络内存储可以让流行的内容更容易被传播，促进本地文件进行恢复，数据加密可以使最简单的NDN应用也可以享有上述的优势。为了让NDN的核心网络层协议实现物联网框架的功能，在网络层需要设置必要的命名规范；控制正在运行的附件以及对附件的增删；需要做信任管理，访问控制，数据融合；应用层面的消息收发；高效的多端通讯；以及将物联网整合进因特网。在NDN上实现物联网还存在许多问题，包括使用多个层次结构命名；在无基础设施的环境中进行路由；在高度有约束的设备上实现；数据收集模式的问题等。","raw":"---\ntitle: 互联网体系结构总结\ndate: 2019-05-09 01:25:57\ntags:\n    - 研究生课程\n    - 互联网体系结构\n---\n\n### The Design Philosophy of the DARPA Internet Protocols（1988） 读书笔记\n\n    TCP/IP协议在（1988-15）年提出，本文目的是解释出于何种原因互联网协议采用了TCP/IP设计。事实上，互联网的设计哲学是从最初的协议逐步进化而来，直至现如今的标准。例如IP和TCP的层级结构，\n看起来是如今互联网协议设计的基础，但在最初的协议中并不存在。  \n    DARPA互联网架构的最高目标是研究出一个可以高效多路复用现有内联网络的技术。最初的目标是通过ARPA分组无线电网络将ARPANET连接到一起，另一种选择是设计一个统一的系统（多媒体网络），用以\n连接多种传输媒介。同时，分组交换技术用以实现多路复用，其他的技术，例如电路交换，也曾被考虑使用。但是考虑到应用场景的支持等原因，分组交换最终成为了互联网架构的基础。最终形成了互联网\n的基本结构：一个分组交换通信设施，其中不同网络通过网关（分组通信处理器：用以实现存储和分组转发算法）相连。  \n    文中列出了七条次级目标，这些目标是影响互联网架构设计的重要因素。其中，最重要的一条是即使网络和网关失效，互联网也应该继续提供通信服务。为达到这一目标，就必须保护正在进行的会话的状态\n信息。需要强调的是虽然“生存能力”次级目标中最重要的一条，它的优先级仍然低于顶级目标。第二目标是互联网架构应该在传输服务层支持多种服务类型。不同的服务类型是通过不同的传输需求区分的，例如\n传输速度，延迟和可靠性。TCP协议在设计之初试图支持所有类型的网络服务，但显然是十分困难的。TCP/IP的出现是为了让互联网架构能够承受并行传输，并最小化依赖性，延迟以及对带宽的需求。第三，一\n个成功的互联网架构需要能够容纳多种网络技术，从军方到商用范围。其余优先级较低的目标，或效率较低，或没有完全在工程中实现。  \n    总之，当时的互联网架构是非常成功的，网络协议被广泛使用并且衍生出了许多类似的架构。理论上存在着比数据报（datagram）更好的模块，用以得到更好的生存性以及灵活性，同时满足资源管理以及问\n责机制的需要。是当时DARPA组织的研究方向。\n\n### Named Data Networking of Things（2016）读书笔记\n\n全面部署物联网面临两大挑战，一是如何使不同种类的电子设备进行通讯，二是在建立通讯后如何保持其连续性和安全性。这篇文章讨论了NDN可以如何改善和简化物联网通讯，主要针对目前IP网络无法解决的问题。这些问题包括：\n1.\t简单的通讯任务需要复杂的解决方案\n2.\t通道和会话机制造成的安全问题\n3.\t本地通讯有严重缺陷\n物联网中的每一个“物”都会按照层次结构分配一个名字，这种命名方式与NDN根据数据名检索的检索模式恰好吻合，使得NDN十分适用于物联网网络。NDN在网络层加密命名数据，从而保证数据只被授权用户获取，以数据为中心的机制解决了物联网应用中安全性的问题。基于命名的传输方式也适用于物联网，例如对延迟的容忍度高，快速恢复丢失的本地内容以及逐跳阻塞控制。网络内存储可以让流行的内容更容易被传播，促进本地文件进行恢复，数据加密可以使最简单的NDN应用也可以享有上述的优势。  \n为了让NDN的核心网络层协议实现物联网框架的功能，在网络层需要设置必要的命名规范；控制正在运行的附件以及对附件的增删；需要做信任管理，访问控制，数据融合；应用层面的消息收发；高效的多端通讯；以及将物联网整合进因特网。  \n在NDN上实现物联网还存在许多问题，包括使用多个层次结构命名；在无基础设施的环境中进行路由；在高度有约束的设备上实现；数据收集模式的问题等。  \n","content":"<h3 id=\"The-Design-Philosophy-of-the-DARPA-Internet-Protocols（1988）-读书笔记\"><a href=\"#The-Design-Philosophy-of-the-DARPA-Internet-Protocols（1988）-读书笔记\" class=\"headerlink\" title=\"The Design Philosophy of the DARPA Internet Protocols（1988） 读书笔记\"></a>The Design Philosophy of the DARPA Internet Protocols（1988） 读书笔记</h3><pre><code>TCP/IP协议在（1988-15）年提出，本文目的是解释出于何种原因互联网协议采用了TCP/IP设计。事实上，互联网的设计哲学是从最初的协议逐步进化而来，直至现如今的标准。例如IP和TCP的层级结构，\n</code></pre><p>看起来是如今互联网协议设计的基础，但在最初的协议中并不存在。<br>    DARPA互联网架构的最高目标是研究出一个可以高效多路复用现有内联网络的技术。最初的目标是通过ARPA分组无线电网络将ARPANET连接到一起，另一种选择是设计一个统一的系统（多媒体网络），用以<br>连接多种传输媒介。同时，分组交换技术用以实现多路复用，其他的技术，例如电路交换，也曾被考虑使用。但是考虑到应用场景的支持等原因，分组交换最终成为了互联网架构的基础。最终形成了互联网<br>的基本结构：一个分组交换通信设施，其中不同网络通过网关（分组通信处理器：用以实现存储和分组转发算法）相连。<br>    文中列出了七条次级目标，这些目标是影响互联网架构设计的重要因素。其中，最重要的一条是即使网络和网关失效，互联网也应该继续提供通信服务。为达到这一目标，就必须保护正在进行的会话的状态<br>信息。需要强调的是虽然“生存能力”次级目标中最重要的一条，它的优先级仍然低于顶级目标。第二目标是互联网架构应该在传输服务层支持多种服务类型。不同的服务类型是通过不同的传输需求区分的，例如<br>传输速度，延迟和可靠性。TCP协议在设计之初试图支持所有类型的网络服务，但显然是十分困难的。TCP/IP的出现是为了让互联网架构能够承受并行传输，并最小化依赖性，延迟以及对带宽的需求。第三，一<br>个成功的互联网架构需要能够容纳多种网络技术，从军方到商用范围。其余优先级较低的目标，或效率较低，或没有完全在工程中实现。<br>    总之，当时的互联网架构是非常成功的，网络协议被广泛使用并且衍生出了许多类似的架构。理论上存在着比数据报（datagram）更好的模块，用以得到更好的生存性以及灵活性，同时满足资源管理以及问<br>责机制的需要。是当时DARPA组织的研究方向。</p>\n<h3 id=\"Named-Data-Networking-of-Things（2016）读书笔记\"><a href=\"#Named-Data-Networking-of-Things（2016）读书笔记\" class=\"headerlink\" title=\"Named Data Networking of Things（2016）读书笔记\"></a>Named Data Networking of Things（2016）读书笔记</h3><p>全面部署物联网面临两大挑战，一是如何使不同种类的电子设备进行通讯，二是在建立通讯后如何保持其连续性和安全性。这篇文章讨论了NDN可以如何改善和简化物联网通讯，主要针对目前IP网络无法解决的问题。这些问题包括：</p>\n<ol>\n<li>简单的通讯任务需要复杂的解决方案</li>\n<li>通道和会话机制造成的安全问题</li>\n<li>本地通讯有严重缺陷<br>物联网中的每一个“物”都会按照层次结构分配一个名字，这种命名方式与NDN根据数据名检索的检索模式恰好吻合，使得NDN十分适用于物联网网络。NDN在网络层加密命名数据，从而保证数据只被授权用户获取，以数据为中心的机制解决了物联网应用中安全性的问题。基于命名的传输方式也适用于物联网，例如对延迟的容忍度高，快速恢复丢失的本地内容以及逐跳阻塞控制。网络内存储可以让流行的内容更容易被传播，促进本地文件进行恢复，数据加密可以使最简单的NDN应用也可以享有上述的优势。<br>为了让NDN的核心网络层协议实现物联网框架的功能，在网络层需要设置必要的命名规范；控制正在运行的附件以及对附件的增删；需要做信任管理，访问控制，数据融合；应用层面的消息收发；高效的多端通讯；以及将物联网整合进因特网。<br>在NDN上实现物联网还存在许多问题，包括使用多个层次结构命名；在无基础设施的环境中进行路由；在高度有约束的设备上实现；数据收集模式的问题等。  </li>\n</ol>\n","slug":"互联网体系结构总结","updated":"2019-06-06T14:26:27.999Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2019/05/09/%E4%BA%92%E8%81%94%E7%BD%91%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/","excerpt":"","categories":[],"tags":[{"name":"研究生课程","slug":"研究生课程","permalink":"https://blog.providencezhang.cn/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"},{"name":"互联网体系结构","slug":"互联网体系结构","permalink":"https://blog.providencezhang.cn/tags/%E4%BA%92%E8%81%94%E7%BD%91%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"深度学习概念总结","date":"2019-03-25T13:54:50.000Z","path":"2019/03/25/深度学习概念总结/","text":"encoder-decoder类型网络autoencoder &amp; PCA (Principal component analysis)所引发的对监督/非监督学习更深入的思考： batch normalization:当然我们是可以用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 但刚刚这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生。神经网络的输入参数维度越低越好 图卷积神经网络资料非欧空间数据如何处理 vgg16:Conv5_3指的是第五个卷积block里面的第三个卷积层图卷积神经网络：eng处理非欧空间数据 聚类算法：四种 Drawing 3D (or 2D) shapes differentiably is challenging in TensorFlowDIRT(git)可以解决这个问题 查看cuda版本：cat /usr/local/cuda/version.txt查看cudnn版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2","raw":"---\ntitle: 深度学习概念总结\ndate: 2019-03-25 21:54:50\ntags:\n    - 深度学习\n    - 基础知识\ncategories: 学习笔记\n---\n\nencoder-decoder类型网络  \nautoencoder & PCA (Principal component analysis)所引发的对监督/非监督学习更深入的思考：  \n\n[batch normalization](https://morvanzhou.github.io/tutorials/machine-learning/torch/5-04-A-batch-normalization/):当然我们是可以用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 但刚刚这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生。  \n神经网络的输入参数维度越低越好\n\n图卷积神经网络[资料](http://tkipf.github.io/graph-convolutional-networks/)\n非欧空间数据如何处理\n\nvgg16:Conv5_3指的是第五个卷积block里面的第三个卷积层\n图卷积神经网络：[eng](http://tkipf.github.io/graph-convolutional-networks/)\n处理非欧空间数据\n\n聚类算法：[四种](https://blog.csdn.net/u011511601/article/details/81951939)\n\nDrawing 3D (or 2D) shapes differentiably is challenging in TensorFlow\nDIRT(git)可以解决这个问题\n\n查看cuda版本：cat /usr/local/cuda/version.txt\n查看cudnn版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2","content":"<p>encoder-decoder类型网络<br>autoencoder &amp; PCA (Principal component analysis)所引发的对监督/非监督学习更深入的思考：  </p>\n<p><a href=\"https://morvanzhou.github.io/tutorials/machine-learning/torch/5-04-A-batch-normalization/\">batch normalization</a>:当然我们是可以用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 但刚刚这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生。<br>神经网络的输入参数维度越低越好</p>\n<p>图卷积神经网络<a href=\"http://tkipf.github.io/graph-convolutional-networks/\">资料</a><br>非欧空间数据如何处理</p>\n<p>vgg16:Conv5_3指的是第五个卷积block里面的第三个卷积层<br>图卷积神经网络：<a href=\"http://tkipf.github.io/graph-convolutional-networks/\">eng</a><br>处理非欧空间数据</p>\n<p>聚类算法：<a href=\"https://blog.csdn.net/u011511601/article/details/81951939\">四种</a></p>\n<p>Drawing 3D (or 2D) shapes differentiably is challenging in TensorFlow<br>DIRT(git)可以解决这个问题</p>\n<p>查看cuda版本：cat /usr/local/cuda/version.txt<br>查看cudnn版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</p>\n","slug":"深度学习概念总结","updated":"2019-06-06T14:26:28.016Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2019/03/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93/","excerpt":"","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://blog.providencezhang.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"基础知识","slug":"基础知识","permalink":"https://blog.providencezhang.cn/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"C++ & C#/Unity notebook","date":"2019-02-18T01:06:46.000Z","path":"2019/02/18/lang-notebook/","text":"C/C++可变参数：1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt;#include &lt;stdarg.h&gt; double average(int num,...)&#123; va_list valist; double sum = 0.0; int i; /* 为 num 个参数初始化 valist */ va_start(valist, num); /* 访问所有赋给 valist 的参数 */ for (i = 0; i &lt; num; i++) &#123; sum += va_arg(valist, int); &#125; /* 清理为 valist 保留的内存 */ va_end(valist); return sum/num;&#125; int main()&#123; printf(&quot;Average of 2, 3, 4, 5 = %f\\n&quot;, average(4, 2,3,4,5)); printf(&quot;Average of 5, 10, 15 = %f\\n&quot;, average(3, 5,10,15));&#125; cdecl, fastcall, __stdcall: extern ‘C’: C++是如何处理异常的： Why can’t I separate the definition of my templates class from its declaration and put it inside a .cpp file? 右值引用与move()\\forward()函数：std::move执行一个无条件的转化到右值，更像是”rvalue_cast“；std::forward把其参数转换为右值，仅仅在那个参数被绑定到一个右值时；右值引用的目的是减少数据拷贝，提升性能 虚继承：解决菱形继承问题 在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区 栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。 堆是操作系统维护的一块内存 自由存储区是C++中通过new与delete动态分配和释放对象的抽象概念。堆与自由存储区并不等价 全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改(当然，你要通过非正当手段也可以修改)？？ 头文件声明static变量，多个文件include该头文件，会导致每个文件都有一个专属的static变量 const的物理常量性和逻辑常量性：物理常量性就是const对象不能改变，但是可以*a.ptr=anything;，逻辑常量性用mutable关键字保证，mutable的成员变量在const成员函数中也是可以改变的 constexpr：constexpr所修饰的变量一定是编译期可求值的，runtime的时候不能赋值，不然会报错，所修饰的函数在其所有参数都是constexpr时，一定会返回constexpr。 泛型技术：说白了就是试图使用不变的代码来实现可变的算法。比如：模板技术，RTTI技术，虚函数技术，要么是试图做到在编译时决议，要么试图做到运行时决议。 重载set的 oprater &lt; 就可以使set内部按特殊要求有序 LFUCache 全局对象的构造函数会在 main 函数之前先运行 extern与static：没有链接属性的标识符（none）总是被当做单独的个体，也就是说该标识符的多个声明被当做独立不同的实体。属于internal链接属性的标识符在同一个源文件内的所有声明中都指同一个实体，但位于不同源文件的多个声明则分属不同的实体。属于external链接属性的标识符不论声明多少次、位于几个源文件都表示同一个实体。 static变量初始化的问题：类成员的static变量要在代码块外初始化，否则要加const 定义与声明：区别在于是否分配空间（extern） do…while(0)的作用：宏定义函数的时候解决“；”所带来的问题。宏跟函数的区别在于宏是把参数替换到指定位置（++a的例子），imgui中也有提到 C++类的内部可以定义引用数据成员，必须通过成员函数初始化列表初始化 const修饰的属性只能在构造函数里初始化，然后就不能用变量名改值了，但是可以直接控制变量所在的地址直接修改值 pragma once：避免include重复引用一个文件空类的sizeof为1：那是被编译器插进去的一个char ，使得这个知class的不同实体（object）在内存中配道置独一无二的回地址。 类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域 p; ``` 实际意思是删除了p所指的目标（变量或对象），释放了它所占的堆空间，而不是删除p本身（指针p本身并没有撤销，它自己仍然存在，该指针所占内存空间并未释放，指针p的真正释放是随着函数调用的结束而消失），释放堆空间后，p成了\"空指针\"。如果我们在delete p后没有进行指针p的制空（p1234567891011121314151617包含纯虚函数的基类可定义指向派生类对象的基类指针和派生类对象的引用，不能直接定义自身对象 [print输出格式控制](https://blog.csdn.net/qq_37059136/article/details/80841675)vecotr的at和[]: v是个空集合的情况下，```[]```访问是行为未定义的，at访问则会抛出std::out_of_range异常。c++标准不要求vector&lt;T&gt;::operator```[]```进行下标越界检查，原因是为了效率，总是强制下标越界检查会增加程序的性能开销。设计vector是用来代替内置数组的，所以效率问题也应该考虑。 unique_ptr是智能指针的一种 comptr和unique_ptr的区别： ``` C++auto_ptr&lt;string&gt; aps(new string(&quot;abd&quot;)); auto_ptr&lt;string&gt; aps2; aps2 = aps; cout &lt;&lt; *aps &lt;&lt; endl;//报错 此时aps已经失去对string内存的所有权，如果是两个普通指针，则没有问题 cout &lt;&lt; *aps2 &lt;&lt; endl; implicit conversion/explicit conversion: pragma comment ( lib,”wpcap.lib” )表示链接wpcap.lib这个库。和在工程设置里写上链入wpcap.lib的效果一样（两种方式等价，或说一个隐式一个显式调用），不过这种方法写的 程序别人在使用你的代码的时候就不用再设置工程settings了。告诉连接器连接的时候要找ws2_32.lib，这样你就不用在linker的lib设置里指定这个lib了。 C++的钻石继承：dreaded diamond： 函数声明后边的const：const的函数不能对其数据成员进行修改操作。const的对象，不能引用非const的成员函数。 noexcept：该关键字告诉编译器，函数中不会发生异常,这有利于编译器对程序做更多的优化。如果在运行时，noexecpt函数向外抛出了异常（如果函数内部捕捉了异常并完成处理，这种情况不算抛出异常），程序会直接终止，调用std::terminate()函数，该函数内部会调用std::abort()终止程序。 class和struct的区别：最根本的引用类型和值类型 volatile: A volatile specifier is a hint to a compiler that an object may change its value in ways not specified by the language so that aggressive optimizations must be avoided. vector &amp; list:vector方便随机查询；扩容时因为它使用内存是连续的，会申请块更大的内存，造成整块内存的拷贝list由双向链表实现，好增删，不好查询 decltype:有时我们希望从表达式的类型推断出要定义的变量类型，但是不想用该表达式的值初始化变量（初始化可以用auto）。为了满足这一需求，C++11新标准引入了decltype类型说明符，它的作用是选择并返回操作数的数据类型，在此过程中，编译器分析表达式并得到它的类型，却不实际计算表达式的值。 12345678910111213int getSize();​int main(void)&#123; int tempA = 2; /*1.dclTempA为int.*/ decltype(tempA) dclTempA; /*2.dclTempB为int，对于getSize根本没有定义，但是程序依旧正常，因为decltype只做分析，并不调用getSize().*/ decltype(getSize()) dclTempB;​ return 0;&#125; 在C中，使用typedef定义struct在创建结构体是就不需要struct Student stu;了，直接使用typedef定义的别名例如S，S stu; unordered_map不能使用pair作为键值，需要提供pair的hash函数，map可以 hash_map与unordered_map: 前者使用一个下标范围比较大的数组来存储元素，形成很多的桶，利用hash函数对key进行映射到不同区域进行保存；后者记录元素的hash值，根据hash值判断元素是否相同。速度上2最优其次hash_map最次map &amp; （位 “与”） and^ （位 “异或”）| （位 “或”） or~ （位 “取反”） 位移运算符(&lt;&lt;/&gt;&gt;)：乘以/除以$2^n$ 整型最大最小值：INT_MIN,INT_MAX map&lt;&gt;如果不赋初值，不是NULL是0 vector：向量1#include &lt;vector&gt;;iterator：迭代器 STL中的基本容器顺序容器：vector，list，deque等关联容器：map，set等 upper_bound, lower_bound:1234567891011121314151617181920// lower_bound/upper_bound example#include &lt;iostream&gt; // std::cout#include &lt;algorithm&gt; // std::lower_bound, std::upper_bound, std::sort#include &lt;vector&gt; // std::vectorint main () &#123; int myints[] = &#123;10,20,30,30,20,10,10,20&#125;; std::vector&lt;int&gt; v(myints,myints+8); // 10 20 30 30 20 10 10 20 std::sort (v.begin(), v.end()); // 10 10 10 20 20 20 30 30 std::vector&lt;int&gt;::iterator low,up; low=std::lower_bound (v.begin(), v.end(), 20); // ^ up= std::upper_bound (v.begin(), v.end(), 20); // ^ std::cout &lt;&lt; &quot;lower_bound at position &quot; &lt;&lt; (low- v.begin()) &lt;&lt; &#x27;\\n&#x27;; std::cout &lt;&lt; &quot;upper_bound at position &quot; &lt;&lt; (up - v.begin()) &lt;&lt; &#x27;\\n&#x27;; return 0;&#125; a++/++a123int a = 1;cout&lt;&lt;a++&lt;&lt;endl; // 1cout&lt;&lt;a&lt;&lt;endl; // 2 12vector&lt;int&gt; &amp;nums;for(auto i : nums)&#123;&#125; unsigned 无符号的 unordered_map C++ struct 构造函数附默认值的写法：12345678910111213struct student&#123; int age; student *child; bool sex; int check; student(int input):age(input),child(nullptr),sex(true),check(1996)&#123;&#125;&#125;;int main()&#123; student a = student(18); cout&lt;&lt;a.age&lt;&lt;a.sex&lt;&lt;a.check&lt;&lt;endl; return 0;&#125;out11811996 把指针运算符 * 应用到 var 上是完全可以的，但修改 var 的值是非法的。这是因为 var 是一个指向数组开头的常量，不能作为左值。C++ 指针int var; //var 输出：20int p; p = &var; //p 输出：地址////////////////////p 输出：20引用int&amp; a; a = var; //a 输出：20 所有指针的值的实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，都是一样的，都是一个代表内存地址的长的十六进制数 引用很容易与指针混淆，它们之间有三个主要的不同： 不存在空引用。引用必须连接到一块合法的内存。 一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。 引用必须在创建时被初始化。指针可以在任何时间被初始化。 试想变量名称是变量附属在内存位置中的标签，您可以把引用当成是变量附属在内存位置中的第二个标签。因此，您可以通过原始变量名称或引用来访问变量的内容。 new动态分配内存（只能new一个指针吗？不是），delete删除，delete [] pvalue 变长数组 普通数组到vector 一维到多维 模板：函数模板/类模板 内联函数（inline属于ret-type）：啥时候用，ret-type还包括哪些？减少了函数调用，避免由函数调用带来的栈内存消耗，但是增加目标代码的大小；成员函数声明和实现写一起默认就是内联的，实现写外边就得手动加inline boost库：准标准库 string::find(&quot;a&quot;) 如果没有找到”a”，会返回一个固定的大数，且等于string::npos 的值 CC#嵌套类型：类里声明类。 struct是值类型，内存分配在栈上； Action与Func是特殊的delegate：func必须有返回值，可以加0到若干个参数，action必须没有返回值，可以加0到若干参数；用event修饰的delegate更加安全。EventHandler就是一个已经声明出来的delegate where and new()在C#中，泛型的使用非常广泛，为了泛型调用安全，经常需要对所使用的类型进行约束。在对泛型的约束中，最常使用的关键字有where 和 new。其中where关键字是约束所使用的泛型，该泛型必须是where后面的类，或者继承自该类。new()说明所使用的泛型，必须具有无参构造函数，这是为了能够正确的初始化对象 静态多态性：函数重载、运算符重载动态多态性：抽象类和虚函数（抽象类和接口的区别：抽象类比接口更详细点，可以继承多个接口，但只能一个类） 正则表达式得看看todo 装饰器 attribute 方法前边直接加个函数的区别 Unity矩阵对应的几何变换 https://orangered3stones.iteye.com/blog/1940821对于N+1维坐标表示的理解 https://www.cnblogs.com/btgyoyo/p/7085264.html碰撞检测 http://www.jmecn.net/tutorial-for-beginners/chapter-15-collision-detection.html 基于组件的引擎架构：派生关系，通过继承父类获得父类的功能，这些通用功能为了能够为各种派生类提供服务，都必须实现到基类中不再是父类中的接口，而变成子对象实例，为游戏对象提供服务组合和继承的区别gameobject都派生自object 为什么coroutine 生命周期 c#的语法 反射 代理 设计模式 工厂 单例 装饰器设计模式 shader Pythonname==”main“:之所以常看见这样的写法，是因为该程序可能有“单独执行”（例如执行一些单元测试）与“被引用”两种情况，鉴于这两种情况中name的值是不同的:当一个模块被直接执行时，其name必然等于main;当一个模块被引用时，其name必然等于文件名（不含.py）。所以利用判断name == ‘main‘的真假就可以将这两种情况区分出来。 todoC++ 语法，算法，引擎：A*再来一遍，多线程，模板，迭代器，网络同步Unity 网络Unet，Mirror","raw":"---\ntitle: C++ & C#/Unity notebook\ndate: 2019-02-18 09:06:46\ntags:\n    - C++\n    - C#\n    - Unity\n    - notebook\ncategories: 学习笔记\n---\n\n# C/C++\n\n[可变参数：](https://www.runoob.com/cprogramming/c-variable-arguments.html)  \n``` C++\n#include <stdio.h>\n#include <stdarg.h>\n \ndouble average(int num,...)\n{\n \n    va_list valist;\n    double sum = 0.0;\n    int i;\n \n    /* 为 num 个参数初始化 valist */\n    va_start(valist, num);\n \n    /* 访问所有赋给 valist 的参数 */\n    for (i = 0; i < num; i++)\n    {\n       sum += va_arg(valist, int);\n    }\n    /* 清理为 valist 保留的内存 */\n    va_end(valist);\n \n    return sum/num;\n}\n \nint main()\n{\n   printf(\"Average of 2, 3, 4, 5 = %f\\n\", average(4, 2,3,4,5));\n   printf(\"Average of 5, 10, 15 = %f\\n\", average(3, 5,10,15));\n}\n```\n\n__cdecl, __fastcall, __stdcall:   \n\nextern 'C':  \n\nC++是如何处理异常的：  \n\n[Why can’t I separate the definition of my templates class from its declaration and put it inside a .cpp file?](https://isocpp.org/wiki/faq/templates#templates-defn-vs-decl)\n\n[右值引用与move()\\forward()函数](https://blog.csdn.net/coolmeme/article/details/44459999)：std::move执行一个无条件的转化到右值，更像是\"rvalue_cast<T>\"；std::forward把其参数转换为右值，仅仅在那个参数被绑定到一个右值时；右值引用的目的是减少数据拷贝，提升性能  \n\n[虚继承](http://c.biancheng.net/view/2280.html)：解决菱形继承问题  \n\n在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区  \n1. 栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。\n2. 堆是操作系统维护的一块内存\n3. 自由存储区是C++中通过new与delete动态分配和释放对象的抽象概念。堆与自由存储区并不等价\n4. 全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。\n5. 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改(当然，你要通过非正当手段也可以修改)\n？？\n\n[头文件声明static变量，多个文件include该头文件](https://bbs.csdn.net/topics/390720572)，会导致每个文件都有一个专属的static变量  \n\nconst的物理常量性和逻辑常量性：物理常量性就是const对象不能改变，但是可以```*a.ptr=anything;```，逻辑常量性用```mutable```关键字保证，mutable的成员变量在const成员函数中也是可以改变的  \n\nconstexpr：constexpr所修饰的变量一定是编译期可求值的，runtime的时候不能赋值，不然会报错，所修饰的函数在其所有参数都是constexpr时，一定会返回constexpr。  \n\n泛型技术：说白了就是试图使用不变的代码来实现可变的算法。比如：模板技术，RTTI技术，虚函数技术，要么是试图做到在编译时决议，要么试图做到运行时决议。  \n\n重载set的 oprater < 就可以使set内部按特殊要求有序 LFUCache\n\n全局对象的构造函数会[在 main 函数之前先运行](https://www.cnblogs.com/zpcoding/p/10805639.html)\n\n[extern与static](https://www.cnblogs.com/wh5313/archive/2012/06/12/2546112.html)：没有链接属性的标识符（none）总是被当做单独的个体，也就是说该标识符的多个声明被当做独立不同的实体。属于internal链接属性的标识符在同一个源文件内的所有声明中都指同一个实体，但位于不同源文件的多个声明则分属不同的实体。属于external链接属性的标识符不论声明多少次、位于几个源文件都表示同一个实体。  \n\n[static变量初始化的问题](https://www.cnblogs.com/weizhixiang/articles/5771501.html)：类成员的static变量要在代码块外初始化，否则要加const  \n\n[定义与声明](https://www.cnblogs.com/damaohai/p/11497143.html)：区别在于是否分配空间（extern）  \n\ndo...while(0)的作用：宏定义函数的时候解决“；”所带来的问题。宏跟函数的区别在于宏是把参数替换到指定位置（++a的例子），imgui中也有提到  \n\nC++类的内部可以定义引用数据成员，必须通过成员函数初始化列表初始化  \n\nconst修饰的属性只能在构造函数里初始化，然后就不能用变量名改值了，但是可以直接控制变量所在的地址直接修改值  \n\n#pragma once：避免include重复引用一个文件  \n\n空类的sizeof为1：那是被编译器插进去的一个char ，使得这个知class的不同实体（object）在内存中配道置独一无二的回地址。\n\n类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域  \n\n``` delete p; ``` 实际意思是删除了p所指的目标（变量或对象），释放了它所占的堆空间，而不是删除p本身（指针p本身并没有撤销，它自己仍然存在，该指针所占内存空间并未释放，指针p的真正释放是随着函数调用的结束而消失），释放堆空间后，p成了\"空指针\"。如果我们在delete p后没有进行指针p的制空（p=NULL)的话，其实指针p这时会成为野指针，为了使用的安全，我们一般在delete p之后还会加上p=NULL这一语句  \n\n包含纯虚函数的基类可定义指向派生类对象的基类指针和派生类对象的引用，不能直接定义自身对象  \n\n[print输出格式控制](https://blog.csdn.net/qq_37059136/article/details/80841675)\n\nvecotr的at和[]: v是个空集合的情况下，```[]```访问是行为未定义的，at访问则会抛出std::out_of_range异常。c++标准不要求vector<T>::operator```[]```进行下标越界检查，原因是为了效率，总是强制下标越界检查会增加程序的性能开销。设计vector是用来代替内置数组的，所以效率问题也应该考虑。  \n\nunique_ptr是智能指针的一种  \n\ncomptr和unique_ptr的区别：  \n\n``` C++\nauto_ptr<string> aps(new string(\"abd\"));\n\tauto_ptr<string> aps2;\n\taps2 = aps;\n\tcout << *aps << endl;//报错 此时aps已经失去对string内存的所有权，如果是两个普通指针，则没有问题\n\tcout << *aps2 << endl;\n```\n\nimplicit conversion/explicit conversion:\n\n#pragma comment ( lib,\"wpcap.lib\" )  \n表示链接wpcap.lib这个库。和在工程设置里写上链入wpcap.lib的效果一样（两种方式等价，或说一个隐式一个显式调用），不过这种方法写的 程序别人在使用你的代码的时候就不用再设置工程settings了。告诉连接器连接的时候要找ws2_32.lib，这样你就不用在linker的lib设置里指定这个lib了。  \n\nC++的钻石继承：dreaded diamond：  \n\n函数声明后边的const：const的函数不能对其数据成员进行修改操作。const的对象，不能引用非const的成员函数。  \n\nnoexcept：该关键字告诉编译器，函数中不会发生异常,这有利于编译器对程序做更多的优化。  \n如果在运行时，noexecpt函数向外抛出了异常（如果函数内部捕捉了异常并完成处理，这种情况不算抛出异常），程序会直接终止，调用std::terminate()函数，该函数内部会调用std::abort()终止程序。  \n\n[class和struct的区别](https://zhidao.baidu.com/question/748004411503788052.html)：最根本的引用类型和值类型\n\nvolatile: A volatile specifier is a hint to a compiler that an object may change its value in ways not specified by the language so that aggressive optimizations must be avoided.\n\nvector & list: \nvector方便随机查询；扩容时因为它使用内存是连续的，会申请块更大的内存，造成整块内存的拷贝  \nlist由双向链表实现，好增删，不好查询  \n\n[decltype](https://www.cnblogs.com/ghbjimmy/p/10636030.html):有时我们希望从表达式的类型推断出要定义的变量类型，但是不想用该表达式的值初始化变量（初始化可以用auto）。为了满足这一需求，C++11新标准引入了decltype类型说明符，它的作用是选择并返回操作数的数据类型，在此过程中，编译器分析表达式并得到它的类型，却不实际计算表达式的值。  \n\n``` C++\nint getSize();\n​\nint main(void)\n{\n    int tempA = 2;\n    \n    /*1.dclTempA为int.*/\n    decltype(tempA) dclTempA;\n    /*2.dclTempB为int，对于getSize根本没有定义，但是程序依旧正常，因为decltype只做分析，并不调用getSize().*/\n    decltype(getSize()) dclTempB;\n​\n    return 0;\n}\n```\n\n在C中，使用typedef定义struct在创建结构体是就不需要``` struct Student stu; ```了，直接使用typedef定义的别名例如S，``` S stu; ```\n\nunordered_map不能使用pair作为键值，需要提供pair的hash函数，map可以  \n\nhash_map与unordered_map: 前者使用一个下标范围比较大的数组来存储元素，形成很多的桶，利用hash函数对key进行映射到不同区域进行保存；\n后者记录元素的hash值，根据hash值判断元素是否相同。  \n速度上2最优其次hash_map最次map  \n\n&  （位   “与”）  and  \n^  （位   “异或”）  \n|  （位   “或”）   or  \n~  （位   “取反”）  \n\n位移运算符(<</>>)：乘以/除以$2^n$\n\n整型最大最小值：INT_MIN,INT_MAX\n\nmap<>如果不赋初值，不是NULL是0\n\n[vector](http://www.cnblogs.com/Nonono-nw/p/3462183.html)：向量\n``` bash\n#include <vector>;\n```\n[iterator](https://www.cnblogs.com/maluning/p/8570717.html)：迭代器  \n\n[STL中的基本容器](https://www.cnblogs.com/cxq0017/p/6555533.html)  \n顺序容器：vector，list，deque等\n关联容器：map，set等\n\nupper_bound, lower_bound:  \n``` bash\n// lower_bound/upper_bound example\n#include <iostream>     // std::cout\n#include <algorithm>    // std::lower_bound, std::upper_bound, std::sort\n#include <vector>       // std::vector\n\nint main () {\n  int myints[] = {10,20,30,30,20,10,10,20};\n  std::vector<int> v(myints,myints+8);           // 10 20 30 30 20 10 10 20\n\n  std::sort (v.begin(), v.end());                // 10 10 10 20 20 20 30 30\n\n  std::vector<int>::iterator low,up;\n  low=std::lower_bound (v.begin(), v.end(), 20); //          ^\n  up= std::upper_bound (v.begin(), v.end(), 20); //                   ^\n\n  std::cout << \"lower_bound at position \" << (low- v.begin()) << '\\n';\n  std::cout << \"upper_bound at position \" << (up - v.begin()) << '\\n';\n\n  return 0;\n}\n```\n\na++/++a\n``` bash\nint a = 1;\ncout<<a++<<endl;  // 1\ncout<<a<<endl;    // 2\n```\n\n``` bash\nvector<int> &nums;\nfor(auto i : nums){}\n```\n\nunsigned 无符号的  \n\n[unordered_map](http://www.cplusplus.com/reference/unordered_map/unordered_map/?kw=unordered_map)\n\nC++ struct 构造函数附默认值的写法：\n``` bash\nstruct student{\n    int age;\n    student *child;\n    bool sex;\n    int check;\n    student(int input):age(input),child(nullptr),sex(true),check(1996){}\n};\n\nint main(){\n    student a = student(18);\n    cout<<a.age<<a.sex<<a.check<<endl;\n    return 0;\n}\n```\nout\n``` bash\n1811996\n```\n\n把指针运算符 * 应用到 var 上是完全可以的，但修改 var 的值是非法的。这是因为 var 是一个指向数组开头的常量，不能作为左值。[C++](https://www.runoob.com/cplusplus/cpp-pointers-vs-arrays.html)  \n\n**指针**int var; //var 输出：20  \nint* p; p = &var; //p 输出：地址   \n////////////////////*p 输出：20  \n**引用**int& a; a = var; //a 输出：20  \n\n所有指针的值的实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，都是一样的，都是一个代表内存地址的长的十六进制数  \n\n引用很容易与指针混淆，它们之间有三个主要的不同：  \n  1. 不存在空引用。引用必须连接到一块合法的内存。  \n  2. 一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。  \n  3. 引用必须在创建时被初始化。指针可以在任何时间被初始化。 \n\n试想变量名称是变量附属在内存位置中的标签，您可以把引用当成是变量附属在内存位置中的第二个标签。因此，您可以通过原始变量名称或引用来访问变量的内容。  \n\nnew动态分配内存（只能new一个指针吗？不是），delete删除，delete [] pvalue\n\n[变长数组](https://blog.csdn.net/fanyun_01/article/details/77430682) 普通数组到vector 一维到多维  \n\n模板：函数模板/类模板  \n\n[内联函数](https://www.jianshu.com/p/a57a7884d6e8)（inline属于ret-type）：啥时候用，ret-type还包括哪些？  \n减少了函数调用，避免由函数调用带来的栈内存消耗，但是增加目标代码的大小；  \n成员函数声明和实现写一起默认就是内联的，实现写外边就得手动加inline  \n\n**boost库**：准标准库\n\n`string::find(\"a\")` 如果没有找到\"a\"，会返回一个固定的大数，且等于`string::npos` 的值\n\n# C#\n\n[C#嵌套类型](https://www.cnblogs.com/rinack/p/5695610.html)：类里声明类。  \n\nstruct是值类型，内存分配在栈上；  \n\nAction与Func是特殊的delegate：func必须有返回值，可以加0到若干个参数，action必须没有返回值，可以加0到若干参数；用event修饰的delegate更加安全。  \nEventHandler就是一个已经声明出来的delegate  \n\n**where and new()**\n在C#中，泛型的使用非常广泛，为了泛型调用安全，经常需要对所使用的类型进行约束。  \n在对泛型的约束中，最常使用的关键字有where 和 new。  \n其中where关键字是约束所使用的泛型，该泛型必须是where后面的类，或者继承自该类。  \nnew()说明所使用的泛型，必须具有无参构造函数，这是为了能够正确的初始化对象  \n\n静态多态性：函数重载、运算符重载  \n动态多态性：抽象类和虚函数（抽象类和接口的区别：抽象类比接口更详细点，可以继承多个接口，但只能一个类）\n\n**正则表达式得看看todo**\n\n装饰器 attribute 方法前边直接加个函数的区别\n\n\n# Unity\n\n矩阵对应的几何变换 https://orangered3stones.iteye.com/blog/1940821  \n对于N+1维坐标表示的理解 https://www.cnblogs.com/btgyoyo/p/7085264.html  \n碰撞检测 http://www.jmecn.net/tutorial-for-beginners/chapter-15-collision-detection.html\n\n基于组件的引擎架构：  \n派生关系，通过继承父类获得父类的功能，这些通用功能为了能够为各种派生类提供服务，都必须实现到基类中  \n不再是父类中的接口，而变成子对象实例，为游戏对象提供服务  \n组合和继承的区别  \ngameobject都派生自object 为什么  \ncoroutine 生命周期 c#的语法 反射 代理 设计模式 工厂 单例 装饰器  \n设计模式 shader\n\n# Python\n\n__name__==\"__main__\":之所以常看见这样的写法，是因为该程序可能有“单独执行”（例如执行一些单元测试）与“被引用”两种情况，鉴于这两种情况中__name__的值是不同的:当一个模块被直接执行时，其__name__必然等于__main__;当一个模块被引用时，其__name__必然等于文件名（不含.py）。所以利用判断__name__ == '__main__'的真假就可以将这两种情况区分出来。\n\n# todo\n\nC++ 语法，算法，引擎：A*再来一遍，多线程，模板，迭代器，网络同步  \nUnity 网络Unet，Mirror","content":"<h1 id=\"C-C\"><a href=\"#C-C\" class=\"headerlink\" title=\"C/C++\"></a>C/C++</h1><p><a href=\"https://www.runoob.com/cprogramming/c-variable-arguments.html\">可变参数：</a><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdarg.h&gt;</span></span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">average</span><span class=\"params\">(<span class=\"keyword\">int</span> num,...)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"> </span><br><span class=\"line\">    va_list valist;</span><br><span class=\"line\">    <span class=\"keyword\">double</span> sum = <span class=\"number\">0.0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i;</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"comment\">/* 为 num 个参数初始化 valist */</span></span><br><span class=\"line\">    <span class=\"built_in\">va_start</span>(valist, num);</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"comment\">/* 访问所有赋给 valist 的参数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; num; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">       sum += <span class=\"built_in\">va_arg</span>(valist, <span class=\"keyword\">int</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/* 清理为 valist 保留的内存 */</span></span><br><span class=\"line\">    <span class=\"built_in\">va_end</span>(valist);</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"keyword\">return</span> sum/num;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">   <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;Average of 2, 3, 4, 5 = %f\\n&quot;</span>, <span class=\"built_in\">average</span>(<span class=\"number\">4</span>, <span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>));</span><br><span class=\"line\">   <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;Average of 5, 10, 15 = %f\\n&quot;</span>, <span class=\"built_in\">average</span>(<span class=\"number\">3</span>, <span class=\"number\">5</span>,<span class=\"number\">10</span>,<span class=\"number\">15</span>));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>cdecl, </strong>fastcall, __stdcall:   </p>\n<p>extern ‘C’:  </p>\n<p>C++是如何处理异常的：  </p>\n<p><a href=\"https://isocpp.org/wiki/faq/templates#templates-defn-vs-decl\">Why can’t I separate the definition of my templates class from its declaration and put it inside a .cpp file?</a></p>\n<p><a href=\"https://blog.csdn.net/coolmeme/article/details/44459999\">右值引用与move()\\forward()函数</a>：std::move执行一个无条件的转化到右值，更像是”rvalue_cast<T>“；std::forward把其参数转换为右值，仅仅在那个参数被绑定到一个右值时；右值引用的目的是减少数据拷贝，提升性能  </p>\n<p><a href=\"http://c.biancheng.net/view/2280.html\">虚继承</a>：解决菱形继承问题  </p>\n<p>在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区  </p>\n<ol>\n<li>栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。</li>\n<li>堆是操作系统维护的一块内存</li>\n<li>自由存储区是C++中通过new与delete动态分配和释放对象的抽象概念。堆与自由存储区并不等价</li>\n<li>全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。</li>\n<li>常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改(当然，你要通过非正当手段也可以修改)<br>？？</li>\n</ol>\n<p><a href=\"https://bbs.csdn.net/topics/390720572\">头文件声明static变量，多个文件include该头文件</a>，会导致每个文件都有一个专属的static变量  </p>\n<p>const的物理常量性和逻辑常量性：物理常量性就是const对象不能改变，但是可以<code>*a.ptr=anything;</code>，逻辑常量性用<code>mutable</code>关键字保证，mutable的成员变量在const成员函数中也是可以改变的  </p>\n<p>constexpr：constexpr所修饰的变量一定是编译期可求值的，runtime的时候不能赋值，不然会报错，所修饰的函数在其所有参数都是constexpr时，一定会返回constexpr。  </p>\n<p>泛型技术：说白了就是试图使用不变的代码来实现可变的算法。比如：模板技术，RTTI技术，虚函数技术，要么是试图做到在编译时决议，要么试图做到运行时决议。  </p>\n<p>重载set的 oprater &lt; 就可以使set内部按特殊要求有序 LFUCache</p>\n<p>全局对象的构造函数会<a href=\"https://www.cnblogs.com/zpcoding/p/10805639.html\">在 main 函数之前先运行</a></p>\n<p><a href=\"https://www.cnblogs.com/wh5313/archive/2012/06/12/2546112.html\">extern与static</a>：没有链接属性的标识符（none）总是被当做单独的个体，也就是说该标识符的多个声明被当做独立不同的实体。属于internal链接属性的标识符在同一个源文件内的所有声明中都指同一个实体，但位于不同源文件的多个声明则分属不同的实体。属于external链接属性的标识符不论声明多少次、位于几个源文件都表示同一个实体。  </p>\n<p><a href=\"https://www.cnblogs.com/weizhixiang/articles/5771501.html\">static变量初始化的问题</a>：类成员的static变量要在代码块外初始化，否则要加const  </p>\n<p><a href=\"https://www.cnblogs.com/damaohai/p/11497143.html\">定义与声明</a>：区别在于是否分配空间（extern）  </p>\n<p>do…while(0)的作用：宏定义函数的时候解决“；”所带来的问题。宏跟函数的区别在于宏是把参数替换到指定位置（++a的例子），imgui中也有提到  </p>\n<p>C++类的内部可以定义引用数据成员，必须通过成员函数初始化列表初始化  </p>\n<p>const修饰的属性只能在构造函数里初始化，然后就不能用变量名改值了，但是可以直接控制变量所在的地址直接修改值  </p>\n<h1 id=\"pragma-once：避免include重复引用一个文件\"><a href=\"#pragma-once：避免include重复引用一个文件\" class=\"headerlink\" title=\"pragma once：避免include重复引用一个文件\"></a>pragma once：避免include重复引用一个文件</h1><p>空类的sizeof为1：那是被编译器插进去的一个char ，使得这个知class的不同实体（object）在内存中配道置独一无二的回地址。</p>\n<p>类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域  </p>\n<figure class=\"highlight plaintext\"><figcaption><span>p; ``` 实际意思是删除了p所指的目标（变量或对象），释放了它所占的堆空间，而不是删除p本身（指针p本身并没有撤销，它自己仍然存在，该指针所占内存空间并未释放，指针p的真正释放是随着函数调用的结束而消失），释放堆空间后，p成了\"空指针\"。如果我们在delete p后没有进行指针p的制空（p</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">包含纯虚函数的基类可定义指向派生类对象的基类指针和派生类对象的引用，不能直接定义自身对象  </span><br><span class=\"line\"></span><br><span class=\"line\">[print输出格式控制](https://blog.csdn.net/qq_37059136/article/details/80841675)</span><br><span class=\"line\"></span><br><span class=\"line\">vecotr的at和[]: v是个空集合的情况下，```[]```访问是行为未定义的，at访问则会抛出std::out_of_range异常。c++标准不要求vector&lt;T&gt;::operator```[]```进行下标越界检查，原因是为了效率，总是强制下标越界检查会增加程序的性能开销。设计vector是用来代替内置数组的，所以效率问题也应该考虑。  </span><br><span class=\"line\"></span><br><span class=\"line\">unique_ptr是智能指针的一种  </span><br><span class=\"line\"></span><br><span class=\"line\">comptr和unique_ptr的区别：  </span><br><span class=\"line\"></span><br><span class=\"line\">``` C++</span><br><span class=\"line\">auto_ptr&lt;string&gt; aps(new string(&quot;abd&quot;));</span><br><span class=\"line\">\tauto_ptr&lt;string&gt; aps2;</span><br><span class=\"line\">\taps2 = aps;</span><br><span class=\"line\">\tcout &lt;&lt; *aps &lt;&lt; endl;//报错 此时aps已经失去对string内存的所有权，如果是两个普通指针，则没有问题</span><br><span class=\"line\">\tcout &lt;&lt; *aps2 &lt;&lt; endl;</span><br></pre></td></tr></table></figure>\n<p>implicit conversion/explicit conversion:</p>\n<h1 id=\"pragma-comment-lib-”wpcap-lib”\"><a href=\"#pragma-comment-lib-”wpcap-lib”\" class=\"headerlink\" title=\"pragma comment ( lib,”wpcap.lib” )\"></a>pragma comment ( lib,”wpcap.lib” )</h1><p>表示链接wpcap.lib这个库。和在工程设置里写上链入wpcap.lib的效果一样（两种方式等价，或说一个隐式一个显式调用），不过这种方法写的 程序别人在使用你的代码的时候就不用再设置工程settings了。告诉连接器连接的时候要找ws2_32.lib，这样你就不用在linker的lib设置里指定这个lib了。  </p>\n<p>C++的钻石继承：dreaded diamond：  </p>\n<p>函数声明后边的const：const的函数不能对其数据成员进行修改操作。const的对象，不能引用非const的成员函数。  </p>\n<p>noexcept：该关键字告诉编译器，函数中不会发生异常,这有利于编译器对程序做更多的优化。<br>如果在运行时，noexecpt函数向外抛出了异常（如果函数内部捕捉了异常并完成处理，这种情况不算抛出异常），程序会直接终止，调用std::terminate()函数，该函数内部会调用std::abort()终止程序。  </p>\n<p><a href=\"https://zhidao.baidu.com/question/748004411503788052.html\">class和struct的区别</a>：最根本的引用类型和值类型</p>\n<p>volatile: A volatile specifier is a hint to a compiler that an object may change its value in ways not specified by the language so that aggressive optimizations must be avoided.</p>\n<p>vector &amp; list:<br>vector方便随机查询；扩容时因为它使用内存是连续的，会申请块更大的内存，造成整块内存的拷贝<br>list由双向链表实现，好增删，不好查询  </p>\n<p><a href=\"https://www.cnblogs.com/ghbjimmy/p/10636030.html\">decltype</a>:有时我们希望从表达式的类型推断出要定义的变量类型，但是不想用该表达式的值初始化变量（初始化可以用auto）。为了满足这一需求，C++11新标准引入了decltype类型说明符，它的作用是选择并返回操作数的数据类型，在此过程中，编译器分析表达式并得到它的类型，却不实际计算表达式的值。  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getSize</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">​</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> tempA = <span class=\"number\">2</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">/*1.dclTempA为int.*/</span></span><br><span class=\"line\">    <span class=\"keyword\">decltype</span>(tempA) dclTempA;</span><br><span class=\"line\">    <span class=\"comment\">/*2.dclTempB为int，对于getSize根本没有定义，但是程序依旧正常，因为decltype只做分析，并不调用getSize().*/</span></span><br><span class=\"line\">    <span class=\"keyword\">decltype</span>(<span class=\"built_in\">getSize</span>()) dclTempB;</span><br><span class=\"line\">​</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在C中，使用typedef定义struct在创建结构体是就不需要<code>struct Student stu;</code>了，直接使用typedef定义的别名例如S，<code>S stu;</code></p>\n<p>unordered_map不能使用pair作为键值，需要提供pair的hash函数，map可以  </p>\n<p>hash_map与unordered_map: 前者使用一个下标范围比较大的数组来存储元素，形成很多的桶，利用hash函数对key进行映射到不同区域进行保存；<br>后者记录元素的hash值，根据hash值判断元素是否相同。<br>速度上2最优其次hash_map最次map  </p>\n<p>&amp;  （位   “与”）  and<br>^  （位   “异或”）<br>|  （位   “或”）   or<br>~  （位   “取反”）  </p>\n<p>位移运算符(&lt;&lt;/&gt;&gt;)：乘以/除以$2^n$</p>\n<p>整型最大最小值：INT_MIN,INT_MAX</p>\n<p>map&lt;&gt;如果不赋初值，不是NULL是0</p>\n<p><a href=\"http://www.cnblogs.com/Nonono-nw/p/3462183.html\">vector</a>：向量<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include &lt;vector&gt;;</span></span><br></pre></td></tr></table></figure><br><a href=\"https://www.cnblogs.com/maluning/p/8570717.html\">iterator</a>：迭代器  </p>\n<p><a href=\"https://www.cnblogs.com/cxq0017/p/6555533.html\">STL中的基本容器</a><br>顺序容器：vector，list，deque等<br>关联容器：map，set等</p>\n<p>upper_bound, lower_bound:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// lower_bound/upper_bound example</span><br><span class=\"line\"><span class=\"comment\">#include &lt;iostream&gt;     // std::cout</span></span><br><span class=\"line\"><span class=\"comment\">#include &lt;algorithm&gt;    // std::lower_bound, std::upper_bound, std::sort</span></span><br><span class=\"line\"><span class=\"comment\">#include &lt;vector&gt;       // std::vector</span></span><br><span class=\"line\"></span><br><span class=\"line\">int <span class=\"function\"><span class=\"title\">main</span></span> () &#123;</span><br><span class=\"line\">  int myints[] = &#123;10,20,30,30,20,10,10,20&#125;;</span><br><span class=\"line\">  std::vector&lt;int&gt; v(myints,myints+8);           // 10 20 30 30 20 10 10 20</span><br><span class=\"line\"></span><br><span class=\"line\">  std::sort (v.begin(), v.end());                // 10 10 10 20 20 20 30 30</span><br><span class=\"line\"></span><br><span class=\"line\">  std::vector&lt;int&gt;::iterator low,up;</span><br><span class=\"line\">  low=std::lower_bound (v.begin(), v.end(), 20); //          ^</span><br><span class=\"line\">  up= std::upper_bound (v.begin(), v.end(), 20); //                   ^</span><br><span class=\"line\"></span><br><span class=\"line\">  std::cout &lt;&lt; <span class=\"string\">&quot;lower_bound at position &quot;</span> &lt;&lt; (low- v.begin()) &lt;&lt; <span class=\"string\">&#x27;\\n&#x27;</span>;</span><br><span class=\"line\">  std::cout &lt;&lt; <span class=\"string\">&quot;upper_bound at position &quot;</span> &lt;&lt; (up - v.begin()) &lt;&lt; <span class=\"string\">&#x27;\\n&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">return</span> 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>a++/++a<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 1;</span><br><span class=\"line\">cout&lt;&lt;<span class=\"string\">a++&lt;&lt;endl;  // 1</span></span><br><span class=\"line\"><span class=\"string\">cout&lt;&lt;a</span>&lt;&lt;<span class=\"string\">endl;    // 2</span></span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector&lt;int&gt; &amp;nums;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(auto i : nums)&#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>unsigned 无符号的  </p>\n<p><a href=\"http://www.cplusplus.com/reference/unordered_map/unordered_map/?kw=unordered_map\">unordered_map</a></p>\n<p>C++ struct 构造函数附默认值的写法：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct student&#123;</span><br><span class=\"line\">    int age;</span><br><span class=\"line\">    student *child;</span><br><span class=\"line\">    bool sex;</span><br><span class=\"line\">    int check;</span><br><span class=\"line\">    student(int input):age(input),child(nullptr),sex(<span class=\"literal\">true</span>),check(1996)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">int <span class=\"function\"><span class=\"title\">main</span></span>()&#123;</span><br><span class=\"line\">    student a = student(18);</span><br><span class=\"line\">    cout&lt;&lt;<span class=\"string\">a.age&lt;&lt;a</span>.sex&lt;&lt;<span class=\"string\">a.check&lt;&lt;endl;</span></span><br><span class=\"line\"><span class=\"string\">    return 0;</span></span><br><span class=\"line\"><span class=\"string\">&#125;</span></span><br></pre></td></tr></table></figure><br>out<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1811996</span><br></pre></td></tr></table></figure></p>\n<p>把指针运算符 * 应用到 var 上是完全可以的，但修改 var 的值是非法的。这是因为 var 是一个指向数组开头的常量，不能作为左值。<a href=\"https://www.runoob.com/cplusplus/cpp-pointers-vs-arrays.html\">C++</a>  </p>\n<p><strong>指针</strong>int var; //var 输出：20<br>int<em> p; p = &var; //p 输出：地址<br>////////////////////</em>p 输出：20<br><strong>引用</strong>int&amp; a; a = var; //a 输出：20  </p>\n<p>所有指针的值的实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，都是一样的，都是一个代表内存地址的长的十六进制数  </p>\n<p>引用很容易与指针混淆，它们之间有三个主要的不同：  </p>\n<ol>\n<li>不存在空引用。引用必须连接到一块合法的内存。  </li>\n<li>一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。  </li>\n<li>引用必须在创建时被初始化。指针可以在任何时间被初始化。 </li>\n</ol>\n<p>试想变量名称是变量附属在内存位置中的标签，您可以把引用当成是变量附属在内存位置中的第二个标签。因此，您可以通过原始变量名称或引用来访问变量的内容。  </p>\n<p>new动态分配内存（只能new一个指针吗？不是），delete删除，delete [] pvalue</p>\n<p><a href=\"https://blog.csdn.net/fanyun_01/article/details/77430682\">变长数组</a> 普通数组到vector 一维到多维  </p>\n<p>模板：函数模板/类模板  </p>\n<p><a href=\"https://www.jianshu.com/p/a57a7884d6e8\">内联函数</a>（inline属于ret-type）：啥时候用，ret-type还包括哪些？<br>减少了函数调用，避免由函数调用带来的栈内存消耗，但是增加目标代码的大小；<br>成员函数声明和实现写一起默认就是内联的，实现写外边就得手动加inline  </p>\n<p><strong>boost库</strong>：准标准库</p>\n<p><code>string::find(&quot;a&quot;)</code> 如果没有找到”a”，会返回一个固定的大数，且等于<code>string::npos</code> 的值</p>\n<h1 id=\"C\"><a href=\"#C\" class=\"headerlink\" title=\"C\"></a>C</h1><p><a href=\"https://www.cnblogs.com/rinack/p/5695610.html\">C#嵌套类型</a>：类里声明类。  </p>\n<p>struct是值类型，内存分配在栈上；  </p>\n<p>Action与Func是特殊的delegate：func必须有返回值，可以加0到若干个参数，action必须没有返回值，可以加0到若干参数；用event修饰的delegate更加安全。<br>EventHandler就是一个已经声明出来的delegate  </p>\n<p><strong>where and new()</strong><br>在C#中，泛型的使用非常广泛，为了泛型调用安全，经常需要对所使用的类型进行约束。<br>在对泛型的约束中，最常使用的关键字有where 和 new。<br>其中where关键字是约束所使用的泛型，该泛型必须是where后面的类，或者继承自该类。<br>new()说明所使用的泛型，必须具有无参构造函数，这是为了能够正确的初始化对象  </p>\n<p>静态多态性：函数重载、运算符重载<br>动态多态性：抽象类和虚函数（抽象类和接口的区别：抽象类比接口更详细点，可以继承多个接口，但只能一个类）</p>\n<p><strong>正则表达式得看看todo</strong></p>\n<p>装饰器 attribute 方法前边直接加个函数的区别</p>\n<h1 id=\"Unity\"><a href=\"#Unity\" class=\"headerlink\" title=\"Unity\"></a>Unity</h1><p>矩阵对应的几何变换 <a href=\"https://orangered3stones.iteye.com/blog/1940821\">https://orangered3stones.iteye.com/blog/1940821</a><br>对于N+1维坐标表示的理解 <a href=\"https://www.cnblogs.com/btgyoyo/p/7085264.html\">https://www.cnblogs.com/btgyoyo/p/7085264.html</a><br>碰撞检测 <a href=\"http://www.jmecn.net/tutorial-for-beginners/chapter-15-collision-detection.html\">http://www.jmecn.net/tutorial-for-beginners/chapter-15-collision-detection.html</a></p>\n<p>基于组件的引擎架构：<br>派生关系，通过继承父类获得父类的功能，这些通用功能为了能够为各种派生类提供服务，都必须实现到基类中<br>不再是父类中的接口，而变成子对象实例，为游戏对象提供服务<br>组合和继承的区别<br>gameobject都派生自object 为什么<br>coroutine 生命周期 c#的语法 反射 代理 设计模式 工厂 单例 装饰器<br>设计模式 shader</p>\n<h1 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h1><p><strong>name</strong>==”<strong>main</strong>“:之所以常看见这样的写法，是因为该程序可能有“单独执行”（例如执行一些单元测试）与“被引用”两种情况，鉴于这两种情况中<strong>name</strong>的值是不同的:当一个模块被直接执行时，其<strong>name</strong>必然等于<strong>main</strong>;当一个模块被引用时，其<strong>name</strong>必然等于文件名（不含.py）。所以利用判断<strong>name</strong> == ‘<strong>main</strong>‘的真假就可以将这两种情况区分出来。</p>\n<h1 id=\"todo\"><a href=\"#todo\" class=\"headerlink\" title=\"todo\"></a>todo</h1><p>C++ 语法，算法，引擎：A*再来一遍，多线程，模板，迭代器，网络同步<br>Unity 网络Unet，Mirror</p>\n","slug":"lang-notebook","updated":"2021-01-06T04:42:54.511Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2019/02/18/lang-notebook/","excerpt":"","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"Unity","slug":"Unity","permalink":"https://blog.providencezhang.cn/tags/Unity/"},{"name":"C#","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"notebook","slug":"notebook","permalink":"https://blog.providencezhang.cn/tags/notebook/"}]},{"title":"python数据分析、可视化相关笔记","date":"2019-01-21T13:23:34.000Z","path":"2019/01/21/Kaggle笔记/","text":"python数据分析、可视化相关笔记我的主页 sklearn-tsne提供了数据可视化的工具：TSNE提供了一种有效的降维方式，让我们对高于2维数据的聚类结果以二维的方式展示出来pytorch的dataloader出来有三个部分（编号，tensor（图片内容信息（100张，1个通道，长，宽）），tensor（标注））","raw":"---\ntitle: python数据分析、可视化相关笔记\ndate: 2019-01-21 21:23:34\ntags:\n    - 数据分析\n    - 数据可视化\n    - Kaggle\ncategories: 学习笔记\n---\n\n# python数据分析、可视化相关笔记\n\n[我的主页](https://www.kaggle.com/taye310)\n\nsklearn-tsne提供了数据可视化的工具：TSNE提供了一种有效的降维方式，让我们对高于2维数据的聚类结果以二维的方式展示出来  \npytorch的dataloader出来有三个部分（编号，tensor（图片内容信息（100张，1个通道，长，宽）），tensor（标注））","content":"<h1 id=\"python数据分析、可视化相关笔记\"><a href=\"#python数据分析、可视化相关笔记\" class=\"headerlink\" title=\"python数据分析、可视化相关笔记\"></a>python数据分析、可视化相关笔记</h1><p><a href=\"https://www.kaggle.com/taye310\">我的主页</a></p>\n<p>sklearn-tsne提供了数据可视化的工具：TSNE提供了一种有效的降维方式，让我们对高于2维数据的聚类结果以二维的方式展示出来<br>pytorch的dataloader出来有三个部分（编号，tensor（图片内容信息（100张，1个通道，长，宽）），tensor（标注））</p>\n","slug":"Kaggle笔记","updated":"2019-05-04T11:31:57.266Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2019/01/21/Kaggle%E7%AC%94%E8%AE%B0/","excerpt":"","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"https://blog.providencezhang.cn/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://blog.providencezhang.cn/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"Kaggle","slug":"Kaggle","permalink":"https://blog.providencezhang.cn/tags/Kaggle/"}]},{"title":"关于三维重建的文献综述","date":"2019-01-03T23:58:17.000Z","path":"2019/01/04/关于三维重建的文献综述/","text":"目录arXiv检索 1812.10558 通过视频素材实现从2d到3d的面部重建来完成测谎 1812.01742 单一视角的三维重建，使用对抗训练（非人 1812.05583 基于学习的ICP（迭代最近点算法）重构场景（非人 1812.07603 通过视频素材的面部模型学习 1812.05806 自我监督的引导方法，单图片的三维人脸重建 1812.02822 学习生成模型的隐藏区域（非人 1901.00049 基于轮廓的衣着人物（全身 A类 通过直接体积cnn回归从单图重建大范围三维人脸（源码lua+py 使用图到图转换的无限制面部重建（源码lua 老师推荐 使用affinity field的实时多人二维姿态估计 综述通用关于三维重建单个图像进行三维重建的数据驱动方法：一是明确使用三维结构，二是使用其他信息推断三维结构2DImage—&gt;encoder—&gt;latent representation—&gt;decoder—&gt;3DObject不同方法区别在于对三维世界采取的限制：多视图一致性学习三维表示、利用关键点和轮廓注释、利用2.5D草图（法线，深度和轮廓）改善预测 encoder-decoder的含义 关于shape priors许多方法选择更好的捕捉多样的真实形状non-deep方法关注低维参数模型，使用CNN来学习2D渲染图像和3D形状的共同嵌入空间其他方法依赖生成模型去学习shape priors 博客链接3D人脸重建学习笔记CSDN3D重建的学习笔记简书 Learning Single-View 3D Reconstruction with Adversarial Training 1812.01742传统方法用多个角度的多张照片实现三维建模问题两个：一是需要大量的观察点；二是物体表面是Lambertian（非反射）albedos是非均匀的另一种三维重建的方式是利用物体外观和形状的知识从单视图二维图像生成（假设shape priors足够丰富）CAD库（computer-aided design）：shapenet，pascal3d+，objectnet3d，pix3d 这些方法都从渲染的图像中回归三维形状：将二位图像转化成潜在表示的编码器 以及 重建三维表示的解码器为了学习shape priors深度学习算法需要大量的三维对象注释，自然图像中获取三维注释很有挑战，因此使用合成图像（三维模型渲染出的图像）CNN的domain shift问题，导致基于cnn的三维重建性能恶化 这篇文章的方法：提高重建模型性能，为了实现获取三维物体标签，他们shape priors训练出的网络有个重建损失值，给这个值引入了两个限制一是受domain shift文献启示，强制让编码的二维特征不变，对应于他们所来自的domain。这样合成图像训练出的编码器在真实图像上表现更好二是将编码的二维特征限制在现实物体的多种形状之中，通过对抗训练定义这两个损失值总结：一个模型和损失函数，利用shape priors提高自然图像三维重建性能（两种方式使用对抗训练）reconstruction adversarial network(RAN)只使用rgb图像信息，和易于获取的自然图像。独立于编码器和解码器，并且可以使用到其中借鉴了domain confusion（作用是classification），为了让从合成图像里训练出来的模型在真实图像这边有更好的表现 具体方法：todo 通过直接体积cnn回归从单图重建大范围三维人脸目前三维人脸重建的方法多假定有多张面部图片可以使用，这使得重建面临方法上的挑战：在夸张的表情、不均匀光照上建立稠密对应关系这些方法需要复杂低效的管道构建模型，拟合模型。本文建议通过在由2D图像和3D面部模型或扫描组成的适当数据集上训练卷积神经网络（CNN）来解决这些限制 Extreme 3D Face Reconstruction: Seeing Through Occlusions 极端3D面部重建：遮挡透视（讲）bumpingmapping概念的推动下，该文提出了一种分层方法。将全局形状与其中细节进行解耦。估计粗糙的3d面部形状为基础，然后将此基础与凹凸贴图表示的细节分开。与本文相关的工作： reconstruction by example 这类方法用三维脸部形状去调整根据输入图片估计出的模型，降低了观看条件却损失了真实度与准确性 face shape from facial landmarks 这类方法稳定但是模型都差不多，没有细节，而且不清楚遮挡landmark的情况下表现会如何 SfS Shape-From-shading 根据光反射生成细节丰富的模型，但是受环境影响严重，需要满足其对环境的特殊要求。任何遮挡物都会生成到模型中 statistical representations 最著名的方法是3DMM，这篇文改进了这个方法直接根据图片强度信息用cnn回归3DMM的参数和面部细节 deep face shape estimation 深度网络一是直接用深度图重建，二是estimate 3D shapes with anemphasis on unconstrained photo 观察条件高度不变但是细节模糊 准备工作矛盾：整体形状的高度正则化vs细节的弱正则化。解决方法：bump map representations which separate global shape from local details 理解的正则化：使模型更有普适性，低正则化是让模型有更多细节、更有特点，反之是让模型更接近普适的规则（每个模型都有一只鼻子一张嘴两只眼睛）给一张图片建立以下几个部分：基础形状——S，面部表情——E，6维度的自由视点——V。接下来是bump map捕捉中级特征（皱纹等非参数的），最后完成因遮挡丢失的细节。添加细节基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。中等程度细节：image to bump map，修复遮挡细节，基于软对称的模型完善。LFW验证 PPT用：目的：现有单图三维重建局限性很高，必须在正前方、距离近、无阻挡的视点，该文设计了一种用于在极端条件下提供细节丰富的面部三维重建模型的系统。极端条件包括，头部旋转以及遮挡方法：简单讲步骤，关键的创新点，值得学习的点后边会细说。总的来说：先创建面部整体的基础形状，与局部细节分开，在基础形状之上建立中等程度的面部特征。这样做可以保证极端条件下整体面部形状的稳定性。其他较新的方法往往用局部细节构建整体形状。 构建基础形状s，构建面部表情e，构建视点v：凹凸图可以分离整体形状和局部细节这仨东西分别是干什么用的：基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。image to bump map转换凹凸图训练集：用深度编码-解码框架生成凹凸图学习建立凹凸图：定义了自己的网络损失函数，可以在不牺牲高频细节的情况下抑制噪声还原遮挡细节给予范例的空洞填充方法搜索参考集混合细节更复杂的修补基于软对称的模型补全 贡献：解决对foundation的高度正则化 VS 对detail的低正则化 两者的矛盾 注： bump map使用灰度值来提供高度信息，normal map使用xyz轴所对应的rgb信息 卷积与反卷积 跑demo流程： NVIDIA-docker启动container，如果跑代码没有driver重新run一个，用readme里的run命令。 之后会出现860m只支持cuda5.0的报错，需要从源码编译pytorch。首先docker里装anaconda wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2018.12-Linux-x86_64.sh 应该不用在docker里装cuda和cudnn，直接安装pytorch的依赖然后安装pytorch应该就可以 在1080上不会出现上边的报错，完全按照README走就行。 PPT Learning to Estimate 3D Human Pose and Shape from a Single Color Image(讲) DOI:10.1109/CVPR.2018.00055SCAPE: shape completion and animationof peopleSMPL: A skinned multi-person linear modelSMPL是一种参数化人体模型，与非参数化模型的区别在于，参数化的可以用函数映射的方式表达出来，或者说是可以解析的？非参数化则认为是通过实验记录到的模型，不存在解析表达式。 Stacked Hourglass Networks资料一资料二 feature mapchannel:卷积核个数、特征图个数、通道个数关系 PPT O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis还有adaptive o-cnnThe main technical challenge of the O-CNN is to parallelize the O-CNN computations defined on the sparse octants so that they can be efficiently executed on the GPUWe train this O-CNN model with 3D shape datasets and refine the O-CNN models with different back-ends for three shape analysis tasks, including object classification, shape retrieval, and shape segmentation. Pixel2Mesh（讲）code编译tensorflow math_functions.hpp找不到。需要软链接这个玩意ln -s /usr/local/cuda/include/crt/math_functions.hpp /usr/local/cuda/include/math_functions.hpp 关于eigen和cuda资料makefile怎么写。hdf5 HDF（Hierarchical Data Format）是一种设计用于存储和组织大量数据的文件格式 CUDACC_VER is no longer supported.的报错看来要更新eigen3才能解决github上新版eigen考到anaconda的eigen和support里就可以成功编译cuda了 图卷积神经网络资料图卷积神经网络材料所有的卷积都是在探讨如何对局部数据按照某一个操作聚合，不同的操作方式就对应于不同的卷积。学习卷积核的过程其实是学习局部聚合参数的过程 PPT SMPL: A Skinned Multi-Person Linear Model(多篇基础，15年)Video Based Reconstruction of 3D People Models(讲，没用网络) DOI:10.1109/CVPR.2018.00875 (video2mesh)第五页第一张图解决了人体非刚性的问题但是问题在于人必须转身后摆出相同的姿势 不允许姿势变化第二张图 可以随意动 不同时刻的深度图非张性的注册并融合到一个template上存在 phantom surface的问题 运动的快会四肢胳膊 两个头第三个 加了一个static的人体模型作为约束 运动速度可以更快 第一个使用rgb相机 并且支持用户运动的重建方法主要思想 和visual hull相似 不同角度拍摄剪影进行重建visual hull的基本原理 几个角度拍摄 分割出前景得到silhouette然后从相机坐标到silhouette的每一个点可以做一条射线 形成的曲面成为silhouette cone用这些cone作为约束就可以重建出三维模型 可以类比为雕刻的过程去掉cone之外的部分 最终剩下的部分就是人体的形状 标准的vh的问题是只能用于静态的物体 这篇的主要是讲怎么把vh用到动态的物体第八页 每帧姿势都不一样 要做的就是去除由于运动对cone造成的变化 称为unpose的过程用unpose的cone做三维重建 使用的人体的三维表达：smpl 参数化模型 T是template的mean shape，Bs是体型变化造成的模型变化Bp是pose的变化带来的变化问题在于没有办法model衣服头发面部特征 基础上加了D offset用于表达smpl表达不了的信息 四个步骤1 前景分割 获取silhouette cone， tracking获取人体模型的姿态2 利用pose信息做unpose操作 转到Tpose姿态下3 人体重建 包含衣服 头发 人脸的人体模型4 多视角图像生成人体贴图 1 基于cnn的方法 2d drawn detection 图像分割的方法 前景分割生成silhouette优化第12页的能量函数 进行pose tracking //简单来说就是求最优的pose和shape的参数 和模型匹配到检测到的2d drawn detection和silhouette上//2 第一步得到的cone进行unpose 每一条射线进行unpose转到canonical pose下//两个数学表达式 射线的转换//任何一点vi 和 任何一条射线ri3 利用unpose后的cone做三维重建 称为consensus shape，相比较SMPL/视频表现出的是可以对衣服进行重建过程可以通过优化一个能量公式实现Edata：模型上的点到unpose ray的距离三个正则项：lap保证局部光滑，body保证重建出的与smpl差距不大，symm保证左右对称4 有了几何信息后 生成appearance信息 生成texture map 第一步有每一帧的pose，精确的将模型覆盖到图像上通过//重投影获得贴图// 用sfs（之前的文章有提到）可以提供更多细节，本文方法可以提高的地方对能量函数的理解：构建能量函数就是我们用方程的最小值来描述我们想要达到的实际效果。资料 第一步最费时间 一帧一分钟 model和silhouette的匹配费时间穿裙子解决不了 改变不了smplmodel的拓扑结构 拉不过去基于cnn的分割已经接近于完美了 用的别人的方法 不是重点给纹理图上色：consensus shape 结合第一步的pose 精确匹配到每一帧的图像上 back projection ppt Learning to Reconstruct People in Clothing from a Single RGB Camera（2019.4video2mesh延伸论文，同一实验室）octopus安装dirt遇到的问题：https://github.com/pmh47/dirt/issues/23已经尝试过cuda10.1/10.0/9.2 cudnn都是对应版本，tensorflow单独测试成功更改gcc/g++版本：https://blog.csdn.net/u012925946/article/details/84584830 最终安装dirt解决方法是：ubuntu 18.04，cuda 8.0，cudnn 6.0，tf 1.4.0，driver 396.54注意conda install 的 cudatoolkit和cudnn不能取代本机安装的cuda和cudnn，也就是说本机要安cuda，cudnn，conda装tf时要装cudatoolkit，cudnn 先装tensorflow再装-gpu 才能启用gpu 前者版本不能比后者高，libcudnn.so.x报错需要在conda里安装tf，tf-gpu。注意版本匹配 跑Octopus的实验时需要scipy&gt;=1.0.0numpy&gt;=1.16Keras&gt;=2.2.0tensorflow_gpu&gt;=1.11.0dirt否则会报：12345678910111213141516171819202122232425262728293031323334(video2mesh) ty@ty-GE60-2PF:~/repos/octopus$ bash run_batch_demo.sh Using TensorFlow backend.2019-05-29 15:18:24.784883: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA2019-05-29 15:18:24.835566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2019-05-29 15:18:24.835835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: name: GeForce GTX 860M major: 5 minor: 0 memoryClockRate(GHz): 1.0195pciBusID: 0000:01:00.0totalMemory: 1.96GiB freeMemory: 1.08GiB2019-05-29 15:18:24.835855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)Processing sample...&gt; Optimizing for pose... 0%| | 0/10 [00:00&lt;?, ?it/s]Traceback (most recent call last): File &quot;infer_batch.py&quot;, line 87, in &lt;module&gt; main(args.weights, args.num, args.batch_file, args.opt_steps_pose, args.opt_steps_shape) File &quot;infer_batch.py&quot;, line 46, in main model.opt_pose(segmentations, joints_2d, opt_steps=opt_pose_steps) File &quot;/home/ty/repos/octopus/model/octopus.py&quot;, line 290, in opt_pose callbacks=[LambdaCallback(on_batch_end=lambda e, l: pbar.update(1))] File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/engine/training.py&quot;, line 1010, in fit self._make_train_function() File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/engine/training.py&quot;, line 509, in _make_train_function loss=self.total_loss) File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/legacy/interfaces.py&quot;, line 91, in wrapper return func(*args, **kwargs) File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/optimizers.py&quot;, line 475, in get_updates grads = self.get_gradients(loss, params) File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/optimizers.py&quot;, line 89, in get_gradients grads = K.gradients(loss, params) File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py&quot;, line 2757, in gradients return tf.gradients(loss, variables, colocate_gradients_with_ops=True) File &quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py&quot;, line 555, in gradients (op.name, op.type))LookupError: No gradient defined for operation &#x27;smpl_body25face_layer_1_7/smpl_main/Svd&#x27; (op type: Svd) 显卡驱动还崩了 用ubuntu自带的怎么切驱动nvidia-smi都会报一行错NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installedand running.然后切不懂了卡在390 有这个问题https://askubuntu.com/questions/1035409/installing-nvidia-drivers-on-18-04 2019.6.4 https://github.com/pmh47/dirt/issues/6 dirt inside cmakecache.txt add -DNDEBUG to CMAKE_CUDA_FLAGS:STRING https://github.com/pmh47/dirt/issues/23tensorflow.python.framework.errors_impl.NotFoundError: /home/ty/repos/dirt/dirt/librasterise.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs should not use conda install tensorflow &amp; tensorflow-gpu, use pip install instead nvidia driver keeps the newest one. 123456789101112(dirt) zhangtianyi@likun-ThinkStation:~/github/dirt$ python tests/square_test.py Traceback (most recent call last): File &quot;tests/square_test.py&quot;, line 4, in &lt;module&gt; import dirt File &quot;/home/zhangtianyi/github/dirt/dirt/__init__.py&quot;, line 2, in &lt;module&gt; from .rasterise_ops import rasterise, rasterise_batch, rasterise_deferred, rasterise_batch_deferred File &quot;/home/zhangtianyi/github/dirt/dirt/rasterise_ops.py&quot;, line 6, in &lt;module&gt; _rasterise_module = tf.load_op_library(_lib_path + &#x27;/librasterise.so&#x27;) File &quot;/home/zhangtianyi/anaconda3/envs/dirt/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py&quot;, line 61, in load_op_library lib_handle = py_tf.TF_LoadLibrary(library_filename)tensorflow.python.framework.errors_impl.NotFoundError: /home/zhangtianyi/github/dirt/dirt/librasterise.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs 成功安装后test时出现上边的问题 -d_glibcxx_use_cxx11_abi=0改成1 gcc/g++版本从4.9换到5重装dirt就好了 总结：py2.7 tf1.13.2 cuda 显卡驱动装新的 setup.py里的dependence去掉用conda装 cmakelists.txt cmake_flag 加-d_glibcxx_use_cxx11_abi=1 change CMakeLists.txt line5 intofind_package(OpenGL REQUIRED COMPONENTS OpenGL EGL)comment line9line53 intotarget_link_libraries(rasterise OpenGL::OpenGL OpenGL::EGL $&#123;Tensorflow_LINK_FLAGS&#125;)As a hack, you can try directly linking the correct library: remove EGL from line 5 of CMakeLists (so FindOpenGL no longer searches for it), and at line 52, replace OpenGL::EGL by /usr/lib/nvidia-384/libEGL.so.1.1.0 cmake ../csrc -D_OPENGL_LIB_PATH=/usr/lib/nvidia-390. 对应驱动版本 cmakecache.txt 加-dndebug make cd .. \\ pip install -e . tests 笔记本会卡死！！！ Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation（3DV 2018）intro已经有很多成功的工作，生成人体关键点，棒状表示模型（火柴人）（说的就是openpose）这里作者提出的是基于smpl的更具挑战性的任务：estimating the parameters of a detailed statistical human body model from a single image Traditional model-based approaches typically optimize an objective function that measures how well the model fits the image observations传统的需要一个差不多初始化模型，然后把初值优化到最终结果（不需要3d训练数据——带3d动作标注的图片）CNN就是forward prediction models，就不需要initialization，但是需要3d姿态标注，不像2d标注好获得 他们近期的工作通过把重建出的模型投影回2d空间更新损失函数，就可以使用2d标注了本文的目的：To analyze the importance of such componentscomponents: image—(CNN,3d notation trained)—&gt;smpl model(hybird params)—&gt;image—(reproject)—&gt;2d notation for CNN training要形成闭环（loop）NBF = 一个包含统计身体模型的CNN两种监督模式：full 3d sup和weak 2d sup，bottom-up top-down的方法，使得NBF既不需要初始化模型也不需要3d标注的训练数据因为光照、衣服、杂乱的背景都不想要，专注于pose和shape，所以用处理后的image代替原始rgb image结论： 12-body-part的分割就包含了足够的shape和pose信息 这种处理后图像的方法比起用原图，效果有竞争力，更简单，训练数据利用率更高 分割质量可以强有力预测fit质量 总结： unites deep learning-based with traditional model-based methods an in-depth analysis of the necessary components to achieve good performance in hybrid architectures and provide insights for its real-world applicability related workMost model-based approaches fit a model to image evidence through complex non-linear optimization, requiring careful initialization to avoid poor local minima.用2d关键点是为了降低fitting复杂度lifting to 3D from 2D information alone is an ambiguous problem 前人的工作有用rgb image的/image+2d keypoint的/2d keypoint+silhouette的NBF不需要初始化模型，用semantic segmentation做图片代理输入，原因有三： 去除与3dpose无关的图像信息 比keypoint和silhouette语义信息多 允许分析精细程度（粒度）和placement对3d预测的重要程度 三个数据集UP-3D，HumanEva-I，Human3.6M 三个数据集UP-3D,HumanEva-I,Human3.6M up-3d有大量smpl形式的3d标注 其他数据集： HumanEva-I使用方法：To be able to use HumanEva-I dataset you must do the following: Sing up and agree with the license or Login if you already have an account. Download the entire HumanEva-I dataset as either zip or tar archive depending on your system. Download critical HumanEva-I update and update the OFS files. Download the latest source code. (optional) Download background statistics (optional) Download the surface model for subject S4. 装matlab, XVID codec, DXAVI toolbox, Camera Calibration Toolbox for Matlab给matlab指定了mingw作为c++编译器 1234567Undefined function or variable &#x27;dxAviOpenMex&#x27;.Error in dxAviOpen (line 3) [hdl, t] = dxAviOpenMex(fname);Error in testDxAvi (line 4)[avi_hdl, avi_inf] = dxAviOpen([pathname, filename]); 运行mex_cmd出现 12F:\\datasets\\HumanEva-I\\Release_Code_v1_1_beta\\TOOLBOX_dxAvi\\dxAviHelper.h:9:21: fatal error: atlbase.h: No such file or directory #include &lt;atlbase.h&gt; 应该是没有这个库的原因，有说是visual studio的库，打算装个vs2019 ATL库试试matlab不支持2019 mex -setup -v可以看到指搜索到vs2017所以装了vs2015，atlbase就可以了123456Building with &#x27;Microsoft Visual C++ 2015&#x27;.Error using mexdxAviOpenMex.cppBaseClasses\\ctlutil.h(278): error C4430: missing type specifier - int assumed. Note: C++ does not support default-intg:\\grads\\3dreconstruction\\humaneva-i\\release_code_v1_1_beta\\toolbox_dxavi\\dxAviHelper.h(15): fatal error C1083: Cannot openinclude file: &#x27;qedit.h&#x27;: No such file or directory 原因在这里link github上找了win64编译好的.m脚本，解决。 todo 怎么做validation 实验复原实验 Extreme 3D Face Reconstruction: Seeing Through Occlusions Github 环境：linux docker镜像 依赖： our Bump-CNN our PyTorch CNN model the Basel Face Model 3DDFA Expression Model 3DMM_model dlib face prediction model Learning to Reconstruct People in Clothing from a Single RGB Camera Github 环境：linux tf 依赖： DIRT SMPL model pre-trained model weights 备注：图片预处理需要 PGN semantic segmentation：Linux/tensorflow Code OpenPose body_25 and face keypoint detection：Win .exe Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation Github 环境：win/linux tensorflow-gpu==1.6.0 依赖： SMPL model(跟上边的还有区别) segmentation model fitting model 备注：没training code tex2shape： hmr hmd shift-net 数据集 HumanEva-I 环境：win/linux matlab 依赖：几个toolbox其中dxavi用的github上编译好的.m UP-3D 环境： 依赖： Human3.6M 注册不通过（20190716） repos repo name description VideoPose3D 3D human pose estimation in video with temporal convolutions and semi-supervised training smplify-x Expressive Body Capture: 3D Hands, Face, and Body from a Single Image neural_body_fitting Neural Body Fitting code repository octopus Learning to Reconstruct People in Clothing from a Single RGB Camera videoavatars Video based reconstruction of 3D people models extreme_3d_faces Extreme 3D Face Reconstruction: Seeing Through Occlusions 3Dpose_ssl 3D Human Pose Machines with Self-supervised Learning pose-hg-train Training and experimentation code used for “Stacked Hourglass Networks for Human Pose Estimation” PRNet Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network (ECCV 2018) vrn Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression openpose OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation Codevscode想在不同的conda环境下都有类型提示和跳转需要在vscode里切环境ctrl+shift+P —&gt; python:select interpreter —&gt; {your env}官方文档 import tensorflow 没有报错也没有反应：tensorflow-gpu跟conda安装的opencv有冲突！！改用pip install opencv-python就解决了 同文件夹下module import要加.1234import tensorflow as tffrom .batch_smpl import SMPLfrom .joints import joints_body25, face_landmarksfrom keras.engine.topology import Layer git-lfs在fork的repo上使用会有问题 “can not upload new objects to public fork” python moduletqdm: process bar toolgreenlet/gevent: 协程工具 octopus 流程：读文件（segmentation/pose） png和json文件K.set_session启动tfsession声明model（octopus），加载weights解析segm：io.py里有解析segmentation的方法解析pose优化pose优化shape生成模型（点和面的list）写入obj（write_mesh） opt_pose:两组数据: data/supervisionopt_pose_model.fit(): opt_shape:data/supervisionopt_shape_model.fit() 想尝试把dirt换了，用别的differentiable renderer tex2shapedecectron2（pytorch环境）先做uv图tex2shape出模型，因为显存不够影响了重建效果（用video2mesh的conda环境就可以（tensorflow+keras））目前的代码是否可以训练模型，hdf5文件怎么生成（keras的hdf5文件，就是tf的ckpt，model.save就完事了，现在主要问题是fit train data） hmr End-to-end Recovery of Human Shape and Pose有train code，可他妈太妙了数据预处理步骤： 数据集lsp —&gt; tfrecord datasets LSP and LSP extended COCO we used 2014 Train. You also need toinstall the COCO API for python. MPII MPI-INF-3DHP Human3.6M Download link to MoSh 训练数据预处理TFRecord:数据序列化成二进制的工具 keraskeras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)Wraps arbitrary expression as a Layer object. keras.backend: At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend. LambdaCallback() 要解决的问题 现有数据集的数据怎么处理到能用在smpl上 ！！（解决 hmr里解决了训练数据—&gt;tfrecord的过程） 确定量化指标 ！！（解决 hmr有evaluation） 确定遮挡情况下的重建效果！！（hmr，tex2shape，octopus，360texture那个） 实验室/作者汇总 名称 文章 链接 MPI SMPL/Octopus/.. https://virtualhumans.mpi-inf.mpg.de/ UCB(Angjoo Kanazawa) 预测人体动作/动物形体重建 https://people.eecs.berkeley.edu/~kanazawa/ 周晓巍(浙大) .. http://www.cad.zju.edu.cn/home/xzhou/ 技术要点汇总 文章名称 完成任务 技术要点描述 end to end recovery of human shape and pose(HMR) an end-to-end framework for reconstructing a full 3D mesh of a human body from a single RGB image 不知道速度怎么样，其他的有做到实时的了 不计算2d/3d joint position，使用了一种高效的mesh representation parameterized by shape and joint angles hmd 分阶段deformation hmr做基础模型，找到joint，anchor关键点deformation，在产生个深度图做vertex级别的deformation deephuman 不用smpl，直接从image用cnn还原三维结构 用了带语义的三维信息semantic volume bodynet 不用smpl hmd里提到的，不用smpl，用cnn找joint找sil构建3d pose再用cnn构建volumetric shape，用smpl监督算一个3d loss。总之就是多loss联合监督回归三维体积 Deep Textured 3D Reconstruction of Human Bodies 不用smpl hmd里提到的 double fusion 用的单个深度摄像头，做到实时三维人体重建 内外两层模型，里边是smpl外层可以根据深度信息较大幅度的拟合RGB图像 hyperfusion 单个深度摄像头+IMUs 惯性测量 在处理快速动作，遮挡情况比df更好，这俩重点在于捕捉连贯动作 Learning to Reconstruct People in Clothing from a Single RGB Camera(Octopus) 视频1-8帧做人体重建，10秒完成（说是速度快，但是其他的有做到实时的了） 速度快归功于两点：Tpose下完成特征融合；using both, bottom-up and top-down streams（？？不理解回头看看） Tex2Shape: Detailed Full Human Body Geometry from a Single Image 单图重建模型，用了detectron的densepose对图像预处理出IUV图，然后根据原图+IUV图出模型 前置条件detectron/densepose/smpl Multi-Garment Net: Learning to Dress 3D People from Images Learning to Estimate 3D Human Pose and Shape from a Single Color Image 周晓巍 跟hmr差不多 hmr用了个判别器，这个用三维模型投影回二维平面做监督 Learning 3D Human Dynamics from Video single image预测人体3D past and future motion present a framework that can similarly learn a representation of 3D dynamics of humans from video via a simple but effective temporal encoding of image features Predicting 3D Human Dynamics from Video 跟上边都是UCB的Predicting Human Dynamics (PHD), a neural autoregressive model that takes a video sequence of a person as input to predict the future 3D human mesh motion LiveCap:Real-time Human Performance Capture from Monocular Video the first real-time human performance capture approach that reconstructs dense, space-time coherent deforming geometry of entire humans in general everyday clothing from just a single RGB video 应该是预处理阶段重建模型（需要花费时间），实时添加动作。重点解决两个非线性优化问题，提出两阶段（stage）解决思路 Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images “In the Wild” 不需要图像分割/关节点标注的动物模型重建 SMAL PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation 对象姿态估计旨在检测对象并估计其相对于规范框架的方向和平移 PVNet predicts unit vectors that represent directions from each pixel of the object towards the keypoints. These directions then vote for the keypoint locations based on RANSAC//vector-field presentation 实验规划 hmr：End-to-end Recovery of Human Shape and Pose octopus 有模型 有纹理贴图 用了Detailed Human Avatars from Monocular Video.的贴图方法 tex2shape 这个有衣服的细节 试试有遮挡的情况下重建效果怎么样 Learning 3D Human Dynamics from Video Multi-Garment Net: Learning to Dress 3D People from Images pvnet 遮挡截断情况下可以做6DoF Pose Estimation 周计划2019.10.21 现有数据集的数据怎么处理到能用在smpl上 ！！（hmr有dataset—&gt;tfrecord的code） 确定量化指标 ！！ （hmr：跟3d groundtruth 点对点算距离，数据集human3.6m — 这东西不知道啥时候能下载） 2019.10.28 处理输入图片准备test（图片加遮挡，截断，运动模糊） hmr、octopus、tex2shape 进行test test结果进行量化评估 2019.11.4 复原结果汇总 贴图怎么上 量化指标 2019.11.11 训练code跑起来 量化指标 日报2019.10.28hmr，tex2shape环境部署todo：处理输入图像，查看结果 2019.10.29hmr结果已出，tex2shape需要densepose预处理图片，需要看看densepose对于遮挡，截断，运动模糊的处理情况todo densepose结果查看 2019.10.30detectron2可以用了，但是2提供的densepose的visualization mode不全，没有IUV，导致作为tex2shape的输入会有问题。还需要继续想办法todo：hmr基本上没有细节，只有pose和大致shape，接下来要主要关注tex2shape在有遮挡的情况下细节重建的效果找两个带贴图repo试试，octopus/garment/360evaluation没有human3.6做不了，那边注册不通过没法下载 2019.10.31摸鱼 2019.11.1detectron2里的densepose没法出IUV的图，不太明白IUV这个图怎么用opencv出。只能在densepose结果图上做遮挡看看tex2shape的重建效果了完成hmr/tex2shape的遮挡测试，todo：octopus/还有smpl加贴图 2019.11.2/3休 2019.11.4dirt 有个undefined symbol 大概率是跟显卡驱动 cuda版本有关系 因为笔记本上就装上了dirt装不上garment也没法跑，得想办法用opendr代替dirtdirt装上后有个segmentfault 明天继续看整理tex2shape/hmr/octopus的结果明天看看贴图怎么搞，octopus用了个方法，还有garment那个的 2019.11.5octopus keras.base_layer会报个参数错误densepose(tex2shape)不知道怎么出IUVgarment(上贴图的)用了MPI-IS的mesh组件 需要python3TODO: humaneva, garment, Semantic Human Texture Stitching 2019.11.6量化指标：the mean per-pixel error of 3d displacements maps中文叫位移贴图/与凹凸贴图（法线贴图属于凹凸图），高度图不同贴图挺顺利的，理论上所有smpl的模型都适用。贴图这边接下来要看怎么用自己的数据（从img—&gt;pkl—&gt;texture）octopus还是不行 操他妈的(keras outputs不是layer类型的，不知道为什么)（11.6更新：因为当时smpl()改成了smpl.call()，还是要走基类的call()的不然不是Layer类型）Lambda表达式是核心问题 明天看 2019.11.7Octopus解决了，Lambda表达式没问题，smpl那个继承了Layer的类在调用call()时调用了call()，后者参数数量与基类Layer的call()参数数量不一致，导致了问题hmr的训练需要groundtruth 3d，先放着吧看effective C++(4/5) 2019.11.8数据集MPI_inf_3dhp/MPII/COCO 下载下载数据集coco/mpii/mpi_inf_3dhp学习dx12 2019.11.9/10休 2019.11.11coco/lsp/lsp_ext/mocap_neutrMosh/mpii/mpi_inf_3dhp —&gt; tfrecordhmr train code在tf1.14上有问题 降到1.4试试（conda最低1.4） hmr官方用的1.3//客制的有pytorch0.4的trainer.py的train()有问题 —&gt; sess.run时间太长了 1.4得调cuda版本 还是用1.14 2019.11.12三个新论文 看起来实验会好做一些 train code/dataset都有： PyTorch implementation of CloudWalk’s recent work DenseBody https://arxiv.org/pdf/1903.10153.pdf github Repository for the paper “Convolutional Mesh Regression for Single-Image Human Shape Reconstruction” github Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation (CVPR2019 Oral) github 2019.11.13看看十大排序七大查找算法（3-0）hmd demo没啥问题 看看train 需要upi的数据集44g 这周五再下evl的用了wild dataset 1.9g//RECON and SYN test 2019.11.14排序/查找算法 2019.11.15upi_s1h//human36m_washed//two test dataset for hmd(eval recon and syn sets//wild set) 2019.11.16/17休 2019.11.18train without coco &amp; human3.6m coco需要联网用json下文件，实验室电脑没有那么多网关流量，human3.6m没数据集train joint的时候dataloader的num有点问题 改成8035试试（worked）donetrain anchor doneeval test doing跑实验的同时看一下红黑树/B树/B+树 2019.11.19eval完成看hmd论文 Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation 2019.11.20tex2shape的模型是有uv的 octopus/hmd都没有uv 所以没法贴图加贴图那个基于octopus，需要绕着人转圈拍照片，然后做分割eval_wild on self trained model（10hrs）明天看看遮挡情况下hmd的重建效果 2019.11.21shell脚本里使用conda命令需要在conda activate前加上source ~/anaconda3/etc/profile.d/conda.sh遮挡情况下的hmd效果实验eval_wild on self trained model（10hrs）（昨天优点问题 再来一遍） 2019.11.22确定目标 基于hmr和hmd做遮挡部分的重建看hmd论文，研究hmd怎么加纹理细节的 2019.11.23/24休 2019.11.25shadingnet: hmr 3d mesh —1-&gt; depth map —2-&gt; detailed depth map —3-&gt; detailed 3d meshhmd里是先shadingnet根据rgb image预测一个depthmap 然后加上mesh(openmesh + hmr smpl) 投影出的depthmapUnet 输入rbg groundtruth depthmap 结果泛化能力差 所以再来个shadingnet loss是前边unet的depthmap loss 还有depth map重建成rbg 跟input的loss需要解决的问题就是设计网络做第二步（doing sfsnet/3dmm/..）先可视化一下depthmap（done） joint和anchor都独立与shading的，在有rgb出了joint/anchor的前提下 rgb做修复 然后经过shading net(pretrained) 加到project depth map上看结果 不处理的rgb 经过shading net(pretrained)生成depth map 然后在dm上做修复 最后加到project depth map上生成最终dm 建立端到端网络直接从未处理的rgb—&gt;修复完成的depth map，最后加上project depth map hmd的数据集刨除h36m应该有18000+ train set，现在只有9000+ 重新用脚本处理一遍 numpy 高级索引 ndarray[x,y]//ndarray[a==b] 2019.11.26机器在处理数据（就是做hmd 里的 wild set）（coco做了7000+然后断开socket链接了，回头继续转）问题转化为：有遮挡的rgb图生成完整的深度图的问题DDRNet做的深度图重建。试试Deeper Depth Prediction with Fully Convolutional Residual Networks (FCRN)还有ddrnet 王琛的方法，需要提供人体/遮挡的数据集（考虑下怎么做这个数据集），网络是现成的三维人体重建转化到深度图的inpainting这样可以吗？？ 更新ubuntu grub的引导会没 需要到win7下重设 2019.11.27coco数据集的hmd预处理还是有socket error，今晚挂上代理再试一次问题：有遮挡的情况下恢复深度图的detail，还是考虑深度图质量差不多的情况下，深度图生成三维模型的精度见今日周报 基本确定12月的工作内容 2019.11.28固定像素位置加遮罩很容易（已完成），考虑往人体固定位置上加？人体的数据集就18000+ 顶多了 看别人做inpainting的得有4/5w监督数据怎么来？1. 通过hmd shading net出深度图；2. 找别的深度估计方法 2019.11.29先用shadingnet的结果做gt吧，开始处理数据集 2019.11.30/1effective c++休 2019.12.2生成depth ground truth 流程如下img—&gt;hmr result（predict_hmr_dm 批处理hmd_2 18403张train img）—&gt;depth result（predict_hmd_dm 生成depth 到hmd_masked/train）做depthmap的gt要150hrs。。？ 感觉没人做带遮挡的rgb到depth的映射(也就是inpainting和depth estimation的混合)现有的depth estimation方法 pretrained的model对人体的效果极差 根本比不了hmd的shadingnet结果 见周报图incomplete RGB —&gt; complete depth 做不动incomplete RGB —&gt; incomplete depth —&gt; complete depth想出incomplete depth还得150hrs最后可能只能在深度图上做inpainting 2019.12.3写周报leetcode 2019.12.4人体的rgb inpainting目前都没有人做的好，主要是会拿背景的信息填充到人体遮挡区域考虑使用sil，把人体抠出来，看看能不能训练一个针对人体的inpainting网络，再出深度图看效果注：rgb重建的效果也不会特别好，举个例子，拿衣服去补人脸的位置，肯定效果不对。但是，转成深度图再到三维模型上，效果不一定会特别差，待试想想怎么给inpainting的输入加入人体轮廓信息这个约束rbg修复好了 —&gt; 深度图效果好 —&gt; 模型效果好 王琛表示深度图做修复能做，接下来准备等深度图数据集处理完成，进inpainting网络，训练修复深度图的网络模型。 2019.12.5玩kbengine，部署linux游戏服务器，打包安卓客户端，双端联机测试深度图要等到周日晚上，给王琛做 2019.12.6/7/8休 2019.12.9train depth inpainting modelshift-net_pytorch 深度图做出npy和png了，shift-net的图片都是256256，我这是448448，需要调整下网络 2019.12.10开始训练针对深度图的shift-net，30hrs(30 epoch) 明天放到hmd里看效果这次训练用的center mask(25%左右的遮挡率) 有些把人遮住太多了 下次试试随机的或者范围小一点的玩kbengine 2019.12.11贵州电网的一个UI材质工具train好的modeltest需要测试集的depth map，2000多张得搞一下hmd的shading-net没有train code，也就是说rgb到depth这段没有源码，shift-net做inpainting已经很好了，如果有shading-net的train code，合起来或许能做 incomplete rgb —&gt; complete depthNYU的数据集看了精度肯定不够 2019.12.12出inpainting好的深度图重建出的三维模型，这个算是完成目标了，但是是分两阶段完成（不完整rgb—&gt;不完整depth—&gt;完整depth）接下来看shadingnet怎么train的，得能跑通 3d mesh —&gt; 图像空间 初步深度信息 —》 shadingnet 增强深度信息—》mesh到depth的原理 还有 ddrnet的那个loss 开题报告 2019.12.13/14/15开题报告 2019.12.16hmd: 训练策略（train scheme）是仿照的sfsnet 先用了一个Unet，train时候输入是RGB + hmr投影出来的depth，监督数据是Kinect扫的depth（这个Unet train的时候只用到了少量数据集，然后用训练好的模型生成大量的depth，此时depth效果不好） 然后是shadingnet，train的输入是hmr投影出来的depth和原始RGB，一个loss是用unet的输出监督，一个loss是photometric reconstruction loss（问题是这个reconstruct 重建了什么 就能知道重建的这个玩意儿跟什么做比较成为损失函数） 重点看ddrnet怎么优化depth的，原理是什么 阶段性总结 明确人体细节是由深度图产生的，三维重建问题转化到深度图修复问题上 做出了深度图数据集 18000+3000 shift-net针对深度图训练了一个模型，可以用于深度图恢复 tex2shape/octupus/hmr/hmd 基本可以跑对比实验了 接下来的工作是做shadingnet的train对比joint和anchor的train codeshadingnet的dataloader返回的是(src_img, depth_diff, mask)为什么要返回diff??? gt和smooth depth的差 2019.12.17自己做了shadingnet的train code，网络结构Unet（hmd给的），损失函数就用MSE，输入完整rgb还有mask，监督数据depth_gt，learning rate降到0.00001搞搞看能不能rgb到depth 30分钟迭代900多次就训练完了 结束条件是什么不知道 测试中测试结果不好 自己train出来的结果有明显颗粒感 深度数值范围0-1之间，pretrain的+-25之间 明天看 2019.12.18改开题报告 整点ddrnet的公式进去shading net 用MSE train 完全不收敛啊 shadingnet dataloader ： mask就是coarse depth？！ 剪影代替的coarse depth？？ wtf 2019.12.19两个问题：背景是黄的 是因为背景到人体的过度不自然，pre的是背景是0 人体上是0左右 正负50都有细节是有的 但是我的像素不连续 有细节但是数值跟pre对应不上 颜色深浅换个loss看看结果变不变 完全不变 调参也不变。。 2019.12.20不清楚网格的问题是不是通过调参就能解决的，或者换loss，还是不知道depth_diff干嘛用的只能换loss了 自定义loss试试 2019.12.21原因是输入图像和gt图像没有匹配，低级错误下一步进一步调参降低loss 2019.12.22 eval pretrained model和我自己的model shift-net改下输出看结果 G &amp; D：G把输出的channel改成1，loss得跟depth比；让D区分gtdepth和preddepth backward_G and backward_D real_A real_B为什么有两个real？ dataloader在aligned_dataset.py里 real_A == real_B//real_A—&gt;fake_B fake_B—netD—&gt;pred_fake//real_B—netD—&gt;pred_real set_gt_latent干什么用的 下周开始做改进改进版shift-net的实验月底开始写论文 2019.12.23改shift-net： Gnet输入RGB，自己加遮罩，生成fake_rgb，用原始RGB监督；Dnet输入RGB和fake_rgb，输出两个判断结果的计算loss G输入3通道输出1通道，D出入1通道输出二分类，netD和vgg16featureextractor（util）问题： 方框可能太大；把RGB的人挖出来比较好背景干扰太多还是应该输出numpy数组，监督数据如果用png出来的是三通道的rgb图，得改可视化的代码，用plt通过numpy数组生成训练过程中图像 2019.12.24方框缩小，单通道输出，trainning，ETA 25号中午 2019.12.25test 2019.12.26spectral_norm gan用的东西现在要解决的问题：重建深度图不光滑，有明显的网格，重复结构，不知道为什么G就是个encoder decoder 为什么会有网格试试用sil不用深度图的a[b==0] = 0 不行 sil只有8035个把unet最后一层的tanh激活函数删了结果看起来好点了 迭代30次看看效果7次 看起来还原出来的部分并没有什么细节 2019.12.27shift-net几个损失函数得调整，D一直为0了 content过于大D的输入已经是抠出来的了，opt.overlap是什么 2019.12.28/29休回放系统、撤销操作 2019.12.30开会，确定一月时间安排开始论文初稿，学习latex，写公式最麻烦，网络结构图，柱状图，折线图 怎么能让遮挡区域的数值乘个系数？？ 2019.12.31abstract完成 2019.1.1开题ppt完成 2019.1.2latex画Unet 2019.1.3朱青审开题报告，ppt修改 2019.1.4/5休 2019.1.6introductionrelated workmethod 2019.1.7resultconclusion 论文结构 abstract introduction三维人体重建：分两种基于参数化模型的和非的/还是特征匹配的和模板适应的目前方法的局限性，我的方法综述，贡献点总结 related work 参数化的 scape 人工标记关键点* 卷积标记关键点 smpl 非参数化的 methods SMPL，anchor/joint deformation，vertex deformation（our dataset, our net, loss） Loss：G_GAN,G_L1,D,style(MSE vgg),content results &amp; comparison介绍evaluation用的数据集，评价方法，评价/对比结果hmr/hmd/tex2shape/octopus原图inpainting/深度图inpainting/遮挡rgb生成完整的深度图测试150加遮罩—&gt;(只能不带遮罩的进？？为什么)进shiftnet出深度图—&gt;hmd_s使用深度图信息而非shadingnet信息—&gt;结果 conclusion 2020.1.13dhdnet在跑recon测试集的时候方框处理的非常不好现在猜测是因为训练的用深度图gt当作的sil，在A[B==0]=0这步的时候很可能把纹理信息填回方框区域内了。。现在但是理论上shiftnet自己还会加遮罩目前recon测试集上只能用不加遮挡的img做输入效果还可以矛盾点在于 shiftnet是在线加的遮罩啊 为什么输入图像加不加遮罩还会造成影响？？？？ 2020.1.14recon只看joint 还是得看syn输入图像家的遮罩试着比 shiftnet动态加的小一点 84 84 140 140—&gt;87 87 137 137 2020.1.15leetcodeblog 加入vuejs静态页面Mirror 多人游戏demo / kbe C++ 服务端 2020.3.8Attention机制zhihu论文搜索：Self-Attention Generative Adversarial Networks (SAGAN)codeA PyTorch reimplementation for paper Generative Image Inpainting with Contextual Attention paper code 2020.3.9Learning 3D Human Shape and Pose from Dense Body Parts 2020.5.30Losses：下降较明显的有G_L1，content；G_GAN略上升，D下降不明显loss计算公式：$lossD = (lossDfake + lossDreal) 0.5$ (vanilla)fake/real 是BCELoss二分类交叉熵损失函数$loss G = loss G L1 + loss G L1 m + loss G GAN + style loss + content loss + tv loss$loss G L1 是 $L1 loss opt.lambda_A$L1_m 是一个spatical discounting l1 loss（别的论文里提出来的）loss G GAN 是BCELossstyle和content都是MSELosstv是自定义一个损失函数 目前已有的： rgb特征提取—&gt;分三阶段形变smpl模型 depth map到人体表面细节，形变方法（hmd提供） 不完整rgb向完整depth map的转换网络模型 不完整rgb到完整人体模型的端到端系统 合成人体深度信息数据集 后续研究方向（大论文第二章，改进算法）： center mask的大小对重建质量的影响（最大多大就handle不住了） 不规则mask（shiftnet做了，这个好实现） attention机制对于结果的提升有多少（没概念） 目前来看多loss共同作用，有些loss并没有明显收敛（是否等于没作用、贡献）—灼烧实验 depth信息到三维点坐标的形变（deform）关系还能改进（比如深度或者说形变的scale，还有方向，目前是垂直于视平面，可以是垂直于粗模型表面？） structure from motion方向研究（全新方向，建筑行业在用） 加壳，做成用户友好的应用程序 2020.6.2ICIP论文中的四个示例在recon_set中，编号为1，3，95，116 2020.7.8专利： 技术背景 应用与不足 现有技术分析 综上 发明内容 2020.7.13ICIP pptmesh deformation with Laplacian coordinates：一种智能化的方法，能够让用户只需设置个别离散点的新位置来表达他所想要的形变，就能自动根据所需保持的形体信息来计算出剩余离散点应有的位置 2020.10.27L_{joint/anchor} = \\parallel p - \\hat{p} \\parallel_{2}2020.11.19PIFuHD的重建效果比hmd好多了，处理遮挡不好 2020.11.20开始研究star的用法，先看smpl-x是怎么使用smpl模型的 hmd中的laplacian形变code来自duke university, course link球谐函数是自己写的tqlrenderer是hmr的 得搞清楚smpl verts faces的维度和个数 2020.11.27texture： Semantic Human Texture Stitching: octupus//// opendr only workable on linux tex2shape: 有uv，unity里可以贴图 pix2suf: 用衣服的2d图片，映射到衣服模型上，是分开的上衣和裤子（短裤）模型，不是smpl人体模型上 geometry：自监督 2020.12.3标准SMPL模型提供了带uv信息的obj文件，可以使用stitching的纹理贴图实验思路： 单帧：包含遮挡和不包含遮挡和经过shift-net图像修复的受遮挡，用tex2shape的理论 多帧：stitching原本，遮挡物随机放置，用stitching的理论 2020.12.4大论文参考论文，hmr，hmd，shift-net，ddrnet，tex2shape，stitching理论知识点，smpl模型，GAN，Unet，Shift layer，拉普拉斯形变Laplacian mesh deformation，球谐函数gi 2020.11.3SIFT：尺度不变特征变换，采用高斯核函数进行滤波，寻找不同的尺度空间 可以解决occlusion和clutter？ LoG(Laplacion of Gaussian)算子： 高斯差分函数（Difference of Gaussian ，简称DOG算子）：KNN：K最近邻，k-nearest neighboraggregator：updater：multi-layer perceptron（MLP） in updater：也就是Full-connection Neural Network self- attention mechanism： attention机制：soft-attention、attention、self-attention，就是source=target，寻找输入语句中单词间的联系node-based clustering：聚类算法 有K-means，和knn有区别但是很像，前者是每次迭代调整聚类中心PointCN：epipolar distance:Structure-from-Motion system:shape-from- silhouette technique：搞出来的初始几何体都不完全并且有噪点human parsing method： 2020.11.10LBS：smpl基于全身的linear blend skinning (LBS)cocoapi报no module pycocotools._mask需要install pycocotools，在git repo pythonapi目录下执行makefile（注意看makefile的内容） 2021.4.7tf.variable_scope() reuse: Link 2021.4.12 数据集规模上要强调自监督在同等数据规模下没有dhd好，然后转到增加数据集规模 4.3节强调采用dhd+自监督的原因是：自监督提供高频细节，dhd提供低频褶皱 强调是框架结果的提升，而不是自监督方法与dhd方法间的比较 dhd的输入是rgb+mask，hmd里shadingnet是rgb+depth，盲审版本第三章的流程图写的是rgb+sil.. 自监督训练数据自己拍的48000帧，网络视频3000组，大概等于12000帧 2021.5.24盲审三个良好，申优答辩很简单，明天交终版论文 终。 conda env pytorch：Python 3.7 + pytorch 1.3 detectron2/densepose/shift-net_pytorch tf2: python2 + tf1.14 hmr, tex2shape, Semantic Human Texture Stitching tf: python3 + tf1.14 + pytorch human_dynamics, neuralgym/generative_inpainting dirt：py2.7 + tf1.13 + dirt octopus, garment hmd(可以跟tf2合并)：py2.7 + pytorch1.0.1 hmd 实验结果 三通道rgb原图到三通道depth.convert(‘RGB’)效果不好，中心预测的不好，四周也没有跟gt完全一致。 缩小遮挡范围1/2改为1/4的宽高 输入三通道rgb 输出单通道npy数组 改下可视化的代码使正常显示 human_depth: 输入三通道depth_png，输出三通道修复完成后的depth_png，这是下边实验的目标效果 rgb2depth_npy_2: 初试版本，1/4边长遮挡，王瑾周报 rgb2depth_npy_3: G去tanh()版本，网格纹理问题解决 rgb2depth_npy_4: 修改D输入图像范围，仅输入被遮挡区域 数学理论相关压缩感知中的欠定方程（undetermined equations）： 目标（朱邮件内容）研究方向：非理想条件下的单目RGB相机三维人体重建 领域现状：目前基于相机阵列以及单目RGBD相机的三维人体重建技术已经较为成熟，仅依靠单目RGB相机的三维人体重建工作具有广阔的发展前景并且具有挑战性。以MPI、UCB、浙大为首的一些实验室已经在该研究方向上已经取得了一些成果，但是输入图像质量都比较理想，非理想条件下的重建效果并不明确。 我的工作：目前确定做非理想条件下的单目相机三维人体重建，提高重建精度包括模型细节、姿态、纹理贴图。非理想条件具体来说有以下情况： 图像中人物受到遮挡（重点） 图像中人物因高速移动产生的运动模糊 图像中人物因环境光照产生的视觉偏差 工作计划：看现有方法在上述非理想条件下的重建效果（文章中没有提到的需要亲自跑实验验证）；设计改善方法，反复实验验证，得到实验数据；论文撰写。 思路 单图多人（人群）三维重建可能需要解决的问题：遮挡（周晓巍的PVNet解决了遮挡的问题，空间维度上的估计）分割大小/相对位置… 跟游戏开发能关联的地方：用引擎看效果实用性 从视频序列中选出作用显著的帧，设计量化评价方法 从不同表达，面点云体素区别入手 增加脸部细节（手部、脚步，观察几个论文的演示视频好像都没有动作细节，骨骼的问题应该是）呢？？结合3dmm（已经有结合的了19.10.10更新） 考虑多模态，加入语义信息辅助重建（还得看nlp的东西，把特征映射到一个空间不知道能不能做） 快速移动/运动模糊的视频/照片做重建（回到图像处理的问题上，不确定目前已有的方法在视频中任务快速移动情况下的重建效果） UCB预测人体动作（时间维度上的估计） 能怎么改进 MPI做的实时 UCB把SMPL用到了动物（斑马）模型重建；不是smpl是smal 光照条件对重建质量的影响 UCB做了动物的模型重建，根据视频预测人体接下来的动作；MPI实时Video to Mesh shape：更有细节/遮挡、截断(空间维度预测)/pose：根据视频、单图预测pose（时间维度预测）/实时更新posetexture：单视角贴图/多视角贴图 疑问6D pose estimation 和 smpl/smal重建出的pose有何异同？？是一个东西吗In contrast to coordinate orheatmap based representations, learning such a representa-tion enforces the network to focus on local features of ob-jects and spatial relations between object parts. As a result,the location of an invisible part can be inferred from the vis-ible parts. In addition, this vector-field representation is ableto represent object keypoints that are even outside the inputimage. All these advantages make it an ideal representationfor occluded or truncated objects. 大论文大论文结构 摘要 三维人体重建是什么 挑战 现有方法的局限性 本文的两个贡献点 绪论 研究背景与意义 三维重建是什么 主要挑战 传统的三维重建方法 传统方法存在的问题 深度学习与GAN 基于GAN的端到端系统 本研究的方法意义 国内外研究现状* 本文主要研究内容+重点 本文结构及安排 第四章 单视图三维人体纹理贴图重建算法 detectron的人体分割和UV映射算法* 基于图像修复的UV纹理映射 输入单张人体RGB—&gt;IUV—&gt;normal texture—&gt;贴图的三维人体模型 实验结果分析停滞在detectron2生成的IUV跟tex2shape中的IUV不一样，感觉就是多个了背景，不知道怎么去困难在于还要训练densepose以应对遮挡，这块监督数据不知道怎么办，训练策略不知道怎么改 第四章 自监督人体深度估计算法研究 总结 定义 应用 思路参数化人体模型—scape和smpl，将形体姿态转换为参数向量，方便神经网络进行学习问题在于精度不够，没有细节，所以自由网格形变，非刚性的三维形变方法对模型进行优化 时间安排 VCIP 5月ACM Multimedia 3月ICIP 1月31日 1月15日初稿和evaluation 1月开始写论文12月实验，开题开始编写代码，训练模型，评估实验数据11月实验设计优化思路，实验步骤，预期的实验结果 11.18-11.29 两周现有方法在非理想情况下的表现 10.21-11.15 四周10月底规划好实验步骤，预计出的结果10月18号确定要做的目标 信息总结fusionmulity domin多元融合 显著性摘要帧对重建质量的贡献 王少帆 北工大计算机学院dblp todo list数据清洗 三个数据集UP-3D，HumanEva-I，Human3.6M清洗的目的？目标？要做成什么样？","raw":"---\ntitle: 关于三维重建的文献综述\ndate: 2019-01-04 07:58:17\ntags: \n    - 3D model reconstruction\n    - 文献综述\ncategories: 论文综述\n---\n\n# 目录\n\n[arXiv检索](https://arxiv.org/)\n\n1. 1812.10558 通过视频素材实现从2d到3d的面部重建来完成测谎\n2. 1812.01742 单一视角的三维重建，使用对抗训练（非人\n3. 1812.05583 基于学习的ICP（迭代最近点算法）重构场景（非人\n4. 1812.07603 通过视频素材的面部模型学习\n5. 1812.05806 自我监督的引导方法，单图片的三维人脸重建\n6. 1812.02822 学习生成模型的隐藏区域（非人\n7. 1901.00049 基于轮廓的衣着人物（全身\n\n**A类**\n\n* 通过直接体积cnn回归从单图重建大范围三维人脸（源码lua+py\n* 使用图到图转换的无限制面部重建（源码lua\n\n**老师推荐**\n\n* 使用affinity field的实时多人二维姿态估计\n\n# 综述\n\n## 通用\n\n**关于三维重建**  \n单个图像进行三维重建的数据驱动方法：一是明确使用三维结构，二是使用其他信息推断三维结构  \n2DImage-->encoder-->latent representation-->decoder-->3DObject  \n不同方法区别在于对三维世界采取的**限制**：多视图一致性学习三维表示、利用关键点和轮廓注释、利用2.5D草图（法线，深度和轮廓）改善预测  \n\nencoder-decoder的[含义](https://blog.csdn.net/chinabing/article/details/78763454)\n\n**关于shape priors**\n许多方法选择更好的捕捉多样的真实形状  \n**non-deep方法**关注低维参数模型，使用CNN来学习2D渲染图像和3D形状的**共同嵌入空间**  \n其他方法依赖**生成模型**去学习shape priors\n\n## 博客链接\n\n[3D人脸重建学习笔记CSDN](https://blog.csdn.net/yyyllla/article/details/84573393)  \n[3D重建的学习笔记简书](https://www.jianshu.com/p/f33b3d440f7d)\n\n## Learning Single-View 3D Reconstruction with Adversarial Training 1812.01742  \n\n传统方法用多个角度的多张照片实现三维建模  \n问题两个：一是需要大量的观察点；二是物体表面是*Lambertian*（非反射）albedos是非均匀的  \n另一种三维重建的方式是利用物体外观和形状的知识从单视图二维图像生成（假设shape priors足够丰富）  \nCAD库（computer-aided design）：<u>shapenet，pascal3d+，objectnet3d，pix3d</u>  \n\n这些方法都从渲染的图像中回归三维形状：将二位图像转化成潜在表示的**编码器** 以及 重建三维表示的**解码器**  \n为了学习shape priors深度学习算法需要大量的三维对象注释，自然图像中获取三维注释很有挑战，因此使用合成图像（三维模型渲染出的图像）  \nCNN的<u>domain shift</u>问题，导致基于cnn的三维重建性能恶化  \n\n这篇文章的方法：提高重建模型性能，为了实现获取三维物体标签，他们shape priors训练出的网络有个**重建损失值**，给这个值引入了两个限制  \n一是受domain shift文献启示，强制让编码的二维特征不变，对应于他们所来自的domain。这样合成图像训练出的编码器在真实图像上表现更好  \n二是将编码的二维特征限制在现实物体的多种形状之中，通过对抗训练定义这两个损失值  \n总结：一个**模型**和**损失函数**，利用shape priors提高自然图像三维重建性能（两种方式使用对抗训练）  \nreconstruction adversarial network(RAN)  \n**只使用rgb图像信息**，和易于获取的自然图像。独立于编码器和解码器，并且可以使用到其中  \n借鉴了domain confusion（作用是classification），为了让从合成图像里训练出来的模型在真实图像这边有更好的表现  \n\n具体方法：todo\n\n## 通过直接体积cnn回归从单图重建大范围三维人脸\n\n目前三维人脸重建的方法多假定有多张面部图片可以使用，这使得重建面临方法上的挑战：在夸张的表情、不均匀光照上建立稠密对应关系  \n这些方法需要复杂低效的管道构建模型，拟合模型。本文建议通过在由2D图像和3D面部模型或扫描组成的适当数据集上训练卷积神经网络\n（CNN）来解决这些限制\n\n## Extreme 3D Face Reconstruction: Seeing Through Occlusions 极端3D面部重建：遮挡透视（讲）\n\nbumpingmapping概念的推动下，该文提出了一种分层方法。将全局形状与其中细节进行解耦。估计粗糙的3d面部形状为基础，然后将此基础与凹凸贴图表示的细节分开。\n与本文相关的工作：\n    reconstruction by example 这类方法用三维脸部形状去调整根据输入图片估计出的模型，降低了观看条件却损失了真实度与准确性  \n    face shape from facial landmarks 这类方法稳定但是模型都差不多，没有细节，而且不清楚遮挡landmark的情况下表现会如何  \n    SfS *Shape-From-shading* 根据光反射生成细节丰富的模型，但是受环境影响严重，需要满足其对环境的特殊要求。任何遮挡物都会生成到模型中  \n    statistical representations 最著名的方法是3DMM，这篇文改进了这个方法直接根据图片强度信息用cnn回归3DMM的参数和面部细节  \n    deep face shape estimation 深度网络一是直接用深度图重建，二是estimate 3D shapes with anemphasis on unconstrained photo 观察条件高度不变但是细节模糊  \n\n**准备工作**  \n矛盾：整体形状的高度正则化vs细节的弱正则化。解决方法：bump map representations which separate global shape from local details\n    理解的正则化：使模型更有普适性，低正则化是让模型有更多细节、更有特点，反之是让模型更接近普适的规则（每个模型都有一只鼻子一张嘴两只眼睛）\n给一张图片建立以下几个部分：基础形状——S，面部表情——E，6维度的自由视点——V。接下来是bump map捕捉中级特征（皱纹等非参数的），最后完成因遮挡丢失的细节。  \n**添加细节**\n基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。  \n中等程度细节：image to bump map，修复遮挡细节，基于软对称的模型完善。  \n[LFW验证](http://vis-www.cs.umass.edu/lfw/)\n\nPPT用：\n目的：现有单图三维重建局限性很高，必须在正前方、距离近、无阻挡的视点，该文设计了一种用于在极端条件下提供细节丰富的面部三维重建模型的系统。极端条件包括，头部旋转以及遮挡\n方法：简单讲步骤，关键的创新点，值得学习的点后边会细说。\n总的来说：先创建面部整体的基础形状，与局部细节分开，在基础形状之上建立中等程度的面部特征。这样做可以保证极端条件下整体面部形状的稳定性。其他较新的方法往往用局部细节构建整体形状。\n 构建基础形状s，构建面部表情e，构建视点v：*凹凸图可以分离整体形状和局部细节*\n这仨东西分别是干什么用的：*基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。*\nimage to bump map转换\n凹凸图训练集：用深度编码-解码框架生成凹凸图\n学习建立凹凸图：定义了自己的网络损失函数，可以在不牺牲高频细节的情况下抑制噪声\n还原遮挡细节\n给予范例的空洞填充方法\n搜索参考集\n混合细节\n更复杂的修补\n基于软对称的模型补全  \n\n贡献：解决**对foundation的高度正则化** VS **对detail的低正则化** 两者的矛盾  \n\n注：  \n    bump map使用灰度值来提供高度信息，normal map使用xyz轴所对应的rgb信息\n    [卷积与反卷积](https://github.com/vdumoulin/conv_arithmetic)\n\n跑demo流程：\n    NVIDIA-docker启动container，如果跑代码没有driver重新run一个，用readme里的run命令。\n    之后会出现860m只支持cuda5.0的报错，需要[从源码编译pytorch](https://github.com/pytorch/pytorch#from-source)。首先docker里装anaconda\n        wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2018.12-Linux-x86_64.sh\n        应该不用在docker里装cuda和cudnn，直接安装pytorch的依赖然后安装pytorch应该就可以  \n        在1080上不会出现上边的报错，完全按照README走就行。\n\n[PPT](extreme_3d_face.pptx)\n\n<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/extreme_3d_face.pptx' width=800 height=600 frameborder='1'></iframe>\n\n## Learning to Estimate 3D Human Pose and Shape from a Single Color Image(讲) DOI:10.1109/CVPR.2018.00055\n\nSCAPE:  shape  completion  and  animationof people\nSMPL: A skinned multi-person linear model  \nSMPL是一种参数化人体模型，与非参数化模型的区别在于，参数化的可以用函数映射的方式表达出来，或者说是可以解析的？非参数化则认为是通过实验记录到的模型，不存在解析表达式。  \n\n\nStacked Hourglass Networks\n[资料一](https://blog.csdn.net/wangzi371312/article/details/81174452)\n[资料二](https://blog.csdn.net/shenxiaolu1984/article/details/51428392)\n\n[feature map](https://blog.csdn.net/dengheCSDN/article/details/77848246)\nchannel:\n卷积核个数、特征图个数、通道个数关系\n\n[PPT](Learning to Estimate 3D Human Pose and Shape from a Single Color Image.pptx)\n\n<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/Learning to Estimate 3D Human Pose and Shape from a Single Color Image.pptx' width=800 height=600 frameborder='1'></iframe>\n\n## O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis\n\n还有adaptive o-cnn  \nThe main technical challenge of the O-CNN is to parallelize the O-CNN computations defined on the sparse octants so that they can be efficiently executed on the GPU  \nWe train this O-CNN model with 3D shape datasets and refine the O-CNN models with different back-ends for three shape analysis tasks, including object classification, shape retrieval, and shape segmentation.\n\n## Pixel2Mesh（讲）\n\n### code\n\n编译tensorflow math_functions.hpp找不到。需要软链接这个玩意  \nln -s /usr/local/cuda/include/crt/math_functions.hpp /usr/local/cuda/include/math_functions.hpp  \n\n关于eigen和cuda[资料](https://blog.csdn.net/O1_1O/article/details/80066236)  \nmakefile怎么写。  \nhdf5 HDF（Hierarchical Data Format）是一种设计用于存储和组织大量数据的文件格式\n\n__CUDACC_VER__ is no longer supported.的报错看来要更新[eigen3](https://blog.csdn.net/luojie140/article/details/80159227)才能解决\ngithub上新版eigen考到anaconda的eigen和support里就可以成功编译cuda了\n\n图卷积神经网络[资料](http://tkipf.github.io/graph-convolutional-networks/)\n图卷积神经网络[材料](https://cloud.tencent.com/developer/news/330322)\n**所有的卷积都是在探讨如何对局部数据按照某一个操作聚合，不同的操作方式就对应于不同的卷积。**学习卷积核的过程其实是学习局部聚合参数的过程\n\n[PPT](pixel2mesh.pptx)\n<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/pixel2mesh.pptx' width=800 height=600 frameborder='1'></iframe>\n\n## SMPL: A Skinned Multi-Person Linear Model(多篇基础，15年)\n\n## Video Based Reconstruction of 3D People Models(讲，没用网络) DOI:10.1109/CVPR.2018.00875 (video2mesh)\n\n第五页第一张图解决了人体非刚性的问题  \n但是问题在于人必须转身后摆出相同的姿势 不允许姿势变化  \n第二张图 可以随意动 不同时刻的深度图非张性的注册并融合到一个template上  \n存在 phantom surface的问题 运动的快会四肢胳膊 两个头  \n第三个 加了一个static的人体模型作为约束 运动速度可以更快  \n\n第一个使用rgb相机 并且支持用户运动的重建方法  \n主要思想 和visual hull相似 不同角度拍摄剪影进行重建  \nvisual hull的基本原理 几个角度拍摄 分割出前景得到silhouette  \n然后从相机坐标到silhouette的每一个点可以做一条射线 形成的曲面成为silhouette cone  \n用这些cone作为约束就可以重建出三维模型 可以类比为雕刻的过程  \n去掉cone之外的部分 最终剩下的部分就是人体的形状  \n\n标准的vh的问题是只能用于静态的物体 这篇的主要是讲怎么把vh用到动态的物体  \n第八页 每帧姿势都不一样 要做的就是去除由于运动对cone造成的变化 称为unpose的过程  \n用unpose的cone做三维重建  \n\n使用的人体的三维表达：smpl 参数化模型 T是template的mean shape，Bs是体型变化造成的模型变化  \nBp是pose的变化带来的变化  \n问题在于没有办法model衣服头发面部特征 基础上加了D offset用于表达smpl表达不了的信息  \n  \n四个步骤  \n1 前景分割 获取silhouette cone， tracking获取人体模型的姿态  \n2 利用pose信息做unpose操作 转到Tpose姿态下  \n3 人体重建 包含衣服 头发 人脸的人体模型  \n4 多视角图像生成人体贴图  \n\n1 基于cnn的方法 2d drawn detection 图像分割的方法 前景分割生成silhouette  \n优化第12页的能量函数 进行pose tracking //简单来说就是求最优的pose和shape的参数 和模型匹配到检测到的  \n2d drawn detection和silhouette上//  \n2 第一步得到的cone进行unpose 每一条射线进行unpose转到canonical pose下  \n//两个数学表达式 射线的转换//  \n任何一点vi 和 任何一条射线ri\n3 利用unpose后的cone做三维重建 称为consensus shape，相比较SMPL/视频表现出的是可以对衣服进行重建  \n过程可以通过优化一个能量公式实现  \nEdata：模型上的点到unpose ray的距离  \n三个正则项：lap保证局部光滑，body保证重建出的与smpl差距不大，symm保证左右对称  \n4 有了几何信息后 生成appearance信息 生成texture map 第一步有每一帧的pose，精确的将模型覆盖到图像上  \n通过//重投影获得贴图//  \n\n用sfs（之前的文章有提到）可以提供更多细节，本文方法可以提高的地方\n对**能量函数**的理解：构建能量函数就是我们用方程的最小值来描述我们想要达到的实际效果。[资料](https://blog.csdn.net/a6333230/article/details/80070586)\n\n第一步最费时间 一帧一分钟 model和silhouette的匹配费时间  \n穿裙子解决不了 改变不了smplmodel的拓扑结构 拉不过去  \n基于cnn的分割已经接近于完美了 用的别人的方法 不是重点  \n给纹理图上色：consensus shape 结合第一步的pose 精确匹配到每一帧的图像上 back projection  \n\n{% pdf videobasedreconstructionof3dpeoplemodelsGAMES201850徐维鹏.pdf %}\n[ppt](videobasedreconstructionof3dpeoplemodelsGAMES201850徐维鹏.pdf)\n\n## Learning to Reconstruct People in Clothing from a Single RGB Camera（2019.4video2mesh延伸论文，同一实验室）octopus\n\n安装dirt遇到的问题：https://github.com/pmh47/dirt/issues/23\n已经尝试过cuda10.1/10.0/9.2 cudnn都是对应版本，tensorflow单独测试成功\n更改gcc/g++版本：https://blog.csdn.net/u012925946/article/details/84584830\n\n最终安装dirt解决方法是：  \nubuntu 18.04，cuda 8.0，cudnn 6.0，tf 1.4.0，driver 396.54  \n注意conda install 的 cudatoolkit和cudnn不能取代本机安装的cuda和cudnn，也就是说本机要安cuda，cudnn，conda装tf时要装cudatoolkit，cudnn  \n\n先装tensorflow再装-gpu 才能启用gpu 前者版本不能比后者高，libcudnn.so.x报错需要在conda里安装tf，tf-gpu。注意版本匹配\n\n跑Octopus的实验时需要  \nscipy>=1.0.0  \nnumpy>=1.16  \nKeras>=2.2.0  \ntensorflow_gpu>=1.11.0  \ndirt  \n否则会报：  \n``` bash\n(video2mesh) ty@ty-GE60-2PF:~/repos/octopus$ bash run_batch_demo.sh \nUsing TensorFlow backend.\n2019-05-29 15:18:24.784883: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2019-05-29 15:18:24.835566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2019-05-29 15:18:24.835835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \nname: GeForce GTX 860M major: 5 minor: 0 memoryClockRate(GHz): 1.0195\npciBusID: 0000:01:00.0\ntotalMemory: 1.96GiB freeMemory: 1.08GiB\n2019-05-29 15:18:24.835855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nProcessing sample...\n> Optimizing for pose...\n  0%|          | 0/10 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"infer_batch.py\", line 87, in <module>\n    main(args.weights, args.num, args.batch_file, args.opt_steps_pose, args.opt_steps_shape)\n  File \"infer_batch.py\", line 46, in main\n    model.opt_pose(segmentations, joints_2d, opt_steps=opt_pose_steps)\n  File \"/home/ty/repos/octopus/model/octopus.py\", line 290, in opt_pose\n    callbacks=[LambdaCallback(on_batch_end=lambda e, l: pbar.update(1))]\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/engine/training.py\", line 1010, in fit\n    self._make_train_function()\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/engine/training.py\", line 509, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/optimizers.py\", line 475, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/optimizers.py\", line 89, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2757, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 555, in gradients\n    (op.name, op.type))\nLookupError: No gradient defined for operation 'smpl_body25face_layer_1_7/smpl_main/Svd' (op type: Svd)\n```\n\n显卡驱动还崩了 用ubuntu自带的怎么切驱动nvidia-smi都会报一行错  \nNVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed \nand running.  \n然后切不懂了卡在390 有这个问题https://askubuntu.com/questions/1035409/installing-nvidia-drivers-on-18-04  \n\n\n2019.6.4 https://github.com/pmh47/dirt/issues/6 dirt inside cmakecache.txt add -DNDEBUG to CMAKE_CUDA_FLAGS:STRING\n\nhttps://github.com/pmh47/dirt/issues/23  \ntensorflow.python.framework.errors_impl.NotFoundError: /home/ty/repos/dirt/dirt/librasterise.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs\n\nshould not use conda install tensorflow & tensorflow-gpu, use pip install instead\n\nnvidia driver keeps the newest one.\n\n``` bash\n(dirt) zhangtianyi@likun-ThinkStation:~/github/dirt$ python tests/square_test.py \nTraceback (most recent call last):\n  File \"tests/square_test.py\", line 4, in <module>\n    import dirt\n  File \"/home/zhangtianyi/github/dirt/dirt/__init__.py\", line 2, in <module>\n    from .rasterise_ops import rasterise, rasterise_batch, rasterise_deferred, rasterise_batch_deferred\n  File \"/home/zhangtianyi/github/dirt/dirt/rasterise_ops.py\", line 6, in <module>\n    _rasterise_module = tf.load_op_library(_lib_path + '/librasterise.so')\n  File \"/home/zhangtianyi/anaconda3/envs/dirt/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py\", line 61, in load_op_library\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\ntensorflow.python.framework.errors_impl.NotFoundError: /home/zhangtianyi/github/dirt/dirt/librasterise.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs\n\n```\n成功安装后test时出现上边的问题 -d_glibcxx_use_cxx11_abi=0改成1 gcc/g++版本从4.9换到5重装dirt就好了\n\n总结：py2.7 tf1.13.2 cuda 显卡驱动装新的\n1. setup.py里的dependence去掉用conda装\n2. cmakelists.txt cmake_flag 加-d_glibcxx_use_cxx11_abi=1\n3. change CMakeLists.txt line5 into  \n`find_package(OpenGL REQUIRED COMPONENTS OpenGL EGL)`  \ncomment line9  \nline53 into  \n`target_link_libraries(rasterise OpenGL::OpenGL OpenGL::EGL ${Tensorflow_LINK_FLAGS})`  \nAs a hack, you can try directly linking the correct library: remove EGL from line 5 of CMakeLists (so FindOpenGL no longer searches for it), and at line 52, replace OpenGL::EGL by /usr/lib/nvidia-384/libEGL.so.1.1.0 \n4. cmake ../csrc -D_OPENGL_LIB_PATH=/usr/lib/nvidia-390. 对应驱动版本\n5. cmakecache.txt 加-dndebug\n6. make\n7. cd .. \\ pip install -e .\n8. tests\n\n\n**笔记本会卡死！！！**\n\n## Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation（3DV 2018）\n\n### intro\n\n已经有很多成功的工作，生成人体关键点，棒状表示模型（火柴人）（说的就是openpose）  \n这里作者提出的是基于smpl的更具挑战性的任务：estimating the parameters of a detailed statistical human body model from a single image  \n\nTraditional model-based approaches typically optimize an objective function that measures how well the model fits the image observations\n传统的需要一个差不多初始化模型，然后把初值优化到最终结果（不需要3d训练数据——带3d动作标注的图片）  \nCNN就是forward prediction models，就不需要initialization，但是需要3d姿态标注，不像2d标注好获得  \n\n他们近期的工作通过把重建出的模型投影回2d空间更新损失函数，就可以使用2d标注了  \n本文的**目的**：To analyze the importance of such components  \ncomponents: image--(CNN,3d notation trained)-->smpl model(hybird params)-->image--(reproject)-->2d notation for CNN training  \n要形成闭环（loop）  \nNBF = 一个包含统计身体模型的CNN  \n两种监督模式：full 3d sup和weak 2d sup，bottom-up top-down的方法，使得NBF既不需要初始化模型也不需要3d标注的训练数据  \n因为光照、衣服、杂乱的背景都不想要，专注于pose和shape，所以用处理后的image代替原始rgb image  \n结论：\n1. 12-body-part的分割就包含了足够的shape和pose信息\n2. 这种处理后图像的方法比起用原图，效果有竞争力，更简单，训练数据利用率更高\n3. 分割质量可以强有力预测fit质量\n\n总结：\n1. unites deep learning-based with traditional model-based methods\n2. an in-depth analysis of the necessary components to achieve good performance in hybrid architectures and provide insights for its real-world applicability\n\n### related work\n\nMost model-based approaches fit a model to image evidence through complex non-linear optimization, requiring careful initialization to avoid poor local minima.  \n用2d关键点是为了降低fitting复杂度  \nlifting to 3D from 2D information alone is an ambiguous problem  \n\n前人的工作有用rgb image的/image+2d keypoint的/2d keypoint+silhouette的  \nNBF不需要初始化模型，用semantic segmentation做图片代理输入，原因有三：\n1. 去除与3dpose无关的图像信息\n2. 比keypoint和silhouette语义信息多\n3. 允许分析精细程度（粒度）和placement对3d预测的重要程度\n\n三个数据集UP-3D，HumanEva-I，Human3.6M  \n{% pdf 19.6.25_weekly_report.pdf %}\n三个数据集[UP-3D](http://files.is.tuebingen.mpg.de/classner/up/),\n[HumanEva-I](http://humaneva.is.tue.mpg.de/datasets_human_1),\n[Human3.6M](http://vision.imar.ro/human3.6m/description.php)  \n\nup-3d有大量smpl形式的3d标注\n\n其他数据集：\n\n\n**HumanEva-I使用方法**：  \nTo be able to use HumanEva-I dataset you must do the following:  \n  Sing up and agree with the license or Login if you already have an account.  \n  Download the entire HumanEva-I dataset as either zip or tar archive depending on your system.   \n  Download critical HumanEva-I update and update the OFS files.   \n  Download the latest source code.    \n  (optional) Download background statistics   \n  (optional) Download the surface model for subject S4.   \n\n装matlab, XVID codec, DXAVI toolbox, Camera Calibration Toolbox for Matlab  \n给matlab指定了mingw作为c++编译器  \n\n``` bash\nUndefined function or variable 'dxAviOpenMex'.\n\nError in dxAviOpen (line 3)\n\t[hdl, t] = dxAviOpenMex(fname);\n\nError in testDxAvi (line 4)\n[avi_hdl, avi_inf] = dxAviOpen([pathname, filename]);\n```\n\n运行mex_cmd出现\n\n``` bash\nF:\\datasets\\HumanEva-I\\Release_Code_v1_1_beta\\TOOLBOX_dxAvi\\dxAviHelper.h:9:21: fatal error: atlbase.h: No such file or directory\n #include <atlbase.h>\n```\n\n应该是没有这个库的原因，有说是visual studio的库，打算装个vs2019 ATL库试试  \nmatlab不支持2019 mex -setup -v可以看到指搜索到vs2017  \n所以装了vs2015，atlbase就可以了  \n``` bash\nBuilding with 'Microsoft Visual C++ 2015'.\nError using mex\ndxAviOpenMex.cpp\nBaseClasses\\ctlutil.h(278): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int\ng:\\grads\\3dreconstruction\\humaneva-i\\release_code_v1_1_beta\\toolbox_dxavi\\dxAviHelper.h(15): fatal error C1083: Cannot open\ninclude file: 'qedit.h': No such file or directory\n```\n\n原因在这里[link](https://github.com/facebookresearch/VideoPose3D/blob/master/DATASETS.md)\n\ngithub上找了win64编译好的.m脚本，解决。 \n\n**todo** 怎么做validation  \n\n# 实验\n\n## 复原实验\n\n1. Extreme 3D Face Reconstruction: Seeing Through Occlusions [Github](https://github.com/anhttran/extreme_3d_faces)\n   1. 环境：linux docker镜像\n   2. 依赖：\n      * our Bump-CNN\n      * our PyTorch CNN model\n      * the Basel Face Model\n      * 3DDFA Expression Model\n      * 3DMM_model\n      * dlib face prediction model\n2. Learning to Reconstruct People in Clothing from a Single RGB Camera [Github](https://github.com/thmoa/octopus)\n   1. 环境：linux tf\n   2. 依赖：\n      * [DIRT](https://github.com/pmh47/dirt)\n      * [SMPL model](http://smplify.is.tue.mpg.de/)\n      * *[pre-trained model weights](https://drive.google.com/open?id=1_CwZo4i48t1TxIlIuUX3JDo6K7QdYI5r)*\n   3. 备注：图片预处理需要\n      * PGN semantic segmentation：Linux/tensorflow [Code](https://github.com/Engineering-Course/CIHP_PGN)\n      * OpenPose body_25 and face keypoint detection：Win [.exe](https://github.com/CMU-Perceptual-Computing-Lab/openpose)\n3. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation [Github](https://github.com/mohomran/neural_body_fitting)\n   1. 环境：win/linux tensorflow-gpu==1.6.0\n   2. 依赖：\n      * [SMPL model(跟上边的还有区别)](http://smpl.is.tue.mpg.de/downloads)\n      * [segmentation model](http://transfer.d2.mpi-inf.mpg.de/mohomran/nbf/refinenet_up.tgz)\n      * [fitting model](http://transfer.d2.mpi-inf.mpg.de/mohomran/nbf/demo_up.tgz)\n   3. 备注：没training code\n4. tex2shape：\n5. hmr\n6. hmd\n7. shift-net\n\n## 数据集\n\n1. HumanEva-I\n   1. 环境：win/linux matlab\n   2. 依赖：几个toolbox其中dxavi用的github上编译好的.m\n2. UP-3D\n   1. 环境：\n   2. 依赖：\n3. Human3.6M\n   1. 注册不通过（20190716）\n\n## repos\n\n| repo name           | description                                                                                               |\n| :------------------ | :-------------------------------------------------------------------------------------------------------- |\n| VideoPose3D         | 3D human pose estimation in video with temporal convolutions and semi-supervised training                 |\n| smplify-x           | Expressive Body Capture: 3D Hands, Face, and Body from a Single Image                                     |\n| neural_body_fitting | Neural Body Fitting code repository                                                                       |\n| octopus             | Learning to Reconstruct People in Clothing from a Single RGB Camera                                       |\n| videoavatars        | Video based reconstruction of 3D people models                                                            |\n| extreme_3d_faces    | Extreme 3D Face Reconstruction: Seeing Through Occlusions                                                 |\n| 3Dpose_ssl          | 3D Human Pose Machines with Self-supervised Learning                                                      |\n| pose-hg-train       | Training and experimentation code used for \"Stacked Hourglass Networks for Human Pose Estimation\"         |\n| PRNet               | Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network (ECCV 2018)         |\n| vrn                 | Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression                |\n| openpose            | OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation    |\n\n# Code\n\nvscode想在不同的conda环境下都有类型提示和跳转需要在vscode里切环境  \nctrl+shift+P --> python:select interpreter --> {your env}  \n[官方文档](https://code.visualstudio.com/docs/python/environments)  \n\nimport tensorflow 没有报错也没有反应：tensorflow-gpu跟conda安装的opencv有冲突！！  \n改用`pip install opencv-python`就解决了  \n\n同文件夹下module import要加`.`  \n``` python\nimport tensorflow as tf\nfrom .batch_smpl import SMPL\nfrom .joints import joints_body25, face_landmarks\nfrom keras.engine.topology import Layer\n```\n\ngit-lfs在fork的repo上使用会有问题 \"can not upload new objects to public fork\"\n\n## python module\n\ntqdm: process bar tool\ngreenlet/gevent: 协程工具\n\n## octopus\n\n> 流程：  \n读文件（segmentation/pose） png和json文件  \nK.set_session启动tfsession  \n声明model（octopus），加载weights  \n解析segm：io.py里有解析segmentation的方法  \n解析pose  \n优化pose  \n优化shape  \n生成模型（点和面的list）  \n写入obj（write_mesh）  \n\n> opt_pose:  \n> 两组数据: data/supervision  \n> opt_pose_model.fit():\n>   *   \n\n> opt_shape:  \n> data/supervision  \n> opt_shape_model.fit()\n\n想尝试把dirt换了，用别的differentiable renderer\n\n## tex2shape\n\ndecectron2（pytorch环境）先做uv图  \ntex2shape出模型，因为显存不够影响了重建效果（用video2mesh的conda环境就可以（tensorflow+keras））  \n目前的代码是否可以训练模型，hdf5文件怎么生成（keras的hdf5文件，就是tf的ckpt，model.save就完事了，现在主要问题是fit train data）\n\n## hmr End-to-end Recovery of Human Shape and Pose\n\n有train code，可他妈太妙了  \n数据预处理步骤：\n* 数据集lsp --> tfrecord\n* \n\n## datasets\n\n- [LSP](http://sam.johnson.io/research/lsp_dataset.zip) and [LSP extended](http://sam.johnson.io/research/lspet_dataset.zip)\n- [COCO](http://cocodataset.org/#download) we used 2014 Train. You also need to\n  install the [COCO API](https://github.com/cocodataset/cocoapi) for python.\n- [MPII](http://human-pose.mpi-inf.mpg.de/#download)\n- [MPI-INF-3DHP](http://gvv.mpi-inf.mpg.de/3dhp-dataset/)\n- [Human3.6M](http://vision.imar.ro/human3.6m/description.php)\n- [Download link to MoSh](https://drive.google.com/file/d/1b51RMzi_5DIHeYh2KNpgEs8LVaplZSRP/view?usp=sharing)\n\n### 训练数据预处理\n\nTFRecord:数据序列化成二进制的工具\n\n## keras\n\n`keras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)`  \nWraps arbitrary expression as a *Layer* object.\n\nkeras.backend: At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.\n\nLambdaCallback()  \n\n## 要解决的问题\n\n1. 现有数据集的数据怎么处理到能用在smpl上 ！！（解决 hmr里解决了训练数据-->tfrecord的过程）\n2. 确定量化指标 ！！（解决 hmr有evaluation）\n3. 确定遮挡情况下的重建效果！！（hmr，tex2shape，octopus，360texture那个）\n\n## 实验室/作者汇总\n\n| 名称                | 文章                   | 链接                  |\n| :------------------ | :-------------------- | :-------------------- |\n| MPI | SMPL/Octopus/.. | https://virtualhumans.mpi-inf.mpg.de/ |\n| UCB(Angjoo Kanazawa) | 预测人体动作/动物形体重建 | https://people.eecs.berkeley.edu/~kanazawa/ |\n| 周晓巍(浙大) | .. | http://www.cad.zju.edu.cn/home/xzhou/ |\n\n## 技术要点汇总\n\n| 文章名称                | 完成任务               | 技术要点描述           |\n| :--------------------- | :-------------------- | :-------------------- |\n| end to end recovery of human shape and pose(HMR) | an end-to-end framework for reconstructing a full 3D mesh of a human body from a single RGB image 不知道速度怎么样，其他的有做到实时的了 | 不计算2d/3d joint position，使用了一种高效的mesh representation parameterized by shape and joint angles|\n| hmd | 分阶段deformation | hmr做基础模型，找到joint，anchor关键点deformation，在产生个深度图做vertex级别的deformation |\n| deephuman | 不用smpl，直接从image用cnn还原三维结构 | 用了带语义的三维信息semantic volume |\n| bodynet | 不用smpl | hmd里提到的，不用smpl，用cnn找joint找sil构建3d pose再用cnn构建volumetric shape，用smpl监督算一个3d loss。总之就是多loss联合监督回归三维体积 |\n| Deep Textured 3D Reconstruction of Human Bodies | 不用smpl | hmd里提到的 |\n| double fusion | 用的单个深度摄像头，做到实时三维人体重建 | 内外两层模型，里边是smpl外层可以根据深度信息较大幅度的拟合RGB图像 |\n| hyperfusion | 单个深度摄像头+IMUs 惯性测量 | 在处理快速动作，遮挡情况比df更好，这俩重点在于捕捉连贯动作 |\n| Learning to Reconstruct People in Clothing from a Single RGB Camera(Octopus) | 视频1-8帧做人体重建，10秒完成（说是速度快，但是其他的有做到实时的了） | 速度快归功于两点：Tpose下完成特征融合；using both, bottom-up and top-down streams（？？不理解回头看看） |\n| Tex2Shape: Detailed Full Human Body Geometry from a Single Image | 单图重建模型，用了detectron的densepose对图像预处理出IUV图，然后根据原图+IUV图出模型 | 前置条件detectron/densepose/smpl |\n| Multi-Garment Net: Learning to Dress 3D People from Images |  |  |\n| Learning to Estimate 3D Human Pose and Shape from a Single Color Image | 周晓巍 | 跟hmr差不多 hmr用了个判别器，这个用三维模型投影回二维平面做监督 |\n| Learning 3D Human Dynamics from Video | single image预测人体3D past and future motion | present a framework that can similarly learn a representation of 3D dynamics of humans from video via a simple but effective temporal encoding of image features |\n| Predicting 3D Human Dynamics from Video | 跟上边都是UCB的Predicting Human Dynamics (PHD), a neural autoregressive model that takes a video sequence of a person as input to predict the future 3D human mesh motion | \n| LiveCap:Real-time Human Performance Capture from Monocular Video | the first real-time human performance capture approach that reconstructs dense, space-time coherent deforming geometry of entire humans in general everyday clothing from just a single RGB video | 应该是预处理阶段重建模型（需要花费时间），实时添加动作。重点解决两个非线性优化问题，提出两阶段（stage）解决思路 |\n| Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images “In the Wild” | 不需要图像分割/关节点标注的动物模型重建 | SMAL |\n| PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation | 对象姿态估计旨在检测对象并估计其相对于规范框架的方向和平移 |  PVNet predicts unit vectors that represent directions from each pixel of the object towards the keypoints. These directions then vote for the keypoint locations based on RANSAC//vector-field presentation |\n\n## 实验规划\n\n> 1. hmr：End-to-end Recovery of Human Shape and Pose\n> 2. octopus 有模型 有纹理贴图 用了Detailed Human Avatars from Monocular Video.的贴图方法\n> 3. tex2shape 这个有衣服的细节 试试有遮挡的情况下重建效果怎么样\n> 4. Learning 3D Human Dynamics from Video\n> 5. Multi-Garment Net: Learning to Dress 3D People from Images\n> 6. pvnet 遮挡截断情况下可以做6DoF Pose Estimation\n\n## 周计划\n\n2019.10.21\n1. 现有数据集的数据怎么处理到能用在smpl上 ！！（hmr有dataset-->tfrecord的code）\n2. 确定量化指标 ！！ （hmr：跟3d groundtruth 点对点算距离，数据集human3.6m -- 这东西不知道啥时候能下载）\n\n2019.10.28\n1. 处理输入图片准备test（图片加遮挡，截断，运动模糊）\n2. hmr、octopus、tex2shape 进行test\n3. test结果进行量化评估\n\n2019.11.4\n1. 复原结果汇总\n2. 贴图怎么上\n3. 量化指标\n\n2019.11.11\n1. 训练code跑起来\n2. 量化指标\n\n## 日报\n\n### 2019.10.28  \nhmr，tex2shape环境部署  \ntodo：处理输入图像，查看结果  \n\n### 2019.10.29\nhmr结果已出，tex2shape需要densepose预处理图片，需要看看densepose对于遮挡，截断，运动模糊的处理情况  \ntodo densepose结果查看  \n\n### 2019.10.30\ndetectron2可以用了，但是2提供的densepose的visualization mode不全，没有IUV，导致作为tex2shape的输入会有问题。还需要继续想办法  \ntodo：hmr基本上没有细节，只有pose和大致shape，接下来要主要关注tex2shape在有遮挡的情况下细节重建的效果  \n找两个带贴图repo试试，octopus/garment/360  \nevaluation没有human3.6做不了，那边注册不通过没法下载  \n\n### 2019.10.31  \n摸鱼\n\n### 2019.11.1\ndetectron2里的densepose没法出IUV的图，不太明白IUV这个图怎么用opencv出。只能在densepose结果图上做遮挡看看tex2shape的重建效果了  \n完成hmr/tex2shape的遮挡测试，todo：octopus/还有smpl加贴图\n\n### 2019.11.2/3\n休\n\n### 2019.11.4\ndirt 有个undefined symbol 大概率是跟显卡驱动 cuda版本有关系 因为笔记本上就装上了  \ndirt装不上garment也没法跑，得想办法用opendr代替dirt  \ndirt装上后有个segmentfault 明天继续看\n整理tex2shape/hmr/octopus的结果  \n明天看看贴图怎么搞，octopus用了个方法，还有garment那个的\n\n### 2019.11.5\noctopus keras.base_layer会报个参数错误  \ndensepose(tex2shape)不知道怎么出IUV  \ngarment(上贴图的)用了MPI-IS的mesh组件 需要python3\nTODO: humaneva, garment, Semantic Human Texture Stitching\n\n### 2019.11.6\n量化指标：the mean per-pixel error of 3d displacements maps  \n中文叫位移贴图/与凹凸贴图（法线贴图属于凹凸图），高度图不同  \n贴图挺顺利的，理论上所有smpl的模型都适用。贴图这边接下来要看怎么用自己的数据（从img-->pkl-->texture）\noctopus还是不行 操他妈的(keras outputs不是layer类型的，不知道为什么)（11.6更新：因为当时smpl()改成了smpl.call()，还是要走基类的__call__()的不然不是Layer类型）  \nLambda表达式是核心问题 明天看\n\n### 2019.11.7\nOctopus解决了，Lambda表达式没问题，smpl那个继承了Layer的类在调用__call__()时调用了call()，后者参数数量与基类Layer的call()参数数量不一致，导致了问题  \nhmr的训练需要groundtruth 3d，先放着吧  \n看effective C++(4/5)\n\n### 2019.11.8\n数据集MPI_inf_3dhp/MPII/COCO 下载  \n下载数据集coco/mpii/mpi_inf_3dhp  \n学习dx12\n\n### 2019.11.9/10\n休\n\n### 2019.11.11\ncoco/lsp/lsp_ext/mocap_neutrMosh/mpii/mpi_inf_3dhp --> tfrecord  \nhmr train code在tf1.14上有问题 降到1.4试试（conda最低1.4） hmr官方用的1.3//客制的有pytorch0.4的\ntrainer.py的train()有问题 --> sess.run时间太长了 1.4得调cuda版本 还是用1.14\n\n### 2019.11.12\n三个新论文 看起来实验会好做一些 train code/dataset都有：\n* PyTorch implementation of CloudWalk's recent work DenseBody https://arxiv.org/pdf/1903.10153.pdf [github](https://github.com/Lotayou/densebody_pytorch)\n* Repository for the paper \"Convolutional Mesh Regression for Single-Image Human Shape Reconstruction\" [github](https://github.com/nkolot/GraphCMR)\n* Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation (CVPR2019 Oral) [github](https://github.com/zhuhao-nju/hmd)\n\n### 2019.11.13\n看看十大排序七大查找算法（3-0）  \nhmd demo没啥问题 看看train 需要upi的数据集44g 这周五再下  \nevl的用了wild dataset 1.9g//RECON and SYN test\n\n### 2019.11.14\n排序/查找算法\n\n### 2019.11.15\nupi_s1h//human36m_washed//two test dataset for hmd(eval recon and syn sets//wild set)  \n\n### 2019.11.16/17\n休\n\n### 2019.11.18\ntrain without coco & human3.6m coco需要联网用json下文件，实验室电脑没有那么多网关流量，human3.6m没数据集  \ntrain joint的时候dataloader的num有点问题 改成8035试试（worked）done  \ntrain anchor done  \neval test doing  \n跑实验的同时看一下红黑树/B树/B+树  \n\n### 2019.11.19\neval完成  \n看hmd论文 `Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation`\n\n### 2019.11.20\ntex2shape的模型是有uv的 octopus/hmd都没有uv 所以没法贴图  \n加贴图那个基于octopus，需要绕着人转圈拍照片，然后做分割  \neval_wild on self trained model（10hrs）  \n明天看看遮挡情况下hmd的重建效果\n\n### 2019.11.21\nshell脚本里使用conda命令需要在conda activate前加上  \n`source ~/anaconda3/etc/profile.d/conda.sh`  \n遮挡情况下的hmd效果实验  \neval_wild on self trained model（10hrs）（昨天优点问题 再来一遍） \n\n### 2019.11.22\n确定目标 基于hmr和hmd做遮挡部分的重建  \n看hmd论文，研究hmd怎么加纹理细节的 \n\n### 2019.11.23/24\n休\n\n### 2019.11.25\nshadingnet: hmr 3d mesh --1-> depth map --2-> detailed depth map --3-> detailed 3d mesh  \nhmd里是先shadingnet根据rgb image预测一个depthmap 然后加上mesh(openmesh + hmr smpl) 投影出的depthmap  \nUnet 输入rbg groundtruth depthmap 结果泛化能力差 所以再来个shadingnet loss是前边unet的depthmap loss 还有depth map重建成rbg 跟input的loss  \n需要解决的问题就是设计网络做第二步（doing sfsnet/3dmm/..）  \n先可视化一下depthmap（done）  \n\njoint和anchor都独立与shading的，在有rgb出了joint/anchor的前提下\n\n1. rgb做修复 然后经过shading net(pretrained) 加到project depth map上看结果  \n2. 不处理的rgb 经过shading net(pretrained)生成depth map 然后在dm上做修复 最后加到project depth map上生成最终dm  \n3. 建立端到端网络直接从未处理的rgb-->修复完成的depth map，最后加上project depth map\n\nhmd的数据集刨除h36m应该有18000+ train set，现在只有9000+ 重新用脚本处理一遍\n\nnumpy 高级索引 ndarray[x,y]//ndarray[a==b]\n\n### 2019.11.26\n机器在处理数据（就是做hmd 里的 wild set）（coco做了7000+然后断开socket链接了，回头继续转）  \n问题转化为：有遮挡的rgb图生成完整的深度图的问题  \nDDRNet做的深度图重建。  \n试试[Deeper Depth Prediction with Fully Convolutional Residual Networks (FCRN)](https://github.com/iro-cp/FCRN-DepthPrediction.git)  \n还有[ddrnet](https://github.com/neycyanshi/DDRNet)  \n\n王琛的方法，需要提供人体/遮挡的数据集（考虑下怎么做这个数据集），网络是现成的  \n三维人体重建转化到深度图的inpainting这样可以吗？？  \n\n更新ubuntu grub的引导会没 需要到win7下重设\n\n### 2019.11.27\ncoco数据集的hmd预处理还是有socket error，今晚挂上代理再试一次  \n问题：有遮挡的情况下恢复深度图的detail，还是考虑深度图质量差不多的情况下，深度图生成三维模型的精度  \n见今日周报 基本确定12月的工作内容  \n\n### 2019.11.28\n固定像素位置加遮罩很容易（已完成），考虑往人体固定位置上加？  \n人体的数据集就18000+ 顶多了 看别人做inpainting的得有4/5w  \n监督数据怎么来？1. 通过hmd shading net出深度图；2. 找别的深度估计方法  \n\n### 2019.11.29\n先用shadingnet的结果做gt吧，开始处理数据集\n\n### 2019.11.30/1\neffective c++\n休\n\n### 2019.12.2\n生成depth ground truth 流程如下\nimg-->hmr result（predict_hmr_dm 批处理hmd_2 18403张train img）-->depth result（predict_hmd_dm 生成depth 到hmd_masked/train）  \n做depthmap的gt要150hrs。。？\n\n感觉没人做带遮挡的rgb到depth的映射(也就是inpainting和depth estimation的混合)  \n现有的depth estimation方法 pretrained的model对人体的效果极差 根本比不了hmd的shadingnet结果 见周报图  \nincomplete RGB --> complete depth 做不动  \nincomplete RGB --> incomplete depth --> complete depth  \n想出incomplete depth还得150hrs  \n最后可能只能在深度图上做inpainting\n\n### 2019.12.3\n写周报  \nleetcode\n\n### 2019.12.4\n人体的rgb inpainting目前都没有人做的好，主要是会拿背景的信息填充到人体遮挡区域  \n考虑使用sil，把人体抠出来，看看能不能训练一个针对人体的inpainting网络，再出深度图看效果  \n注：rgb重建的效果也不会特别好，举个例子，拿衣服去补人脸的位置，肯定效果不对。但是，转成深度图再到三维模型上，效果不一定会特别差，待试  \n想想怎么给inpainting的输入加入人体轮廓信息这个约束  \nrbg修复好了 --> 深度图效果好 --> 模型效果好  \n\n王琛表示深度图做修复能做，接下来准备等深度图数据集处理完成，进inpainting网络，训练修复深度图的网络模型。\n\n### 2019.12.5\n玩kbengine，部署linux游戏服务器，打包安卓客户端，双端联机测试  \n深度图要等到周日晚上，给王琛做\n\n### 2019.12.6/7/8\n休\n\n### 2019.12.9\ntrain depth inpainting model  \nshift-net_pytorch 深度图做出npy和png了，shift-net的图片都是256256，我这是448448，需要调整下网络\n\n### 2019.12.10\n开始训练针对深度图的shift-net，30hrs(30 epoch) 明天放到hmd里看效果  \n这次训练用的center mask(25%左右的遮挡率) 有些把人遮住太多了 下次试试随机的或者范围小一点的\n玩kbengine\n\n### 2019.12.11\n贵州电网的一个UI材质工具  \ntrain好的modeltest需要测试集的depth map，2000多张得搞一下  \nhmd的shading-net没有train code，也就是说rgb到depth这段没有源码，shift-net做inpainting已经很好了，如果有shading-net的train code，合起来或许能做 incomplete rgb --> complete depth  \nNYU的数据集看了精度肯定不够  \n\n### 2019.12.12\n出inpainting好的深度图重建出的三维模型，这个算是完成目标了，但是是分两阶段完成（不完整rgb-->不完整depth-->完整depth）  \n接下来看shadingnet怎么train的，得能跑通\n\n3d mesh --> 图像空间 初步深度信息 --》 shadingnet 增强深度信息--》  \nmesh到depth的原理 还有 ddrnet的那个loss  \n\n开题报告\n\n### 2019.12.13/14/15\n开题报告\n\n### 2019.12.16\nhmd: 训练策略（train scheme）是仿照的sfsnet  \n  先用了一个Unet，train时候输入是RGB + hmr投影出来的depth，监督数据是Kinect扫的depth（这个Unet train的时候只用到了少量数据集，然后用训练好的模型生成大量的depth，此时depth效果不好）  \n  然后是shadingnet，train的输入是hmr投影出来的depth和原始RGB，一个loss是用unet的输出监督，一个loss是photometric reconstruction loss（问题是这个reconstruct 重建了什么 就能知道重建的这个玩意儿跟什么做比较成为损失函数）\n\n重点看ddrnet怎么优化depth的，原理是什么\n\n> **阶段性总结**  \n> 1. 明确人体细节是由深度图产生的，三维重建问题转化到深度图修复问题上\n> 2. 做出了深度图数据集 18000+3000\n> 3. shift-net针对深度图训练了一个模型，可以用于深度图恢复\n> 4. tex2shape/octupus/hmr/hmd 基本可以跑对比实验了\n\n接下来的工作是做shadingnet的train  \n对比joint和anchor的train code  \nshadingnet的dataloader返回的是(src_img, depth_diff, mask)为什么要返回diff??? gt和smooth depth的差\n\n### 2019.12.17\n自己做了shadingnet的train code，网络结构Unet（hmd给的），损失函数就用MSE，输入完整rgb还有mask，监督数据depth_gt，learning rate降到0.00001  \n搞搞看能不能rgb到depth 30分钟迭代900多次就训练完了 结束条件是什么不知道 测试中  \n测试结果不好 自己train出来的结果有明显颗粒感 深度数值范围0-1之间，pretrain的+-25之间 明天看\n\n### 2019.12.18\n改开题报告 整点ddrnet的公式进去  \nshading net 用MSE train 完全不收敛啊  \n\nshadingnet dataloader ： mask就是coarse depth？！ 剪影代替的coarse depth？？ wtf  \n\n### 2019.12.19\n两个问题：背景是黄的 是因为背景到人体的过度不自然，pre的是背景是0 人体上是0左右 正负50都有  \n细节是有的 但是我的像素不连续 有细节但是数值跟pre对应不上 颜色深浅  \n换个loss看看结果变不变 完全不变 调参也不变。。\n\n### 2019.12.20\n不清楚网格的问题是不是通过调参就能解决的，或者换loss，还是不知道depth_diff干嘛用的  \n只能换loss了 自定义loss试试\n\n### 2019.12.21\n原因是输入图像和gt图像没有匹配，低级错误  \n下一步进一步调参降低loss\n\n### 2019.12.22\n1. eval pretrained model和我自己的model\n2. shift-net改下输出看结果\n   1. G & D：G把输出的channel改成1，loss得跟depth比；让D区分gtdepth和preddepth\n   2. backward_G and backward_D real_A real_B为什么有两个real？ dataloader在aligned_dataset.py里\n   3. real_A == real_B//real_A-->fake_B\n   4. fake_B--netD-->pred_fake//real_B--netD-->pred_real\n   5. set_gt_latent干什么用的\n\n> 下周开始做改进改进版shift-net的实验\n> 月底开始写论文\n\n### 2019.12.23\n改shift-net：\n  1. Gnet输入RGB，自己加遮罩，生成fake_rgb，用原始RGB监督；Dnet输入RGB和fake_rgb，输出两个判断结果的计算loss\n  2. G输入3通道输出1通道，D出入1通道输出二分类，netD和vgg16featureextractor（util）\n问题： 方框可能太大；把RGB的人挖出来比较好背景干扰太多\n还是应该输出numpy数组，监督数据如果用png出来的是三通道的rgb图，得改可视化的代码，用plt通过numpy数组生成训练过程中图像\n\n### 2019.12.24\n方框缩小，单通道输出，trainning，ETA 25号中午\n\n### 2019.12.25\ntest\n\n### 2019.12.26\nspectral_norm gan用的东西  \n现在要解决的问题：重建深度图不光滑，有明显的网格，重复结构，不知道为什么  \nG就是个encoder decoder 为什么会有网格   \n试试用sil不用深度图的a[b==0] = 0 不行 sil只有8035个  \n把unet最后一层的tanh激活函数删了结果看起来好点了 迭代30次看看效果  \n7次 看起来还原出来的部分并没有什么细节\n\n### 2019.12.27\nshift-net几个损失函数得调整，D一直为0了 content过于大  \nD的输入已经是抠出来的了，opt.overlap是什么\n\n### 2019.12.28/29\n休 \n回放系统、撤销操作  \n\n### 2019.12.30\n开会，确定一月时间安排  \n开始论文初稿，学习latex，写公式最麻烦，网络结构图，柱状图，折线图  \n\n怎么能让遮挡区域的数值乘个系数？？\n\n### 2019.12.31\nabstract完成\n\n### 2019.1.1\n开题ppt完成\n\n### 2019.1.2\nlatex画Unet\n\n### 2019.1.3\n朱青审开题报告，ppt  \n修改\n\n### 2019.1.4/5\n休\n\n### 2019.1.6\nintroduction\nrelated work\nmethod\n\n### 2019.1.7\nresult\nconclusion\n\n>  **论文结构**\n>  1. abstract\n>     \n>  2. introduction\n>     三维人体重建：分两种基于参数化模型的和非的/还是特征匹配的和模板适应的  \n>     目前方法的局限性，我的方法综述，贡献点总结\n>  3. related work  \n>     * 参数化的  \n>       * scape  \n>         * 人工标记关键点\n>           * \n>         * 卷积标记关键点  \n>       * smpl  \n>         \n>     * 非参数化的  \n>     \n>  4. methods  \n>     * SMPL，anchor/joint deformation，**vertex deformation**（our dataset, our net, loss）\n>     * Loss：G_GAN,G_L1,D,style(MSE vgg),content\n>  5. results & comparison  \n>     介绍evaluation用的数据集，评价方法，评价/对比结果  \n>     hmr/hmd/tex2shape/octopus  \n>     原图inpainting/深度图inpainting/遮挡rgb生成完整的深度图  \n>     测试150加遮罩-->(只能不带遮罩的进？？为什么)进shiftnet出深度图-->hmd_s使用深度图信息而非shadingnet信息-->结果\n>  6. conclusion\n\n\n### 2020.1.13\ndhdnet在跑recon测试集的时候方框处理的非常不好  \n现在猜测是因为训练的用深度图gt当作的sil，在A[B==0]=0这步的时候很可能把纹理信息填回方框区域内了。。现在但是理论上shiftnet自己还会加遮罩  \n目前recon测试集上只能用不加遮挡的img做输入效果还可以  \n矛盾点在于 shiftnet是在线加的遮罩啊 为什么输入图像加不加遮罩还会造成影响？？？？\n\n### 2020.1.14\nrecon只看joint 还是得看syn  \n输入图像家的遮罩试着比 shiftnet动态加的小一点 84 84 140 140-->87 87 137 137\n\n### 2020.1.15\nleetcode  \nblog 加入vuejs静态页面  \nMirror 多人游戏demo / kbe C++ 服务端  \n\n\n### 2020.3.8\nAttention机制[zhihu](https://zhuanlan.zhihu.com/p/91839581)  \n论文搜索：  \nSelf-Attention Generative Adversarial Networks (SAGAN)[code](https://github.com/heykeetae/Self-Attention-GAN)  \nA PyTorch reimplementation for paper Generative Image Inpainting with Contextual Attention [paper](https://arxiv.org/abs/1801.07892) [code](https://github.com/daa233/generative-inpainting-pytorch)\n\n### 2020.3.9\n\n[Learning 3D Human Shape and Pose from Dense Body Parts]()\n\n### 2020.5.30\n\nLosses：下降较明显的有G_L1，content；G_GAN略上升，D下降不明显  \nloss计算公式：  \n$lossD = (lossDfake + lossDreal) * 0.5$ (vanilla)  \nfake/real 是BCELoss二分类交叉熵损失函数  \n$loss G = loss G L1 + loss G L1 m + loss G GAN + style loss + content loss + tv loss$  \nloss G L1 是 $L1 loss * opt.lambda_A$  \nL1_m 是一个spatical discounting l1 loss（别的论文里提出来的）  \nloss G GAN 是BCELoss  \nstyle和content都是MSELoss  \ntv是自定义一个损失函数  \n\n目前已有的：\n* rgb特征提取-->分三阶段形变smpl模型\n* depth map到人体表面细节，形变方法（hmd提供）\n* 不完整rgb向完整depth map的转换网络模型\n* 不完整rgb到完整人体模型的端到端系统\n* 合成人体深度信息数据集\n\n后续研究方向（大论文第二章，改进算法）：\n* center mask的大小对重建质量的影响（最大多大就handle不住了）\n* 不规则mask（shiftnet做了，这个好实现）\n* attention机制对于结果的提升有多少（没概念）\n* 目前来看多loss共同作用，有些loss并没有明显收敛（是否等于没作用、贡献）--灼烧实验\n* depth信息到三维点坐标的形变（deform）关系还能改进（比如深度或者说形变的scale，还有方向，目前是垂直于视平面，可以是垂直于粗模型表面？）\n* structure from motion方向研究（全新方向，建筑行业在用）\n* 加壳，做成用户友好的应用程序\n\n### 2020.6.2\n\nICIP论文中的四个示例在recon_set中，编号为1，3，95，116  \n\n### 2020.7.8\n\n专利：\n* 技术背景\n  * 应用与不足\n  * 现有技术分析\n  * 综上\n* 发明内容\n\n\n### 2020.7.13\n\nICIP ppt  \n[mesh deformation with Laplacian coordinates](https://zhuanlan.zhihu.com/p/25804146)：一种智能化的方法，能够让用户只需设置个别离散点的新位置来表达他所想要的形变，就能自动根据所需保持的形体信息来计算出剩余离散点应有的位置\n\n### 2020.10.27\n\n$$ L_{joint/anchor} = \\parallel p - \\hat{p} \\parallel_{2} $$\n\n### 2020.11.19\n\nPIFuHD的重建效果比hmd好多了，处理遮挡不好\n\n### 2020.11.20\n\n开始研究star的用法，先看smpl-x是怎么使用smpl模型的  \n\nhmd中的laplacian形变code来自duke university, [course link](https://github.com/bmershon/laplacian-meshes)  \n球谐函数是自己写的tql  \nrenderer是hmr的\n\n得搞清楚smpl verts faces的维度和个数\n\n### 2020.11.27\n\ntexture：\n* Semantic Human Texture Stitching: octupus//// opendr only workable on linux\n* tex2shape: 有uv，unity里可以贴图\n* pix2suf: 用衣服的2d图片，映射到衣服模型上，是分开的上衣和裤子（短裤）模型，不是smpl人体模型上\n\ngeometry：自监督\n\n### 2020.12.3\n\n标准SMPL模型提供了带uv信息的obj文件，可以使用stitching的纹理贴图  \n实验思路：\n* 单帧：包含遮挡和不包含遮挡和经过shift-net图像修复的受遮挡，用tex2shape的理论\n* 多帧：stitching原本，遮挡物随机放置，用stitching的理论\n\n### 2020.12.4\n\n大论文参考论文，hmr，hmd，shift-net，ddrnet，tex2shape，stitching  \n理论知识点，smpl模型，GAN，Unet，Shift layer，拉普拉斯形变Laplacian mesh deformation，球谐函数gi\n\n\n### 2020.11.3\n\n[SIFT](https://blog.csdn.net/zddblog/article/details/7521424)：尺度不变特征变换，采用高斯核函数进行滤波，寻找不同的尺度空间  \n  可以解决occlusion和clutter？  \n  LoG(Laplacion of Gaussian)算子：\n  高斯差分函数（Difference of Gaussian ，简称DOG算子）：\nKNN：K最近邻，k-nearest neighbor\naggregator：\nupdater：\n[multi-layer perceptron](https://blog.csdn.net/xholes/article/details/78461164)（MLP） in updater：也就是Full-connection Neural Network \n\nself- attention mechanism：\n  [attention机制](https://zhuanlan.zhihu.com/p/37601161)：soft-attention、attention、self-attention，就是source=target，寻找输入语句中单词间的联系\nnode-based clustering：聚类算法 有K-means，和knn有区别但是很像，前者是每次迭代调整聚类中心\nPointCN：\nepipolar distance:\nStructure-from-Motion system:\nshape-from- silhouette technique：搞出来的初始几何体都不完全并且有噪点  \nhuman parsing method：\n\n\n### 2020.11.10\n\nLBS：smpl基于全身的linear blend skinning (LBS)\ncocoapi报no module pycocotools._mask需要install pycocotools，在git repo pythonapi目录下执行makefile（注意看makefile的内容）\n\n### 2021.4.7\n\ntf.variable_scope() reuse: [Link](https://blog.csdn.net/xpy870663266/article/details/98950853)\n\n\n### 2021.4.12\n\n1. 数据集规模上要强调自监督在同等数据规模下没有dhd好，然后转到增加数据集规模\n2. 4.3节强调采用dhd+自监督的原因是：自监督提供高频细节，dhd提供低频褶皱\n3. 强调是框架结果的提升，而不是自监督方法与dhd方法间的比较\n4. dhd的输入是rgb+mask，hmd里shadingnet是rgb+depth，盲审版本第三章的流程图写的是rgb+sil..\n5. 自监督训练数据自己拍的48000帧，网络视频3000组，大概等于12000帧\n\n\n### 2021.5.24\n\n盲审三个良好，申优答辩很简单，明天交终版论文  \n  \n终。  \n\n\n## conda env\n\n  * pytorch：Python 3.7 + pytorch 1.3  detectron2/densepose/shift-net_pytorch\n  * tf2: python2 + tf1.14  hmr, tex2shape, Semantic Human Texture Stitching\n  * tf: python3 + tf1.14 + pytorch  human_dynamics, neuralgym/generative_inpainting\n  * dirt：py2.7 + tf1.13 + dirt  octopus, garment\n  * hmd(可以跟tf2合并)：py2.7 + pytorch1.0.1  hmd\n\n## 实验结果\n\n* 三通道rgb原图到三通道depth.convert('RGB')效果不好，中心预测的不好，四周也没有跟gt完全一致。\n  * 缩小遮挡范围1/2改为1/4的宽高\n  * 输入三通道rgb 输出单通道npy数组 改下可视化的代码使正常显示\n\n* human_depth: 输入三通道depth_png，输出三通道修复完成后的depth_png，这是下边实验的目标效果\n* rgb2depth_npy_2: 初试版本，1/4边长遮挡，王瑾周报\n* rgb2depth_npy_3: G去tanh()版本，网格纹理问题解决\n* rgb2depth_npy_4: 修改D输入图像范围，仅输入被遮挡区域\n\n\n## 数学理论相关\n\n[压缩感知](https://www.zhihu.com/question/28552876/answer/1268629178)中的欠定方程（undetermined equations）：\n\n\n## 目标（朱邮件内容）\n\n研究方向：**非理想条件下的单目RGB相机三维人体重建**  \n\n领域现状：目前基于相机阵列以及单目RGBD相机的三维人体重建技术已经较为成熟，仅依靠单目RGB相机的三维人体重建工作具有广阔的发展前景并且具有挑战性。以MPI、UCB、浙大为首的一些实验室已经在该研究方向上已经取得了一些成果，但是输入图像质量都比较理想，非理想条件下的重建效果并不明确。  \n\n我的工作：目前确定做非理想条件下的单目相机三维人体重建，提高重建精度包括模型细节、姿态、纹理贴图。非理想条件具体来说有以下情况：\n1. 图像中人物受到遮挡（重点）\n2. 图像中人物因高速移动产生的运动模糊\n3. 图像中人物因环境光照产生的视觉偏差\n\n工作计划：看现有方法在上述非理想条件下的重建效果（文章中没有提到的需要亲自跑实验验证）；设计改善方法，反复实验验证，得到实验数据；论文撰写。\n\n# 思路\n\n* 单图多人（人群）三维重建  \n  可能需要解决的问题：  \n  遮挡（周晓巍的PVNet解决了遮挡的问题，空间维度上的估计）  \n  分割  \n  大小/相对位置  \n  ...   \n* 跟游戏开发能关联的地方：  \n  用引擎看效果  \n  实用性  \n\n* 从视频序列中选出作用显著的帧，设计量化评价方法  \n\n* 从不同表达，面点云体素区别入手  \n\n* 增加脸部细节（手部、脚步，观察几个论文的演示视频好像都没有动作细节，骨骼的问题应该是）呢？？结合3dmm（已经有结合的了19.10.10更新）  \n\n* 考虑多模态，加入语义信息辅助重建（还得看nlp的东西，把特征映射到一个空间不知道能不能做）\n\n* **快速移动/运动模糊**的视频/照片做重建（回到图像处理的问题上，不确定目前已有的方法在视频中任务快速移动情况下的重建效果）\n\n* UCB预测人体动作（时间维度上的估计） 能怎么改进\n\n* MPI做的实时 \n\n* UCB把SMPL用到了动物（斑马）模型重建；不是smpl是smal\n\n* 光照条件对重建质量的影响\n\nUCB做了动物的模型重建，根据视频**预测**人体接下来的动作；MPI**实时**Video to Mesh  \n\n>>> shape：更有细节/遮挡、截断(空间维度预测)/  \n>>> pose：根据视频、单图预测pose（时间维度预测）/实时更新pose  \n>>> texture：单视角贴图/多视角贴图\n\n> **疑问**\n> 6D pose estimation 和 smpl/smal重建出的pose有何异同？？是一个东西吗  \n> In contrast to coordinate or\nheatmap based representations, learning such a representa-\ntion enforces the network to focus on local features of ob-\njects and spatial relations between object parts. As a result,\nthe location of an invisible part can be inferred from the vis-\nible parts. In addition, this vector-field representation is able\nto represent object keypoints that are even outside the input\nimage. All these advantages make it an ideal representation\nfor occluded or truncated objects.\n\n## 大论文\n\n### 大论文结构\n\n* 摘要\n  * 三维人体重建是什么\n  * 挑战\n  * 现有方法的局限性\n  * 本文的两个贡献点\n* 绪论\n  * 研究背景与意义\n    * 三维重建是什么\n    * 主要挑战\n    * 传统的三维重建方法\n    * 传统方法存在的问题\n    * 深度学习与GAN\n    * 基于GAN的端到端系统\n    * 本研究的方法意义\n  * 国内外研究现状\n    * \n  * 本文主要研究内容+重点\n  * 本文结构及安排\n\n\n* 第四章 单视图三维人体纹理贴图重建算法\n  * detectron的人体分割和UV映射算法\n    * \n  * 基于图像修复的UV纹理映射\n    * 输入单张人体RGB-->IUV-->normal texture-->贴图的三维人体模型\n  * 实验结果分析\n停滞在detectron2生成的IUV跟tex2shape中的IUV不一样，感觉就是多个了背景，不知道怎么去  \n困难在于还要训练densepose以应对遮挡，这块监督数据不知道怎么办，训练策略不知道怎么改  \n\n* 第四章 自监督人体深度估计算法研究\n\n\n* 总结\n  * 定义\n  * 应用\n  * \n\n### 思路\n\n参数化人体模型--scape和smpl，将形体姿态转换为参数向量，方便神经网络进行学习  \n问题在于精度不够，没有细节，所以自由网格形变，非刚性的三维形变方法对模型进行优化  \n\n\n## 时间安排\n> VCIP 5月\n> ACM Multimedia 3月\n> ICIP 1月31日\n> > 1月15日初稿和evaluation  \n> \n> 1月开始写论文  \n> 12月实验，开题  \n> 开始编写代码，训练模型，评估实验数据\n> 11月实验  \n> 设计优化思路，实验步骤，预期的实验结果 11.18-11.29 两周\n> 现有方法在非理想情况下的表现 10.21-11.15 四周\n> 10月底规划好实验步骤，预计出的结果\n> 10月18号确定要做的目标\n\n# 信息总结\n\nfusion\nmulity domin\n多元融合\n\n显著性\n摘要\n帧对重建质量的贡献\n\n王少帆 北工大计算机学院\ndblp\n\n# todo list\n\n数据清洗 三个数据集UP-3D，HumanEva-I，Human3.6M  \n清洗的目的？目标？要做成什么样？","content":"<h1 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h1><p><a href=\"https://arxiv.org/\">arXiv检索</a></p>\n<ol>\n<li>1812.10558 通过视频素材实现从2d到3d的面部重建来完成测谎</li>\n<li>1812.01742 单一视角的三维重建，使用对抗训练（非人</li>\n<li>1812.05583 基于学习的ICP（迭代最近点算法）重构场景（非人</li>\n<li>1812.07603 通过视频素材的面部模型学习</li>\n<li>1812.05806 自我监督的引导方法，单图片的三维人脸重建</li>\n<li>1812.02822 学习生成模型的隐藏区域（非人</li>\n<li>1901.00049 基于轮廓的衣着人物（全身</li>\n</ol>\n<p><strong>A类</strong></p>\n<ul>\n<li>通过直接体积cnn回归从单图重建大范围三维人脸（源码lua+py</li>\n<li>使用图到图转换的无限制面部重建（源码lua</li>\n</ul>\n<p><strong>老师推荐</strong></p>\n<ul>\n<li>使用affinity field的实时多人二维姿态估计</li>\n</ul>\n<h1 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h1><h2 id=\"通用\"><a href=\"#通用\" class=\"headerlink\" title=\"通用\"></a>通用</h2><p><strong>关于三维重建</strong><br>单个图像进行三维重建的数据驱动方法：一是明确使用三维结构，二是使用其他信息推断三维结构<br>2DImage—&gt;encoder—&gt;latent representation—&gt;decoder—&gt;3DObject<br>不同方法区别在于对三维世界采取的<strong>限制</strong>：多视图一致性学习三维表示、利用关键点和轮廓注释、利用2.5D草图（法线，深度和轮廓）改善预测  </p>\n<p>encoder-decoder的<a href=\"https://blog.csdn.net/chinabing/article/details/78763454\">含义</a></p>\n<p><strong>关于shape priors</strong><br>许多方法选择更好的捕捉多样的真实形状<br><strong>non-deep方法</strong>关注低维参数模型，使用CNN来学习2D渲染图像和3D形状的<strong>共同嵌入空间</strong><br>其他方法依赖<strong>生成模型</strong>去学习shape priors</p>\n<h2 id=\"博客链接\"><a href=\"#博客链接\" class=\"headerlink\" title=\"博客链接\"></a>博客链接</h2><p><a href=\"https://blog.csdn.net/yyyllla/article/details/84573393\">3D人脸重建学习笔记CSDN</a><br><a href=\"https://www.jianshu.com/p/f33b3d440f7d\">3D重建的学习笔记简书</a></p>\n<h2 id=\"Learning-Single-View-3D-Reconstruction-with-Adversarial-Training-1812-01742\"><a href=\"#Learning-Single-View-3D-Reconstruction-with-Adversarial-Training-1812-01742\" class=\"headerlink\" title=\"Learning Single-View 3D Reconstruction with Adversarial Training 1812.01742\"></a>Learning Single-View 3D Reconstruction with Adversarial Training 1812.01742</h2><p>传统方法用多个角度的多张照片实现三维建模<br>问题两个：一是需要大量的观察点；二是物体表面是<em>Lambertian</em>（非反射）albedos是非均匀的<br>另一种三维重建的方式是利用物体外观和形状的知识从单视图二维图像生成（假设shape priors足够丰富）<br>CAD库（computer-aided design）：<u>shapenet，pascal3d+，objectnet3d，pix3d</u>  </p>\n<p>这些方法都从渲染的图像中回归三维形状：将二位图像转化成潜在表示的<strong>编码器</strong> 以及 重建三维表示的<strong>解码器</strong><br>为了学习shape priors深度学习算法需要大量的三维对象注释，自然图像中获取三维注释很有挑战，因此使用合成图像（三维模型渲染出的图像）<br>CNN的<u>domain shift</u>问题，导致基于cnn的三维重建性能恶化  </p>\n<p>这篇文章的方法：提高重建模型性能，为了实现获取三维物体标签，他们shape priors训练出的网络有个<strong>重建损失值</strong>，给这个值引入了两个限制<br>一是受domain shift文献启示，强制让编码的二维特征不变，对应于他们所来自的domain。这样合成图像训练出的编码器在真实图像上表现更好<br>二是将编码的二维特征限制在现实物体的多种形状之中，通过对抗训练定义这两个损失值<br>总结：一个<strong>模型</strong>和<strong>损失函数</strong>，利用shape priors提高自然图像三维重建性能（两种方式使用对抗训练）<br>reconstruction adversarial network(RAN)<br><strong>只使用rgb图像信息</strong>，和易于获取的自然图像。独立于编码器和解码器，并且可以使用到其中<br>借鉴了domain confusion（作用是classification），为了让从合成图像里训练出来的模型在真实图像这边有更好的表现  </p>\n<p>具体方法：todo</p>\n<h2 id=\"通过直接体积cnn回归从单图重建大范围三维人脸\"><a href=\"#通过直接体积cnn回归从单图重建大范围三维人脸\" class=\"headerlink\" title=\"通过直接体积cnn回归从单图重建大范围三维人脸\"></a>通过直接体积cnn回归从单图重建大范围三维人脸</h2><p>目前三维人脸重建的方法多假定有多张面部图片可以使用，这使得重建面临方法上的挑战：在夸张的表情、不均匀光照上建立稠密对应关系<br>这些方法需要复杂低效的管道构建模型，拟合模型。本文建议通过在由2D图像和3D面部模型或扫描组成的适当数据集上训练卷积神经网络<br>（CNN）来解决这些限制</p>\n<h2 id=\"Extreme-3D-Face-Reconstruction-Seeing-Through-Occlusions-极端3D面部重建：遮挡透视（讲）\"><a href=\"#Extreme-3D-Face-Reconstruction-Seeing-Through-Occlusions-极端3D面部重建：遮挡透视（讲）\" class=\"headerlink\" title=\"Extreme 3D Face Reconstruction: Seeing Through Occlusions 极端3D面部重建：遮挡透视（讲）\"></a>Extreme 3D Face Reconstruction: Seeing Through Occlusions 极端3D面部重建：遮挡透视（讲）</h2><p>bumpingmapping概念的推动下，该文提出了一种分层方法。将全局形状与其中细节进行解耦。估计粗糙的3d面部形状为基础，然后将此基础与凹凸贴图表示的细节分开。<br>与本文相关的工作：<br>    reconstruction by example 这类方法用三维脸部形状去调整根据输入图片估计出的模型，降低了观看条件却损失了真实度与准确性<br>    face shape from facial landmarks 这类方法稳定但是模型都差不多，没有细节，而且不清楚遮挡landmark的情况下表现会如何<br>    SfS <em>Shape-From-shading</em> 根据光反射生成细节丰富的模型，但是受环境影响严重，需要满足其对环境的特殊要求。任何遮挡物都会生成到模型中<br>    statistical representations 最著名的方法是3DMM，这篇文改进了这个方法直接根据图片强度信息用cnn回归3DMM的参数和面部细节<br>    deep face shape estimation 深度网络一是直接用深度图重建，二是estimate 3D shapes with anemphasis on unconstrained photo 观察条件高度不变但是细节模糊  </p>\n<p><strong>准备工作</strong><br>矛盾：整体形状的高度正则化vs细节的弱正则化。解决方法：bump map representations which separate global shape from local details<br>    理解的正则化：使模型更有普适性，低正则化是让模型有更多细节、更有特点，反之是让模型更接近普适的规则（每个模型都有一只鼻子一张嘴两只眼睛）<br>给一张图片建立以下几个部分：基础形状——S，面部表情——E，6维度的自由视点——V。接下来是bump map捕捉中级特征（皱纹等非参数的），最后完成因遮挡丢失的细节。<br><strong>添加细节</strong><br>基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。<br>中等程度细节：image to bump map，修复遮挡细节，基于软对称的模型完善。<br><a href=\"http://vis-www.cs.umass.edu/lfw/\">LFW验证</a></p>\n<p>PPT用：<br>目的：现有单图三维重建局限性很高，必须在正前方、距离近、无阻挡的视点，该文设计了一种用于在极端条件下提供细节丰富的面部三维重建模型的系统。极端条件包括，头部旋转以及遮挡<br>方法：简单讲步骤，关键的创新点，值得学习的点后边会细说。<br>总的来说：先创建面部整体的基础形状，与局部细节分开，在基础形状之上建立中等程度的面部特征。这样做可以保证极端条件下整体面部形状的稳定性。其他较新的方法往往用局部细节构建整体形状。<br> 构建基础形状s，构建面部表情e，构建视点v：<em>凹凸图可以分离整体形状和局部细节</em><br>这仨东西分别是干什么用的：<em>基础形状使用3DMM，3DMM用了resnet的101层网络架构。表情部分由3DDFA提供，更新的有expnet。确定视点用了deep，facepostnet。</em><br>image to bump map转换<br>凹凸图训练集：用深度编码-解码框架生成凹凸图<br>学习建立凹凸图：定义了自己的网络损失函数，可以在不牺牲高频细节的情况下抑制噪声<br>还原遮挡细节<br>给予范例的空洞填充方法<br>搜索参考集<br>混合细节<br>更复杂的修补<br>基于软对称的模型补全  </p>\n<p>贡献：解决<strong>对foundation的高度正则化</strong> VS <strong>对detail的低正则化</strong> 两者的矛盾  </p>\n<p>注：<br>    bump map使用灰度值来提供高度信息，normal map使用xyz轴所对应的rgb信息<br>    <a href=\"https://github.com/vdumoulin/conv_arithmetic\">卷积与反卷积</a></p>\n<p>跑demo流程：<br>    NVIDIA-docker启动container，如果跑代码没有driver重新run一个，用readme里的run命令。<br>    之后会出现860m只支持cuda5.0的报错，需要<a href=\"https://github.com/pytorch/pytorch#from-source\">从源码编译pytorch</a>。首先docker里装anaconda<br>        wget <a href=\"https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2018.12-Linux-x86_64.sh\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2018.12-Linux-x86_64.sh</a><br>        应该不用在docker里装cuda和cudnn，直接安装pytorch的依赖然后安装pytorch应该就可以<br>        在1080上不会出现上边的报错，完全按照README走就行。</p>\n<p><a href=\"extreme_3d_face.pptx\">PPT</a></p>\n<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/extreme_3d_face.pptx' width=800 height=600 frameborder='1'></iframe>\n\n<h2 id=\"Learning-to-Estimate-3D-Human-Pose-and-Shape-from-a-Single-Color-Image-讲-DOI-10-1109-CVPR-2018-00055\"><a href=\"#Learning-to-Estimate-3D-Human-Pose-and-Shape-from-a-Single-Color-Image-讲-DOI-10-1109-CVPR-2018-00055\" class=\"headerlink\" title=\"Learning to Estimate 3D Human Pose and Shape from a Single Color Image(讲) DOI:10.1109/CVPR.2018.00055\"></a>Learning to Estimate 3D Human Pose and Shape from a Single Color Image(讲) DOI:10.1109/CVPR.2018.00055</h2><p>SCAPE:  shape  completion  and  animationof people<br>SMPL: A skinned multi-person linear model<br>SMPL是一种参数化人体模型，与非参数化模型的区别在于，参数化的可以用函数映射的方式表达出来，或者说是可以解析的？非参数化则认为是通过实验记录到的模型，不存在解析表达式。  </p>\n<p>Stacked Hourglass Networks<br><a href=\"https://blog.csdn.net/wangzi371312/article/details/81174452\">资料一</a><br><a href=\"https://blog.csdn.net/shenxiaolu1984/article/details/51428392\">资料二</a></p>\n<p><a href=\"https://blog.csdn.net/dengheCSDN/article/details/77848246\">feature map</a><br>channel:<br>卷积核个数、特征图个数、通道个数关系</p>\n<p><a href=\"Learning to Estimate 3D Human Pose and Shape from a Single Color Image.pptx\">PPT</a></p>\n<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/Learning to Estimate 3D Human Pose and Shape from a Single Color Image.pptx' width=800 height=600 frameborder='1'></iframe>\n\n<h2 id=\"O-CNN-Octree-based-Convolutional-Neural-Networks-for-3D-Shape-Analysis\"><a href=\"#O-CNN-Octree-based-Convolutional-Neural-Networks-for-3D-Shape-Analysis\" class=\"headerlink\" title=\"O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis\"></a>O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis</h2><p>还有adaptive o-cnn<br>The main technical challenge of the O-CNN is to parallelize the O-CNN computations defined on the sparse octants so that they can be efficiently executed on the GPU<br>We train this O-CNN model with 3D shape datasets and refine the O-CNN models with different back-ends for three shape analysis tasks, including object classification, shape retrieval, and shape segmentation.</p>\n<h2 id=\"Pixel2Mesh（讲）\"><a href=\"#Pixel2Mesh（讲）\" class=\"headerlink\" title=\"Pixel2Mesh（讲）\"></a>Pixel2Mesh（讲）</h2><h3 id=\"code\"><a href=\"#code\" class=\"headerlink\" title=\"code\"></a>code</h3><p>编译tensorflow math_functions.hpp找不到。需要软链接这个玩意<br>ln -s /usr/local/cuda/include/crt/math_functions.hpp /usr/local/cuda/include/math_functions.hpp  </p>\n<p>关于eigen和cuda<a href=\"https://blog.csdn.net/O1_1O/article/details/80066236\">资料</a><br>makefile怎么写。<br>hdf5 HDF（Hierarchical Data Format）是一种设计用于存储和组织大量数据的文件格式</p>\n<p><strong>CUDACC_VER</strong> is no longer supported.的报错看来要更新<a href=\"https://blog.csdn.net/luojie140/article/details/80159227\">eigen3</a>才能解决<br>github上新版eigen考到anaconda的eigen和support里就可以成功编译cuda了</p>\n<p>图卷积神经网络<a href=\"http://tkipf.github.io/graph-convolutional-networks/\">资料</a><br>图卷积神经网络<a href=\"https://cloud.tencent.com/developer/news/330322\">材料</a><br><strong>所有的卷积都是在探讨如何对局部数据按照某一个操作聚合，不同的操作方式就对应于不同的卷积。</strong>学习卷积核的过程其实是学习局部聚合参数的过程</p>\n<p><a href=\"pixel2mesh.pptx\">PPT</a></p>\n<iframe src='https://view.officeapps.live.com/op/view.aspx?src=https://taye310.github.io/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/pixel2mesh.pptx' width=800 height=600 frameborder='1'></iframe>\n\n<h2 id=\"SMPL-A-Skinned-Multi-Person-Linear-Model-多篇基础，15年\"><a href=\"#SMPL-A-Skinned-Multi-Person-Linear-Model-多篇基础，15年\" class=\"headerlink\" title=\"SMPL: A Skinned Multi-Person Linear Model(多篇基础，15年)\"></a>SMPL: A Skinned Multi-Person Linear Model(多篇基础，15年)</h2><h2 id=\"Video-Based-Reconstruction-of-3D-People-Models-讲，没用网络-DOI-10-1109-CVPR-2018-00875-video2mesh\"><a href=\"#Video-Based-Reconstruction-of-3D-People-Models-讲，没用网络-DOI-10-1109-CVPR-2018-00875-video2mesh\" class=\"headerlink\" title=\"Video Based Reconstruction of 3D People Models(讲，没用网络) DOI:10.1109/CVPR.2018.00875 (video2mesh)\"></a>Video Based Reconstruction of 3D People Models(讲，没用网络) DOI:10.1109/CVPR.2018.00875 (video2mesh)</h2><p>第五页第一张图解决了人体非刚性的问题<br>但是问题在于人必须转身后摆出相同的姿势 不允许姿势变化<br>第二张图 可以随意动 不同时刻的深度图非张性的注册并融合到一个template上<br>存在 phantom surface的问题 运动的快会四肢胳膊 两个头<br>第三个 加了一个static的人体模型作为约束 运动速度可以更快  </p>\n<p>第一个使用rgb相机 并且支持用户运动的重建方法<br>主要思想 和visual hull相似 不同角度拍摄剪影进行重建<br>visual hull的基本原理 几个角度拍摄 分割出前景得到silhouette<br>然后从相机坐标到silhouette的每一个点可以做一条射线 形成的曲面成为silhouette cone<br>用这些cone作为约束就可以重建出三维模型 可以类比为雕刻的过程<br>去掉cone之外的部分 最终剩下的部分就是人体的形状  </p>\n<p>标准的vh的问题是只能用于静态的物体 这篇的主要是讲怎么把vh用到动态的物体<br>第八页 每帧姿势都不一样 要做的就是去除由于运动对cone造成的变化 称为unpose的过程<br>用unpose的cone做三维重建  </p>\n<p>使用的人体的三维表达：smpl 参数化模型 T是template的mean shape，Bs是体型变化造成的模型变化<br>Bp是pose的变化带来的变化<br>问题在于没有办法model衣服头发面部特征 基础上加了D offset用于表达smpl表达不了的信息  </p>\n<p>四个步骤<br>1 前景分割 获取silhouette cone， tracking获取人体模型的姿态<br>2 利用pose信息做unpose操作 转到Tpose姿态下<br>3 人体重建 包含衣服 头发 人脸的人体模型<br>4 多视角图像生成人体贴图  </p>\n<p>1 基于cnn的方法 2d drawn detection 图像分割的方法 前景分割生成silhouette<br>优化第12页的能量函数 进行pose tracking //简单来说就是求最优的pose和shape的参数 和模型匹配到检测到的<br>2d drawn detection和silhouette上//<br>2 第一步得到的cone进行unpose 每一条射线进行unpose转到canonical pose下<br>//两个数学表达式 射线的转换//<br>任何一点vi 和 任何一条射线ri<br>3 利用unpose后的cone做三维重建 称为consensus shape，相比较SMPL/视频表现出的是可以对衣服进行重建<br>过程可以通过优化一个能量公式实现<br>Edata：模型上的点到unpose ray的距离<br>三个正则项：lap保证局部光滑，body保证重建出的与smpl差距不大，symm保证左右对称<br>4 有了几何信息后 生成appearance信息 生成texture map 第一步有每一帧的pose，精确的将模型覆盖到图像上<br>通过//重投影获得贴图//  </p>\n<p>用sfs（之前的文章有提到）可以提供更多细节，本文方法可以提高的地方<br>对<strong>能量函数</strong>的理解：构建能量函数就是我们用方程的最小值来描述我们想要达到的实际效果。<a href=\"https://blog.csdn.net/a6333230/article/details/80070586\">资料</a></p>\n<p>第一步最费时间 一帧一分钟 model和silhouette的匹配费时间<br>穿裙子解决不了 改变不了smplmodel的拓扑结构 拉不过去<br>基于cnn的分割已经接近于完美了 用的别人的方法 不是重点<br>给纹理图上色：consensus shape 结合第一步的pose 精确匹配到每一帧的图像上 back projection  </p>\n\n\n\t<div class=\"row\">\n    <embed src=\"videobasedreconstructionof3dpeoplemodelsGAMES201850徐维鹏.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n\n<p><a href=\"videobasedreconstructionof3dpeoplemodelsGAMES201850徐维鹏.pdf\">ppt</a></p>\n<h2 id=\"Learning-to-Reconstruct-People-in-Clothing-from-a-Single-RGB-Camera（2019-4video2mesh延伸论文，同一实验室）octopus\"><a href=\"#Learning-to-Reconstruct-People-in-Clothing-from-a-Single-RGB-Camera（2019-4video2mesh延伸论文，同一实验室）octopus\" class=\"headerlink\" title=\"Learning to Reconstruct People in Clothing from a Single RGB Camera（2019.4video2mesh延伸论文，同一实验室）octopus\"></a>Learning to Reconstruct People in Clothing from a Single RGB Camera（2019.4video2mesh延伸论文，同一实验室）octopus</h2><p>安装dirt遇到的问题：<a href=\"https://github.com/pmh47/dirt/issues/23\">https://github.com/pmh47/dirt/issues/23</a><br>已经尝试过cuda10.1/10.0/9.2 cudnn都是对应版本，tensorflow单独测试成功<br>更改gcc/g++版本：<a href=\"https://blog.csdn.net/u012925946/article/details/84584830\">https://blog.csdn.net/u012925946/article/details/84584830</a></p>\n<p>最终安装dirt解决方法是：<br>ubuntu 18.04，cuda 8.0，cudnn 6.0，tf 1.4.0，driver 396.54<br>注意conda install 的 cudatoolkit和cudnn不能取代本机安装的cuda和cudnn，也就是说本机要安cuda，cudnn，conda装tf时要装cudatoolkit，cudnn  </p>\n<p>先装tensorflow再装-gpu 才能启用gpu 前者版本不能比后者高，libcudnn.so.x报错需要在conda里安装tf，tf-gpu。注意版本匹配</p>\n<p>跑Octopus的实验时需要<br>scipy&gt;=1.0.0<br>numpy&gt;=1.16<br>Keras&gt;=2.2.0<br>tensorflow_gpu&gt;=1.11.0<br>dirt<br>否则会报：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(video2mesh) ty@ty-GE60-2PF:~/repos/octopus$ bash run_batch_demo.sh </span><br><span class=\"line\">Using TensorFlow backend.</span><br><span class=\"line\">2019-05-29 15:18:24.784883: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class=\"line\">2019-05-29 15:18:24.835566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node <span class=\"built_in\">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class=\"line\">2019-05-29 15:18:24.835835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: </span><br><span class=\"line\">name: GeForce GTX 860M major: 5 minor: 0 memoryClockRate(GHz): 1.0195</span><br><span class=\"line\">pciBusID: 0000:01:00.0</span><br><span class=\"line\">totalMemory: 1.96GiB freeMemory: 1.08GiB</span><br><span class=\"line\">2019-05-29 15:18:24.835855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)</span><br><span class=\"line\">Processing sample...</span><br><span class=\"line\">&gt; Optimizing <span class=\"keyword\">for</span> pose...</span><br><span class=\"line\">  0%|          | 0/10 [00:00&lt;?, ?it/s]</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">&quot;infer_batch.py&quot;</span>, line 87, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    main(args.weights, args.num, args.batch_file, args.opt_steps_pose, args.opt_steps_shape)</span><br><span class=\"line\">  File <span class=\"string\">&quot;infer_batch.py&quot;</span>, line 46, <span class=\"keyword\">in</span> main</span><br><span class=\"line\">    model.opt_pose(segmentations, joints_2d, opt_steps=opt_pose_steps)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/repos/octopus/model/octopus.py&quot;</span>, line 290, <span class=\"keyword\">in</span> opt_pose</span><br><span class=\"line\">    callbacks=[LambdaCallback(on_batch_end=lambda e, l: pbar.update(1))]</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/engine/training.py&quot;</span>, line 1010, <span class=\"keyword\">in</span> fit</span><br><span class=\"line\">    self._make_train_function()</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/engine/training.py&quot;</span>, line 509, <span class=\"keyword\">in</span> _make_train_function</span><br><span class=\"line\">    loss=self.total_loss)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/legacy/interfaces.py&quot;</span>, line 91, <span class=\"keyword\">in</span> wrapper</span><br><span class=\"line\">    <span class=\"built_in\">return</span> func(*args, **kwargs)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/optimizers.py&quot;</span>, line 475, <span class=\"keyword\">in</span> get_updates</span><br><span class=\"line\">    grads = self.get_gradients(loss, params)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/optimizers.py&quot;</span>, line 89, <span class=\"keyword\">in</span> get_gradients</span><br><span class=\"line\">    grads = K.gradients(loss, params)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py&quot;</span>, line 2757, <span class=\"keyword\">in</span> gradients</span><br><span class=\"line\">    <span class=\"built_in\">return</span> tf.gradients(loss, variables, colocate_gradients_with_ops=True)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/ty/anaconda3/envs/video2mesh/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py&quot;</span>, line 555, <span class=\"keyword\">in</span> gradients</span><br><span class=\"line\">    (op.name, op.type))</span><br><span class=\"line\">LookupError: No gradient defined <span class=\"keyword\">for</span> operation <span class=\"string\">&#x27;smpl_body25face_layer_1_7/smpl_main/Svd&#x27;</span> (op <span class=\"built_in\">type</span>: Svd)</span><br></pre></td></tr></table></figure></p>\n<p>显卡驱动还崩了 用ubuntu自带的怎么切驱动nvidia-smi都会报一行错<br>NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed<br>and running.<br>然后切不懂了卡在390 有这个问题<a href=\"https://askubuntu.com/questions/1035409/installing-nvidia-drivers-on-18-04\">https://askubuntu.com/questions/1035409/installing-nvidia-drivers-on-18-04</a>  </p>\n<p>2019.6.4 <a href=\"https://github.com/pmh47/dirt/issues/6\">https://github.com/pmh47/dirt/issues/6</a> dirt inside cmakecache.txt add -DNDEBUG to CMAKE_CUDA_FLAGS:STRING</p>\n<p><a href=\"https://github.com/pmh47/dirt/issues/23\">https://github.com/pmh47/dirt/issues/23</a><br>tensorflow.python.framework.errors_impl.NotFoundError: /home/ty/repos/dirt/dirt/librasterise.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs</p>\n<p>should not use conda install tensorflow &amp; tensorflow-gpu, use pip install instead</p>\n<p>nvidia driver keeps the newest one.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(dirt) zhangtianyi@likun-ThinkStation:~/github/dirt$ python tests/square_test.py </span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">&quot;tests/square_test.py&quot;</span>, line 4, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    import dirt</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/zhangtianyi/github/dirt/dirt/__init__.py&quot;</span>, line 2, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    from .rasterise_ops import rasterise, rasterise_batch, rasterise_deferred, rasterise_batch_deferred</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/zhangtianyi/github/dirt/dirt/rasterise_ops.py&quot;</span>, line 6, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    _rasterise_module = tf.load_op_library(_lib_path + <span class=\"string\">&#x27;/librasterise.so&#x27;</span>)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/zhangtianyi/anaconda3/envs/dirt/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py&quot;</span>, line 61, <span class=\"keyword\">in</span> load_op_library</span><br><span class=\"line\">    lib_handle = py_tf.TF_LoadLibrary(library_filename)</span><br><span class=\"line\">tensorflow.python.framework.errors_impl.NotFoundError: /home/zhangtianyi/github/dirt/dirt/librasterise.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>成功安装后test时出现上边的问题 -d_glibcxx_use_cxx11_abi=0改成1 gcc/g++版本从4.9换到5重装dirt就好了</p>\n<p>总结：py2.7 tf1.13.2 cuda 显卡驱动装新的</p>\n<ol>\n<li>setup.py里的dependence去掉用conda装</li>\n<li>cmakelists.txt cmake_flag 加-d_glibcxx_use_cxx11_abi=1</li>\n<li>change CMakeLists.txt line5 into<br><code>find_package(OpenGL REQUIRED COMPONENTS OpenGL EGL)</code><br>comment line9<br>line53 into<br><code>target_link_libraries(rasterise OpenGL::OpenGL OpenGL::EGL $&#123;Tensorflow_LINK_FLAGS&#125;)</code><br>As a hack, you can try directly linking the correct library: remove EGL from line 5 of CMakeLists (so FindOpenGL no longer searches for it), and at line 52, replace OpenGL::EGL by /usr/lib/nvidia-384/libEGL.so.1.1.0 </li>\n<li>cmake ../csrc -D_OPENGL_LIB_PATH=/usr/lib/nvidia-390. 对应驱动版本</li>\n<li>cmakecache.txt 加-dndebug</li>\n<li>make</li>\n<li>cd .. \\ pip install -e .</li>\n<li>tests</li>\n</ol>\n<p><strong>笔记本会卡死！！！</strong></p>\n<h2 id=\"Neural-Body-Fitting-Unifying-Deep-Learning-and-Model-Based-Human-Pose-and-Shape-Estimation（3DV-2018）\"><a href=\"#Neural-Body-Fitting-Unifying-Deep-Learning-and-Model-Based-Human-Pose-and-Shape-Estimation（3DV-2018）\" class=\"headerlink\" title=\"Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation（3DV 2018）\"></a>Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation（3DV 2018）</h2><h3 id=\"intro\"><a href=\"#intro\" class=\"headerlink\" title=\"intro\"></a>intro</h3><p>已经有很多成功的工作，生成人体关键点，棒状表示模型（火柴人）（说的就是openpose）<br>这里作者提出的是基于smpl的更具挑战性的任务：estimating the parameters of a detailed statistical human body model from a single image  </p>\n<p>Traditional model-based approaches typically optimize an objective function that measures how well the model fits the image observations<br>传统的需要一个差不多初始化模型，然后把初值优化到最终结果（不需要3d训练数据——带3d动作标注的图片）<br>CNN就是forward prediction models，就不需要initialization，但是需要3d姿态标注，不像2d标注好获得  </p>\n<p>他们近期的工作通过把重建出的模型投影回2d空间更新损失函数，就可以使用2d标注了<br>本文的<strong>目的</strong>：To analyze the importance of such components<br>components: image—(CNN,3d notation trained)—&gt;smpl model(hybird params)—&gt;image—(reproject)—&gt;2d notation for CNN training<br>要形成闭环（loop）<br>NBF = 一个包含统计身体模型的CNN<br>两种监督模式：full 3d sup和weak 2d sup，bottom-up top-down的方法，使得NBF既不需要初始化模型也不需要3d标注的训练数据<br>因为光照、衣服、杂乱的背景都不想要，专注于pose和shape，所以用处理后的image代替原始rgb image<br>结论：</p>\n<ol>\n<li>12-body-part的分割就包含了足够的shape和pose信息</li>\n<li>这种处理后图像的方法比起用原图，效果有竞争力，更简单，训练数据利用率更高</li>\n<li>分割质量可以强有力预测fit质量</li>\n</ol>\n<p>总结：</p>\n<ol>\n<li>unites deep learning-based with traditional model-based methods</li>\n<li>an in-depth analysis of the necessary components to achieve good performance in hybrid architectures and provide insights for its real-world applicability</li>\n</ol>\n<h3 id=\"related-work\"><a href=\"#related-work\" class=\"headerlink\" title=\"related work\"></a>related work</h3><p>Most model-based approaches fit a model to image evidence through complex non-linear optimization, requiring careful initialization to avoid poor local minima.<br>用2d关键点是为了降低fitting复杂度<br>lifting to 3D from 2D information alone is an ambiguous problem  </p>\n<p>前人的工作有用rgb image的/image+2d keypoint的/2d keypoint+silhouette的<br>NBF不需要初始化模型，用semantic segmentation做图片代理输入，原因有三：</p>\n<ol>\n<li>去除与3dpose无关的图像信息</li>\n<li>比keypoint和silhouette语义信息多</li>\n<li>允许分析精细程度（粒度）和placement对3d预测的重要程度</li>\n</ol>\n<p>三个数据集UP-3D，HumanEva-I，Human3.6M<br>\n\n\t<div class=\"row\">\n    <embed src=\"19.6.25_weekly_report.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n<br>三个数据集<a href=\"http://files.is.tuebingen.mpg.de/classner/up/\">UP-3D</a>,<br><a href=\"http://humaneva.is.tue.mpg.de/datasets_human_1\">HumanEva-I</a>,<br><a href=\"http://vision.imar.ro/human3.6m/description.php\">Human3.6M</a>  </p>\n<p>up-3d有大量smpl形式的3d标注</p>\n<p>其他数据集：</p>\n<p><strong>HumanEva-I使用方法</strong>：<br>To be able to use HumanEva-I dataset you must do the following:<br>  Sing up and agree with the license or Login if you already have an account.<br>  Download the entire HumanEva-I dataset as either zip or tar archive depending on your system.<br>  Download critical HumanEva-I update and update the OFS files.<br>  Download the latest source code.<br>  (optional) Download background statistics<br>  (optional) Download the surface model for subject S4.   </p>\n<p>装matlab, XVID codec, DXAVI toolbox, Camera Calibration Toolbox for Matlab<br>给matlab指定了mingw作为c++编译器  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Undefined <span class=\"keyword\">function</span> or variable <span class=\"string\">&#x27;dxAviOpenMex&#x27;</span>.</span><br><span class=\"line\"></span><br><span class=\"line\">Error <span class=\"keyword\">in</span> dxAviOpen (line 3)</span><br><span class=\"line\">\t[hdl, t] = dxAviOpenMex(fname);</span><br><span class=\"line\"></span><br><span class=\"line\">Error <span class=\"keyword\">in</span> testDxAvi (line 4)</span><br><span class=\"line\">[avi_hdl, avi_inf] = dxAviOpen([pathname, filename]);</span><br></pre></td></tr></table></figure>\n<p>运行mex_cmd出现</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">F:\\datasets\\HumanEva-I\\Release_Code_v1_1_beta\\TOOLBOX_dxAvi\\dxAviHelper.h:9:21: fatal error: atlbase.h: No such file or directory</span><br><span class=\"line\"> <span class=\"comment\">#include &lt;atlbase.h&gt;</span></span><br></pre></td></tr></table></figure>\n<p>应该是没有这个库的原因，有说是visual studio的库，打算装个vs2019 ATL库试试<br>matlab不支持2019 mex -setup -v可以看到指搜索到vs2017<br>所以装了vs2015，atlbase就可以了<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Building with <span class=\"string\">&#x27;Microsoft Visual C++ 2015&#x27;</span>.</span><br><span class=\"line\">Error using mex</span><br><span class=\"line\">dxAviOpenMex.cpp</span><br><span class=\"line\">BaseClasses\\ctlutil.h(278): error C4430: missing <span class=\"built_in\">type</span> specifier - int assumed. Note: C++ does not support default-int</span><br><span class=\"line\">g:\\grads\\3dreconstruction\\humaneva-i\\release_code_v1_1_beta\\toolbox_dxavi\\dxAviHelper.h(15): fatal error C1083: Cannot open</span><br><span class=\"line\">include file: <span class=\"string\">&#x27;qedit.h&#x27;</span>: No such file or directory</span><br></pre></td></tr></table></figure></p>\n<p>原因在这里<a href=\"https://github.com/facebookresearch/VideoPose3D/blob/master/DATASETS.md\">link</a></p>\n<p>github上找了win64编译好的.m脚本，解决。 </p>\n<p><strong>todo</strong> 怎么做validation  </p>\n<h1 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h1><h2 id=\"复原实验\"><a href=\"#复原实验\" class=\"headerlink\" title=\"复原实验\"></a>复原实验</h2><ol>\n<li>Extreme 3D Face Reconstruction: Seeing Through Occlusions <a href=\"https://github.com/anhttran/extreme_3d_faces\">Github</a><ol>\n<li>环境：linux docker镜像</li>\n<li>依赖：<ul>\n<li>our Bump-CNN</li>\n<li>our PyTorch CNN model</li>\n<li>the Basel Face Model</li>\n<li>3DDFA Expression Model</li>\n<li>3DMM_model</li>\n<li>dlib face prediction model</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>Learning to Reconstruct People in Clothing from a Single RGB Camera <a href=\"https://github.com/thmoa/octopus\">Github</a><ol>\n<li>环境：linux tf</li>\n<li>依赖：<ul>\n<li><a href=\"https://github.com/pmh47/dirt\">DIRT</a></li>\n<li><a href=\"http://smplify.is.tue.mpg.de/\">SMPL model</a></li>\n<li><em><a href=\"https://drive.google.com/open?id=1_CwZo4i48t1TxIlIuUX3JDo6K7QdYI5r\">pre-trained model weights</a></em></li>\n</ul>\n</li>\n<li>备注：图片预处理需要<ul>\n<li>PGN semantic segmentation：Linux/tensorflow <a href=\"https://github.com/Engineering-Course/CIHP_PGN\">Code</a></li>\n<li>OpenPose body_25 and face keypoint detection：Win <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose\">.exe</a></li>\n</ul>\n</li>\n</ol>\n</li>\n<li>Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation <a href=\"https://github.com/mohomran/neural_body_fitting\">Github</a><ol>\n<li>环境：win/linux tensorflow-gpu==1.6.0</li>\n<li>依赖：<ul>\n<li><a href=\"http://smpl.is.tue.mpg.de/downloads\">SMPL model(跟上边的还有区别)</a></li>\n<li><a href=\"http://transfer.d2.mpi-inf.mpg.de/mohomran/nbf/refinenet_up.tgz\">segmentation model</a></li>\n<li><a href=\"http://transfer.d2.mpi-inf.mpg.de/mohomran/nbf/demo_up.tgz\">fitting model</a></li>\n</ul>\n</li>\n<li>备注：没training code</li>\n</ol>\n</li>\n<li>tex2shape：</li>\n<li>hmr</li>\n<li>hmd</li>\n<li>shift-net</li>\n</ol>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h2><ol>\n<li>HumanEva-I<ol>\n<li>环境：win/linux matlab</li>\n<li>依赖：几个toolbox其中dxavi用的github上编译好的.m</li>\n</ol>\n</li>\n<li>UP-3D<ol>\n<li>环境：</li>\n<li>依赖：</li>\n</ol>\n</li>\n<li>Human3.6M<ol>\n<li>注册不通过（20190716）</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"repos\"><a href=\"#repos\" class=\"headerlink\" title=\"repos\"></a>repos</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">repo name</th>\n<th style=\"text-align:left\">description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">VideoPose3D</td>\n<td style=\"text-align:left\">3D human pose estimation in video with temporal convolutions and semi-supervised training</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">smplify-x</td>\n<td style=\"text-align:left\">Expressive Body Capture: 3D Hands, Face, and Body from a Single Image</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">neural_body_fitting</td>\n<td style=\"text-align:left\">Neural Body Fitting code repository</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">octopus</td>\n<td style=\"text-align:left\">Learning to Reconstruct People in Clothing from a Single RGB Camera</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">videoavatars</td>\n<td style=\"text-align:left\">Video based reconstruction of 3D people models</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">extreme_3d_faces</td>\n<td style=\"text-align:left\">Extreme 3D Face Reconstruction: Seeing Through Occlusions</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3Dpose_ssl</td>\n<td style=\"text-align:left\">3D Human Pose Machines with Self-supervised Learning</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">pose-hg-train</td>\n<td style=\"text-align:left\">Training and experimentation code used for “Stacked Hourglass Networks for Human Pose Estimation”</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">PRNet</td>\n<td style=\"text-align:left\">Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network (ECCV 2018)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">vrn</td>\n<td style=\"text-align:left\">Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">openpose</td>\n<td style=\"text-align:left\">OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"Code\"><a href=\"#Code\" class=\"headerlink\" title=\"Code\"></a>Code</h1><p>vscode想在不同的conda环境下都有类型提示和跳转需要在vscode里切环境<br>ctrl+shift+P —&gt; python:select interpreter —&gt; {your env}<br><a href=\"https://code.visualstudio.com/docs/python/environments\">官方文档</a>  </p>\n<p>import tensorflow 没有报错也没有反应：tensorflow-gpu跟conda安装的opencv有冲突！！<br>改用<code>pip install opencv-python</code>就解决了  </p>\n<p>同文件夹下module import要加<code>.</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> .batch_smpl <span class=\"keyword\">import</span> SMPL</span><br><span class=\"line\"><span class=\"keyword\">from</span> .joints <span class=\"keyword\">import</span> joints_body25, face_landmarks</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.engine.topology <span class=\"keyword\">import</span> Layer</span><br></pre></td></tr></table></figure></p>\n<p>git-lfs在fork的repo上使用会有问题 “can not upload new objects to public fork”</p>\n<h2 id=\"python-module\"><a href=\"#python-module\" class=\"headerlink\" title=\"python module\"></a>python module</h2><p>tqdm: process bar tool<br>greenlet/gevent: 协程工具</p>\n<h2 id=\"octopus\"><a href=\"#octopus\" class=\"headerlink\" title=\"octopus\"></a>octopus</h2><blockquote>\n<p>流程：<br>读文件（segmentation/pose） png和json文件<br>K.set_session启动tfsession<br>声明model（octopus），加载weights<br>解析segm：io.py里有解析segmentation的方法<br>解析pose<br>优化pose<br>优化shape<br>生成模型（点和面的list）<br>写入obj（write_mesh）  </p>\n<p>opt_pose:<br>两组数据: data/supervision<br>opt_pose_model.fit():</p>\n<ul>\n<li></li>\n</ul>\n<p>opt_shape:<br>data/supervision<br>opt_shape_model.fit()</p>\n</blockquote>\n<p>想尝试把dirt换了，用别的differentiable renderer</p>\n<h2 id=\"tex2shape\"><a href=\"#tex2shape\" class=\"headerlink\" title=\"tex2shape\"></a>tex2shape</h2><p>decectron2（pytorch环境）先做uv图<br>tex2shape出模型，因为显存不够影响了重建效果（用video2mesh的conda环境就可以（tensorflow+keras））<br>目前的代码是否可以训练模型，hdf5文件怎么生成（keras的hdf5文件，就是tf的ckpt，model.save就完事了，现在主要问题是fit train data）</p>\n<h2 id=\"hmr-End-to-end-Recovery-of-Human-Shape-and-Pose\"><a href=\"#hmr-End-to-end-Recovery-of-Human-Shape-and-Pose\" class=\"headerlink\" title=\"hmr End-to-end Recovery of Human Shape and Pose\"></a>hmr End-to-end Recovery of Human Shape and Pose</h2><p>有train code，可他妈太妙了<br>数据预处理步骤：</p>\n<ul>\n<li>数据集lsp —&gt; tfrecord</li>\n<li></li>\n</ul>\n<h2 id=\"datasets\"><a href=\"#datasets\" class=\"headerlink\" title=\"datasets\"></a>datasets</h2><ul>\n<li><a href=\"http://sam.johnson.io/research/lsp_dataset.zip\">LSP</a> and <a href=\"http://sam.johnson.io/research/lspet_dataset.zip\">LSP extended</a></li>\n<li><a href=\"http://cocodataset.org/#download\">COCO</a> we used 2014 Train. You also need to<br>install the <a href=\"https://github.com/cocodataset/cocoapi\">COCO API</a> for python.</li>\n<li><a href=\"http://human-pose.mpi-inf.mpg.de/#download\">MPII</a></li>\n<li><a href=\"http://gvv.mpi-inf.mpg.de/3dhp-dataset/\">MPI-INF-3DHP</a></li>\n<li><a href=\"http://vision.imar.ro/human3.6m/description.php\">Human3.6M</a></li>\n<li><a href=\"https://drive.google.com/file/d/1b51RMzi_5DIHeYh2KNpgEs8LVaplZSRP/view?usp=sharing\">Download link to MoSh</a></li>\n</ul>\n<h3 id=\"训练数据预处理\"><a href=\"#训练数据预处理\" class=\"headerlink\" title=\"训练数据预处理\"></a>训练数据预处理</h3><p>TFRecord:数据序列化成二进制的工具</p>\n<h2 id=\"keras\"><a href=\"#keras\" class=\"headerlink\" title=\"keras\"></a>keras</h2><p><code>keras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)</code><br>Wraps arbitrary expression as a <em>Layer</em> object.</p>\n<p>keras.backend: At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.</p>\n<p>LambdaCallback()  </p>\n<h2 id=\"要解决的问题\"><a href=\"#要解决的问题\" class=\"headerlink\" title=\"要解决的问题\"></a>要解决的问题</h2><ol>\n<li>现有数据集的数据怎么处理到能用在smpl上 ！！（解决 hmr里解决了训练数据—&gt;tfrecord的过程）</li>\n<li>确定量化指标 ！！（解决 hmr有evaluation）</li>\n<li>确定遮挡情况下的重建效果！！（hmr，tex2shape，octopus，360texture那个）</li>\n</ol>\n<h2 id=\"实验室-作者汇总\"><a href=\"#实验室-作者汇总\" class=\"headerlink\" title=\"实验室/作者汇总\"></a>实验室/作者汇总</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">名称</th>\n<th style=\"text-align:left\">文章</th>\n<th style=\"text-align:left\">链接</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">MPI</td>\n<td style=\"text-align:left\">SMPL/Octopus/..</td>\n<td style=\"text-align:left\"><a href=\"https://virtualhumans.mpi-inf.mpg.de/\">https://virtualhumans.mpi-inf.mpg.de/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">UCB(Angjoo Kanazawa)</td>\n<td style=\"text-align:left\">预测人体动作/动物形体重建</td>\n<td style=\"text-align:left\"><a href=\"https://people.eecs.berkeley.edu/~kanazawa/\">https://people.eecs.berkeley.edu/~kanazawa/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">周晓巍(浙大)</td>\n<td style=\"text-align:left\">..</td>\n<td style=\"text-align:left\"><a href=\"http://www.cad.zju.edu.cn/home/xzhou/\">http://www.cad.zju.edu.cn/home/xzhou/</a></td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"技术要点汇总\"><a href=\"#技术要点汇总\" class=\"headerlink\" title=\"技术要点汇总\"></a>技术要点汇总</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">文章名称</th>\n<th style=\"text-align:left\">完成任务</th>\n<th style=\"text-align:left\">技术要点描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">end to end recovery of human shape and pose(HMR)</td>\n<td style=\"text-align:left\">an end-to-end framework for reconstructing a full 3D mesh of a human body from a single RGB image 不知道速度怎么样，其他的有做到实时的了</td>\n<td style=\"text-align:left\">不计算2d/3d joint position，使用了一种高效的mesh representation parameterized by shape and joint angles</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">hmd</td>\n<td style=\"text-align:left\">分阶段deformation</td>\n<td style=\"text-align:left\">hmr做基础模型，找到joint，anchor关键点deformation，在产生个深度图做vertex级别的deformation</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">deephuman</td>\n<td style=\"text-align:left\">不用smpl，直接从image用cnn还原三维结构</td>\n<td style=\"text-align:left\">用了带语义的三维信息semantic volume</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">bodynet</td>\n<td style=\"text-align:left\">不用smpl</td>\n<td style=\"text-align:left\">hmd里提到的，不用smpl，用cnn找joint找sil构建3d pose再用cnn构建volumetric shape，用smpl监督算一个3d loss。总之就是多loss联合监督回归三维体积</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Deep Textured 3D Reconstruction of Human Bodies</td>\n<td style=\"text-align:left\">不用smpl</td>\n<td style=\"text-align:left\">hmd里提到的</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">double fusion</td>\n<td style=\"text-align:left\">用的单个深度摄像头，做到实时三维人体重建</td>\n<td style=\"text-align:left\">内外两层模型，里边是smpl外层可以根据深度信息较大幅度的拟合RGB图像</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">hyperfusion</td>\n<td style=\"text-align:left\">单个深度摄像头+IMUs 惯性测量</td>\n<td style=\"text-align:left\">在处理快速动作，遮挡情况比df更好，这俩重点在于捕捉连贯动作</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Learning to Reconstruct People in Clothing from a Single RGB Camera(Octopus)</td>\n<td style=\"text-align:left\">视频1-8帧做人体重建，10秒完成（说是速度快，但是其他的有做到实时的了）</td>\n<td style=\"text-align:left\">速度快归功于两点：Tpose下完成特征融合；using both, bottom-up and top-down streams（？？不理解回头看看）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Tex2Shape: Detailed Full Human Body Geometry from a Single Image</td>\n<td style=\"text-align:left\">单图重建模型，用了detectron的densepose对图像预处理出IUV图，然后根据原图+IUV图出模型</td>\n<td style=\"text-align:left\">前置条件detectron/densepose/smpl</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Multi-Garment Net: Learning to Dress 3D People from Images</td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Learning to Estimate 3D Human Pose and Shape from a Single Color Image</td>\n<td style=\"text-align:left\">周晓巍</td>\n<td style=\"text-align:left\">跟hmr差不多 hmr用了个判别器，这个用三维模型投影回二维平面做监督</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Learning 3D Human Dynamics from Video</td>\n<td style=\"text-align:left\">single image预测人体3D past and future motion</td>\n<td style=\"text-align:left\">present a framework that can similarly learn a representation of 3D dynamics of humans from video via a simple but effective temporal encoding of image features</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Predicting 3D Human Dynamics from Video</td>\n<td style=\"text-align:left\">跟上边都是UCB的Predicting Human Dynamics (PHD), a neural autoregressive model that takes a video sequence of a person as input to predict the future 3D human mesh motion</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">LiveCap:Real-time Human Performance Capture from Monocular Video</td>\n<td style=\"text-align:left\">the first real-time human performance capture approach that reconstructs dense, space-time coherent deforming geometry of entire humans in general everyday clothing from just a single RGB video</td>\n<td style=\"text-align:left\">应该是预处理阶段重建模型（需要花费时间），实时添加动作。重点解决两个非线性优化问题，提出两阶段（stage）解决思路</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images “In the Wild”</td>\n<td style=\"text-align:left\">不需要图像分割/关节点标注的动物模型重建</td>\n<td style=\"text-align:left\">SMAL</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation</td>\n<td style=\"text-align:left\">对象姿态估计旨在检测对象并估计其相对于规范框架的方向和平移</td>\n<td style=\"text-align:left\">PVNet predicts unit vectors that represent directions from each pixel of the object towards the keypoints. These directions then vote for the keypoint locations based on RANSAC//vector-field presentation</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"实验规划\"><a href=\"#实验规划\" class=\"headerlink\" title=\"实验规划\"></a>实验规划</h2><blockquote>\n<ol>\n<li>hmr：End-to-end Recovery of Human Shape and Pose</li>\n<li>octopus 有模型 有纹理贴图 用了Detailed Human Avatars from Monocular Video.的贴图方法</li>\n<li>tex2shape 这个有衣服的细节 试试有遮挡的情况下重建效果怎么样</li>\n<li>Learning 3D Human Dynamics from Video</li>\n<li>Multi-Garment Net: Learning to Dress 3D People from Images</li>\n<li>pvnet 遮挡截断情况下可以做6DoF Pose Estimation</li>\n</ol>\n</blockquote>\n<h2 id=\"周计划\"><a href=\"#周计划\" class=\"headerlink\" title=\"周计划\"></a>周计划</h2><p>2019.10.21</p>\n<ol>\n<li>现有数据集的数据怎么处理到能用在smpl上 ！！（hmr有dataset—&gt;tfrecord的code）</li>\n<li>确定量化指标 ！！ （hmr：跟3d groundtruth 点对点算距离，数据集human3.6m — 这东西不知道啥时候能下载）</li>\n</ol>\n<p>2019.10.28</p>\n<ol>\n<li>处理输入图片准备test（图片加遮挡，截断，运动模糊）</li>\n<li>hmr、octopus、tex2shape 进行test</li>\n<li>test结果进行量化评估</li>\n</ol>\n<p>2019.11.4</p>\n<ol>\n<li>复原结果汇总</li>\n<li>贴图怎么上</li>\n<li>量化指标</li>\n</ol>\n<p>2019.11.11</p>\n<ol>\n<li>训练code跑起来</li>\n<li>量化指标</li>\n</ol>\n<h2 id=\"日报\"><a href=\"#日报\" class=\"headerlink\" title=\"日报\"></a>日报</h2><h3 id=\"2019-10-28\"><a href=\"#2019-10-28\" class=\"headerlink\" title=\"2019.10.28\"></a>2019.10.28</h3><p>hmr，tex2shape环境部署<br>todo：处理输入图像，查看结果  </p>\n<h3 id=\"2019-10-29\"><a href=\"#2019-10-29\" class=\"headerlink\" title=\"2019.10.29\"></a>2019.10.29</h3><p>hmr结果已出，tex2shape需要densepose预处理图片，需要看看densepose对于遮挡，截断，运动模糊的处理情况<br>todo densepose结果查看  </p>\n<h3 id=\"2019-10-30\"><a href=\"#2019-10-30\" class=\"headerlink\" title=\"2019.10.30\"></a>2019.10.30</h3><p>detectron2可以用了，但是2提供的densepose的visualization mode不全，没有IUV，导致作为tex2shape的输入会有问题。还需要继续想办法<br>todo：hmr基本上没有细节，只有pose和大致shape，接下来要主要关注tex2shape在有遮挡的情况下细节重建的效果<br>找两个带贴图repo试试，octopus/garment/360<br>evaluation没有human3.6做不了，那边注册不通过没法下载  </p>\n<h3 id=\"2019-10-31\"><a href=\"#2019-10-31\" class=\"headerlink\" title=\"2019.10.31\"></a>2019.10.31</h3><p>摸鱼</p>\n<h3 id=\"2019-11-1\"><a href=\"#2019-11-1\" class=\"headerlink\" title=\"2019.11.1\"></a>2019.11.1</h3><p>detectron2里的densepose没法出IUV的图，不太明白IUV这个图怎么用opencv出。只能在densepose结果图上做遮挡看看tex2shape的重建效果了<br>完成hmr/tex2shape的遮挡测试，todo：octopus/还有smpl加贴图</p>\n<h3 id=\"2019-11-2-3\"><a href=\"#2019-11-2-3\" class=\"headerlink\" title=\"2019.11.2/3\"></a>2019.11.2/3</h3><p>休</p>\n<h3 id=\"2019-11-4\"><a href=\"#2019-11-4\" class=\"headerlink\" title=\"2019.11.4\"></a>2019.11.4</h3><p>dirt 有个undefined symbol 大概率是跟显卡驱动 cuda版本有关系 因为笔记本上就装上了<br>dirt装不上garment也没法跑，得想办法用opendr代替dirt<br>dirt装上后有个segmentfault 明天继续看<br>整理tex2shape/hmr/octopus的结果<br>明天看看贴图怎么搞，octopus用了个方法，还有garment那个的</p>\n<h3 id=\"2019-11-5\"><a href=\"#2019-11-5\" class=\"headerlink\" title=\"2019.11.5\"></a>2019.11.5</h3><p>octopus keras.base_layer会报个参数错误<br>densepose(tex2shape)不知道怎么出IUV<br>garment(上贴图的)用了MPI-IS的mesh组件 需要python3<br>TODO: humaneva, garment, Semantic Human Texture Stitching</p>\n<h3 id=\"2019-11-6\"><a href=\"#2019-11-6\" class=\"headerlink\" title=\"2019.11.6\"></a>2019.11.6</h3><p>量化指标：the mean per-pixel error of 3d displacements maps<br>中文叫位移贴图/与凹凸贴图（法线贴图属于凹凸图），高度图不同<br>贴图挺顺利的，理论上所有smpl的模型都适用。贴图这边接下来要看怎么用自己的数据（从img—&gt;pkl—&gt;texture）<br>octopus还是不行 操他妈的(keras outputs不是layer类型的，不知道为什么)（11.6更新：因为当时smpl()改成了smpl.call()，还是要走基类的<strong>call</strong>()的不然不是Layer类型）<br>Lambda表达式是核心问题 明天看</p>\n<h3 id=\"2019-11-7\"><a href=\"#2019-11-7\" class=\"headerlink\" title=\"2019.11.7\"></a>2019.11.7</h3><p>Octopus解决了，Lambda表达式没问题，smpl那个继承了Layer的类在调用<strong>call</strong>()时调用了call()，后者参数数量与基类Layer的call()参数数量不一致，导致了问题<br>hmr的训练需要groundtruth 3d，先放着吧<br>看effective C++(4/5)</p>\n<h3 id=\"2019-11-8\"><a href=\"#2019-11-8\" class=\"headerlink\" title=\"2019.11.8\"></a>2019.11.8</h3><p>数据集MPI_inf_3dhp/MPII/COCO 下载<br>下载数据集coco/mpii/mpi_inf_3dhp<br>学习dx12</p>\n<h3 id=\"2019-11-9-10\"><a href=\"#2019-11-9-10\" class=\"headerlink\" title=\"2019.11.9/10\"></a>2019.11.9/10</h3><p>休</p>\n<h3 id=\"2019-11-11\"><a href=\"#2019-11-11\" class=\"headerlink\" title=\"2019.11.11\"></a>2019.11.11</h3><p>coco/lsp/lsp_ext/mocap_neutrMosh/mpii/mpi_inf_3dhp —&gt; tfrecord<br>hmr train code在tf1.14上有问题 降到1.4试试（conda最低1.4） hmr官方用的1.3//客制的有pytorch0.4的<br>trainer.py的train()有问题 —&gt; sess.run时间太长了 1.4得调cuda版本 还是用1.14</p>\n<h3 id=\"2019-11-12\"><a href=\"#2019-11-12\" class=\"headerlink\" title=\"2019.11.12\"></a>2019.11.12</h3><p>三个新论文 看起来实验会好做一些 train code/dataset都有：</p>\n<ul>\n<li>PyTorch implementation of CloudWalk’s recent work DenseBody <a href=\"https://arxiv.org/pdf/1903.10153.pdf\">https://arxiv.org/pdf/1903.10153.pdf</a> <a href=\"https://github.com/Lotayou/densebody_pytorch\">github</a></li>\n<li>Repository for the paper “Convolutional Mesh Regression for Single-Image Human Shape Reconstruction” <a href=\"https://github.com/nkolot/GraphCMR\">github</a></li>\n<li>Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation (CVPR2019 Oral) <a href=\"https://github.com/zhuhao-nju/hmd\">github</a></li>\n</ul>\n<h3 id=\"2019-11-13\"><a href=\"#2019-11-13\" class=\"headerlink\" title=\"2019.11.13\"></a>2019.11.13</h3><p>看看十大排序七大查找算法（3-0）<br>hmd demo没啥问题 看看train 需要upi的数据集44g 这周五再下<br>evl的用了wild dataset 1.9g//RECON and SYN test</p>\n<h3 id=\"2019-11-14\"><a href=\"#2019-11-14\" class=\"headerlink\" title=\"2019.11.14\"></a>2019.11.14</h3><p>排序/查找算法</p>\n<h3 id=\"2019-11-15\"><a href=\"#2019-11-15\" class=\"headerlink\" title=\"2019.11.15\"></a>2019.11.15</h3><p>upi_s1h//human36m_washed//two test dataset for hmd(eval recon and syn sets//wild set)  </p>\n<h3 id=\"2019-11-16-17\"><a href=\"#2019-11-16-17\" class=\"headerlink\" title=\"2019.11.16/17\"></a>2019.11.16/17</h3><p>休</p>\n<h3 id=\"2019-11-18\"><a href=\"#2019-11-18\" class=\"headerlink\" title=\"2019.11.18\"></a>2019.11.18</h3><p>train without coco &amp; human3.6m coco需要联网用json下文件，实验室电脑没有那么多网关流量，human3.6m没数据集<br>train joint的时候dataloader的num有点问题 改成8035试试（worked）done<br>train anchor done<br>eval test doing<br>跑实验的同时看一下红黑树/B树/B+树  </p>\n<h3 id=\"2019-11-19\"><a href=\"#2019-11-19\" class=\"headerlink\" title=\"2019.11.19\"></a>2019.11.19</h3><p>eval完成<br>看hmd论文 <code>Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation</code></p>\n<h3 id=\"2019-11-20\"><a href=\"#2019-11-20\" class=\"headerlink\" title=\"2019.11.20\"></a>2019.11.20</h3><p>tex2shape的模型是有uv的 octopus/hmd都没有uv 所以没法贴图<br>加贴图那个基于octopus，需要绕着人转圈拍照片，然后做分割<br>eval_wild on self trained model（10hrs）<br>明天看看遮挡情况下hmd的重建效果</p>\n<h3 id=\"2019-11-21\"><a href=\"#2019-11-21\" class=\"headerlink\" title=\"2019.11.21\"></a>2019.11.21</h3><p>shell脚本里使用conda命令需要在conda activate前加上<br><code>source ~/anaconda3/etc/profile.d/conda.sh</code><br>遮挡情况下的hmd效果实验<br>eval_wild on self trained model（10hrs）（昨天优点问题 再来一遍） </p>\n<h3 id=\"2019-11-22\"><a href=\"#2019-11-22\" class=\"headerlink\" title=\"2019.11.22\"></a>2019.11.22</h3><p>确定目标 基于hmr和hmd做遮挡部分的重建<br>看hmd论文，研究hmd怎么加纹理细节的 </p>\n<h3 id=\"2019-11-23-24\"><a href=\"#2019-11-23-24\" class=\"headerlink\" title=\"2019.11.23/24\"></a>2019.11.23/24</h3><p>休</p>\n<h3 id=\"2019-11-25\"><a href=\"#2019-11-25\" class=\"headerlink\" title=\"2019.11.25\"></a>2019.11.25</h3><p>shadingnet: hmr 3d mesh —1-&gt; depth map —2-&gt; detailed depth map —3-&gt; detailed 3d mesh<br>hmd里是先shadingnet根据rgb image预测一个depthmap 然后加上mesh(openmesh + hmr smpl) 投影出的depthmap<br>Unet 输入rbg groundtruth depthmap 结果泛化能力差 所以再来个shadingnet loss是前边unet的depthmap loss 还有depth map重建成rbg 跟input的loss<br>需要解决的问题就是设计网络做第二步（doing sfsnet/3dmm/..）<br>先可视化一下depthmap（done）  </p>\n<p>joint和anchor都独立与shading的，在有rgb出了joint/anchor的前提下</p>\n<ol>\n<li>rgb做修复 然后经过shading net(pretrained) 加到project depth map上看结果  </li>\n<li>不处理的rgb 经过shading net(pretrained)生成depth map 然后在dm上做修复 最后加到project depth map上生成最终dm  </li>\n<li>建立端到端网络直接从未处理的rgb—&gt;修复完成的depth map，最后加上project depth map</li>\n</ol>\n<p>hmd的数据集刨除h36m应该有18000+ train set，现在只有9000+ 重新用脚本处理一遍</p>\n<p>numpy 高级索引 ndarray[x,y]//ndarray[a==b]</p>\n<h3 id=\"2019-11-26\"><a href=\"#2019-11-26\" class=\"headerlink\" title=\"2019.11.26\"></a>2019.11.26</h3><p>机器在处理数据（就是做hmd 里的 wild set）（coco做了7000+然后断开socket链接了，回头继续转）<br>问题转化为：有遮挡的rgb图生成完整的深度图的问题<br>DDRNet做的深度图重建。<br>试试<a href=\"https://github.com/iro-cp/FCRN-DepthPrediction.git\">Deeper Depth Prediction with Fully Convolutional Residual Networks (FCRN)</a><br>还有<a href=\"https://github.com/neycyanshi/DDRNet\">ddrnet</a>  </p>\n<p>王琛的方法，需要提供人体/遮挡的数据集（考虑下怎么做这个数据集），网络是现成的<br>三维人体重建转化到深度图的inpainting这样可以吗？？  </p>\n<p>更新ubuntu grub的引导会没 需要到win7下重设</p>\n<h3 id=\"2019-11-27\"><a href=\"#2019-11-27\" class=\"headerlink\" title=\"2019.11.27\"></a>2019.11.27</h3><p>coco数据集的hmd预处理还是有socket error，今晚挂上代理再试一次<br>问题：有遮挡的情况下恢复深度图的detail，还是考虑深度图质量差不多的情况下，深度图生成三维模型的精度<br>见今日周报 基本确定12月的工作内容  </p>\n<h3 id=\"2019-11-28\"><a href=\"#2019-11-28\" class=\"headerlink\" title=\"2019.11.28\"></a>2019.11.28</h3><p>固定像素位置加遮罩很容易（已完成），考虑往人体固定位置上加？<br>人体的数据集就18000+ 顶多了 看别人做inpainting的得有4/5w<br>监督数据怎么来？1. 通过hmd shading net出深度图；2. 找别的深度估计方法  </p>\n<h3 id=\"2019-11-29\"><a href=\"#2019-11-29\" class=\"headerlink\" title=\"2019.11.29\"></a>2019.11.29</h3><p>先用shadingnet的结果做gt吧，开始处理数据集</p>\n<h3 id=\"2019-11-30-1\"><a href=\"#2019-11-30-1\" class=\"headerlink\" title=\"2019.11.30/1\"></a>2019.11.30/1</h3><p>effective c++<br>休</p>\n<h3 id=\"2019-12-2\"><a href=\"#2019-12-2\" class=\"headerlink\" title=\"2019.12.2\"></a>2019.12.2</h3><p>生成depth ground truth 流程如下<br>img—&gt;hmr result（predict_hmr_dm 批处理hmd_2 18403张train img）—&gt;depth result（predict_hmd_dm 生成depth 到hmd_masked/train）<br>做depthmap的gt要150hrs。。？</p>\n<p>感觉没人做带遮挡的rgb到depth的映射(也就是inpainting和depth estimation的混合)<br>现有的depth estimation方法 pretrained的model对人体的效果极差 根本比不了hmd的shadingnet结果 见周报图<br>incomplete RGB —&gt; complete depth 做不动<br>incomplete RGB —&gt; incomplete depth —&gt; complete depth<br>想出incomplete depth还得150hrs<br>最后可能只能在深度图上做inpainting</p>\n<h3 id=\"2019-12-3\"><a href=\"#2019-12-3\" class=\"headerlink\" title=\"2019.12.3\"></a>2019.12.3</h3><p>写周报<br>leetcode</p>\n<h3 id=\"2019-12-4\"><a href=\"#2019-12-4\" class=\"headerlink\" title=\"2019.12.4\"></a>2019.12.4</h3><p>人体的rgb inpainting目前都没有人做的好，主要是会拿背景的信息填充到人体遮挡区域<br>考虑使用sil，把人体抠出来，看看能不能训练一个针对人体的inpainting网络，再出深度图看效果<br>注：rgb重建的效果也不会特别好，举个例子，拿衣服去补人脸的位置，肯定效果不对。但是，转成深度图再到三维模型上，效果不一定会特别差，待试<br>想想怎么给inpainting的输入加入人体轮廓信息这个约束<br>rbg修复好了 —&gt; 深度图效果好 —&gt; 模型效果好  </p>\n<p>王琛表示深度图做修复能做，接下来准备等深度图数据集处理完成，进inpainting网络，训练修复深度图的网络模型。</p>\n<h3 id=\"2019-12-5\"><a href=\"#2019-12-5\" class=\"headerlink\" title=\"2019.12.5\"></a>2019.12.5</h3><p>玩kbengine，部署linux游戏服务器，打包安卓客户端，双端联机测试<br>深度图要等到周日晚上，给王琛做</p>\n<h3 id=\"2019-12-6-7-8\"><a href=\"#2019-12-6-7-8\" class=\"headerlink\" title=\"2019.12.6/7/8\"></a>2019.12.6/7/8</h3><p>休</p>\n<h3 id=\"2019-12-9\"><a href=\"#2019-12-9\" class=\"headerlink\" title=\"2019.12.9\"></a>2019.12.9</h3><p>train depth inpainting model<br>shift-net_pytorch 深度图做出npy和png了，shift-net的图片都是256256，我这是448448，需要调整下网络</p>\n<h3 id=\"2019-12-10\"><a href=\"#2019-12-10\" class=\"headerlink\" title=\"2019.12.10\"></a>2019.12.10</h3><p>开始训练针对深度图的shift-net，30hrs(30 epoch) 明天放到hmd里看效果<br>这次训练用的center mask(25%左右的遮挡率) 有些把人遮住太多了 下次试试随机的或者范围小一点的<br>玩kbengine</p>\n<h3 id=\"2019-12-11\"><a href=\"#2019-12-11\" class=\"headerlink\" title=\"2019.12.11\"></a>2019.12.11</h3><p>贵州电网的一个UI材质工具<br>train好的modeltest需要测试集的depth map，2000多张得搞一下<br>hmd的shading-net没有train code，也就是说rgb到depth这段没有源码，shift-net做inpainting已经很好了，如果有shading-net的train code，合起来或许能做 incomplete rgb —&gt; complete depth<br>NYU的数据集看了精度肯定不够  </p>\n<h3 id=\"2019-12-12\"><a href=\"#2019-12-12\" class=\"headerlink\" title=\"2019.12.12\"></a>2019.12.12</h3><p>出inpainting好的深度图重建出的三维模型，这个算是完成目标了，但是是分两阶段完成（不完整rgb—&gt;不完整depth—&gt;完整depth）<br>接下来看shadingnet怎么train的，得能跑通</p>\n<p>3d mesh —&gt; 图像空间 初步深度信息 —》 shadingnet 增强深度信息—》<br>mesh到depth的原理 还有 ddrnet的那个loss  </p>\n<p>开题报告</p>\n<h3 id=\"2019-12-13-14-15\"><a href=\"#2019-12-13-14-15\" class=\"headerlink\" title=\"2019.12.13/14/15\"></a>2019.12.13/14/15</h3><p>开题报告</p>\n<h3 id=\"2019-12-16\"><a href=\"#2019-12-16\" class=\"headerlink\" title=\"2019.12.16\"></a>2019.12.16</h3><p>hmd: 训练策略（train scheme）是仿照的sfsnet<br>  先用了一个Unet，train时候输入是RGB + hmr投影出来的depth，监督数据是Kinect扫的depth（这个Unet train的时候只用到了少量数据集，然后用训练好的模型生成大量的depth，此时depth效果不好）<br>  然后是shadingnet，train的输入是hmr投影出来的depth和原始RGB，一个loss是用unet的输出监督，一个loss是photometric reconstruction loss（问题是这个reconstruct 重建了什么 就能知道重建的这个玩意儿跟什么做比较成为损失函数）</p>\n<p>重点看ddrnet怎么优化depth的，原理是什么</p>\n<blockquote>\n<p><strong>阶段性总结</strong>  </p>\n<ol>\n<li>明确人体细节是由深度图产生的，三维重建问题转化到深度图修复问题上</li>\n<li>做出了深度图数据集 18000+3000</li>\n<li>shift-net针对深度图训练了一个模型，可以用于深度图恢复</li>\n<li>tex2shape/octupus/hmr/hmd 基本可以跑对比实验了</li>\n</ol>\n</blockquote>\n<p>接下来的工作是做shadingnet的train<br>对比joint和anchor的train code<br>shadingnet的dataloader返回的是(src_img, depth_diff, mask)为什么要返回diff??? gt和smooth depth的差</p>\n<h3 id=\"2019-12-17\"><a href=\"#2019-12-17\" class=\"headerlink\" title=\"2019.12.17\"></a>2019.12.17</h3><p>自己做了shadingnet的train code，网络结构Unet（hmd给的），损失函数就用MSE，输入完整rgb还有mask，监督数据depth_gt，learning rate降到0.00001<br>搞搞看能不能rgb到depth 30分钟迭代900多次就训练完了 结束条件是什么不知道 测试中<br>测试结果不好 自己train出来的结果有明显颗粒感 深度数值范围0-1之间，pretrain的+-25之间 明天看</p>\n<h3 id=\"2019-12-18\"><a href=\"#2019-12-18\" class=\"headerlink\" title=\"2019.12.18\"></a>2019.12.18</h3><p>改开题报告 整点ddrnet的公式进去<br>shading net 用MSE train 完全不收敛啊  </p>\n<p>shadingnet dataloader ： mask就是coarse depth？！ 剪影代替的coarse depth？？ wtf  </p>\n<h3 id=\"2019-12-19\"><a href=\"#2019-12-19\" class=\"headerlink\" title=\"2019.12.19\"></a>2019.12.19</h3><p>两个问题：背景是黄的 是因为背景到人体的过度不自然，pre的是背景是0 人体上是0左右 正负50都有<br>细节是有的 但是我的像素不连续 有细节但是数值跟pre对应不上 颜色深浅<br>换个loss看看结果变不变 完全不变 调参也不变。。</p>\n<h3 id=\"2019-12-20\"><a href=\"#2019-12-20\" class=\"headerlink\" title=\"2019.12.20\"></a>2019.12.20</h3><p>不清楚网格的问题是不是通过调参就能解决的，或者换loss，还是不知道depth_diff干嘛用的<br>只能换loss了 自定义loss试试</p>\n<h3 id=\"2019-12-21\"><a href=\"#2019-12-21\" class=\"headerlink\" title=\"2019.12.21\"></a>2019.12.21</h3><p>原因是输入图像和gt图像没有匹配，低级错误<br>下一步进一步调参降低loss</p>\n<h3 id=\"2019-12-22\"><a href=\"#2019-12-22\" class=\"headerlink\" title=\"2019.12.22\"></a>2019.12.22</h3><ol>\n<li>eval pretrained model和我自己的model</li>\n<li>shift-net改下输出看结果<ol>\n<li>G &amp; D：G把输出的channel改成1，loss得跟depth比；让D区分gtdepth和preddepth</li>\n<li>backward_G and backward_D real_A real_B为什么有两个real？ dataloader在aligned_dataset.py里</li>\n<li>real_A == real_B//real_A—&gt;fake_B</li>\n<li>fake_B—netD—&gt;pred_fake//real_B—netD—&gt;pred_real</li>\n<li>set_gt_latent干什么用的</li>\n</ol>\n</li>\n</ol>\n<blockquote>\n<p>下周开始做改进改进版shift-net的实验<br>月底开始写论文</p>\n</blockquote>\n<h3 id=\"2019-12-23\"><a href=\"#2019-12-23\" class=\"headerlink\" title=\"2019.12.23\"></a>2019.12.23</h3><p>改shift-net：</p>\n<ol>\n<li>Gnet输入RGB，自己加遮罩，生成fake_rgb，用原始RGB监督；Dnet输入RGB和fake_rgb，输出两个判断结果的计算loss</li>\n<li>G输入3通道输出1通道，D出入1通道输出二分类，netD和vgg16featureextractor（util）<br>问题： 方框可能太大；把RGB的人挖出来比较好背景干扰太多<br>还是应该输出numpy数组，监督数据如果用png出来的是三通道的rgb图，得改可视化的代码，用plt通过numpy数组生成训练过程中图像</li>\n</ol>\n<h3 id=\"2019-12-24\"><a href=\"#2019-12-24\" class=\"headerlink\" title=\"2019.12.24\"></a>2019.12.24</h3><p>方框缩小，单通道输出，trainning，ETA 25号中午</p>\n<h3 id=\"2019-12-25\"><a href=\"#2019-12-25\" class=\"headerlink\" title=\"2019.12.25\"></a>2019.12.25</h3><p>test</p>\n<h3 id=\"2019-12-26\"><a href=\"#2019-12-26\" class=\"headerlink\" title=\"2019.12.26\"></a>2019.12.26</h3><p>spectral_norm gan用的东西<br>现在要解决的问题：重建深度图不光滑，有明显的网格，重复结构，不知道为什么<br>G就是个encoder decoder 为什么会有网格<br>试试用sil不用深度图的a[b==0] = 0 不行 sil只有8035个<br>把unet最后一层的tanh激活函数删了结果看起来好点了 迭代30次看看效果<br>7次 看起来还原出来的部分并没有什么细节</p>\n<h3 id=\"2019-12-27\"><a href=\"#2019-12-27\" class=\"headerlink\" title=\"2019.12.27\"></a>2019.12.27</h3><p>shift-net几个损失函数得调整，D一直为0了 content过于大<br>D的输入已经是抠出来的了，opt.overlap是什么</p>\n<h3 id=\"2019-12-28-29\"><a href=\"#2019-12-28-29\" class=\"headerlink\" title=\"2019.12.28/29\"></a>2019.12.28/29</h3><p>休<br>回放系统、撤销操作  </p>\n<h3 id=\"2019-12-30\"><a href=\"#2019-12-30\" class=\"headerlink\" title=\"2019.12.30\"></a>2019.12.30</h3><p>开会，确定一月时间安排<br>开始论文初稿，学习latex，写公式最麻烦，网络结构图，柱状图，折线图  </p>\n<p>怎么能让遮挡区域的数值乘个系数？？</p>\n<h3 id=\"2019-12-31\"><a href=\"#2019-12-31\" class=\"headerlink\" title=\"2019.12.31\"></a>2019.12.31</h3><p>abstract完成</p>\n<h3 id=\"2019-1-1\"><a href=\"#2019-1-1\" class=\"headerlink\" title=\"2019.1.1\"></a>2019.1.1</h3><p>开题ppt完成</p>\n<h3 id=\"2019-1-2\"><a href=\"#2019-1-2\" class=\"headerlink\" title=\"2019.1.2\"></a>2019.1.2</h3><p>latex画Unet</p>\n<h3 id=\"2019-1-3\"><a href=\"#2019-1-3\" class=\"headerlink\" title=\"2019.1.3\"></a>2019.1.3</h3><p>朱青审开题报告，ppt<br>修改</p>\n<h3 id=\"2019-1-4-5\"><a href=\"#2019-1-4-5\" class=\"headerlink\" title=\"2019.1.4/5\"></a>2019.1.4/5</h3><p>休</p>\n<h3 id=\"2019-1-6\"><a href=\"#2019-1-6\" class=\"headerlink\" title=\"2019.1.6\"></a>2019.1.6</h3><p>introduction<br>related work<br>method</p>\n<h3 id=\"2019-1-7\"><a href=\"#2019-1-7\" class=\"headerlink\" title=\"2019.1.7\"></a>2019.1.7</h3><p>result<br>conclusion</p>\n<blockquote>\n<p> <strong>论文结构</strong></p>\n<ol>\n<li><p>abstract</p>\n</li>\n<li><p>introduction<br>三维人体重建：分两种基于参数化模型的和非的/还是特征匹配的和模板适应的<br>目前方法的局限性，我的方法综述，贡献点总结</p>\n</li>\n<li><p>related work  </p>\n<ul>\n<li><p>参数化的  </p>\n<ul>\n<li>scape  <ul>\n<li>人工标记关键点<br>* </li>\n<li>卷积标记关键点  </li>\n</ul>\n</li>\n<li>smpl  </li>\n</ul>\n</li>\n<li><p>非参数化的  </p>\n</li>\n</ul>\n</li>\n<li><p>methods  </p>\n<ul>\n<li>SMPL，anchor/joint deformation，<strong>vertex deformation</strong>（our dataset, our net, loss）</li>\n<li>Loss：G_GAN,G_L1,D,style(MSE vgg),content</li>\n</ul>\n</li>\n<li>results &amp; comparison<br>介绍evaluation用的数据集，评价方法，评价/对比结果<br>hmr/hmd/tex2shape/octopus<br>原图inpainting/深度图inpainting/遮挡rgb生成完整的深度图<br>测试150加遮罩—&gt;(只能不带遮罩的进？？为什么)进shiftnet出深度图—&gt;hmd_s使用深度图信息而非shadingnet信息—&gt;结果</li>\n<li>conclusion</li>\n</ol>\n</blockquote>\n<h3 id=\"2020-1-13\"><a href=\"#2020-1-13\" class=\"headerlink\" title=\"2020.1.13\"></a>2020.1.13</h3><p>dhdnet在跑recon测试集的时候方框处理的非常不好<br>现在猜测是因为训练的用深度图gt当作的sil，在A[B==0]=0这步的时候很可能把纹理信息填回方框区域内了。。现在但是理论上shiftnet自己还会加遮罩<br>目前recon测试集上只能用不加遮挡的img做输入效果还可以<br>矛盾点在于 shiftnet是在线加的遮罩啊 为什么输入图像加不加遮罩还会造成影响？？？？</p>\n<h3 id=\"2020-1-14\"><a href=\"#2020-1-14\" class=\"headerlink\" title=\"2020.1.14\"></a>2020.1.14</h3><p>recon只看joint 还是得看syn<br>输入图像家的遮罩试着比 shiftnet动态加的小一点 84 84 140 140—&gt;87 87 137 137</p>\n<h3 id=\"2020-1-15\"><a href=\"#2020-1-15\" class=\"headerlink\" title=\"2020.1.15\"></a>2020.1.15</h3><p>leetcode<br>blog 加入vuejs静态页面<br>Mirror 多人游戏demo / kbe C++ 服务端  </p>\n<h3 id=\"2020-3-8\"><a href=\"#2020-3-8\" class=\"headerlink\" title=\"2020.3.8\"></a>2020.3.8</h3><p>Attention机制<a href=\"https://zhuanlan.zhihu.com/p/91839581\">zhihu</a><br>论文搜索：<br>Self-Attention Generative Adversarial Networks (SAGAN)<a href=\"https://github.com/heykeetae/Self-Attention-GAN\">code</a><br>A PyTorch reimplementation for paper Generative Image Inpainting with Contextual Attention <a href=\"https://arxiv.org/abs/1801.07892\">paper</a> <a href=\"https://github.com/daa233/generative-inpainting-pytorch\">code</a></p>\n<h3 id=\"2020-3-9\"><a href=\"#2020-3-9\" class=\"headerlink\" title=\"2020.3.9\"></a>2020.3.9</h3><p><a href=\"\">Learning 3D Human Shape and Pose from Dense Body Parts</a></p>\n<h3 id=\"2020-5-30\"><a href=\"#2020-5-30\" class=\"headerlink\" title=\"2020.5.30\"></a>2020.5.30</h3><p>Losses：下降较明显的有G_L1，content；G_GAN略上升，D下降不明显<br>loss计算公式：<br>$lossD = (lossDfake + lossDreal) <em> 0.5$ (vanilla)<br>fake/real 是BCELoss二分类交叉熵损失函数<br>$loss G = loss G L1 + loss G L1 m + loss G GAN + style loss + content loss + tv loss$<br>loss G L1 是 $L1 loss </em> opt.lambda_A$<br>L1_m 是一个spatical discounting l1 loss（别的论文里提出来的）<br>loss G GAN 是BCELoss<br>style和content都是MSELoss<br>tv是自定义一个损失函数  </p>\n<p>目前已有的：</p>\n<ul>\n<li>rgb特征提取—&gt;分三阶段形变smpl模型</li>\n<li>depth map到人体表面细节，形变方法（hmd提供）</li>\n<li>不完整rgb向完整depth map的转换网络模型</li>\n<li>不完整rgb到完整人体模型的端到端系统</li>\n<li>合成人体深度信息数据集</li>\n</ul>\n<p>后续研究方向（大论文第二章，改进算法）：</p>\n<ul>\n<li>center mask的大小对重建质量的影响（最大多大就handle不住了）</li>\n<li>不规则mask（shiftnet做了，这个好实现）</li>\n<li>attention机制对于结果的提升有多少（没概念）</li>\n<li>目前来看多loss共同作用，有些loss并没有明显收敛（是否等于没作用、贡献）—灼烧实验</li>\n<li>depth信息到三维点坐标的形变（deform）关系还能改进（比如深度或者说形变的scale，还有方向，目前是垂直于视平面，可以是垂直于粗模型表面？）</li>\n<li>structure from motion方向研究（全新方向，建筑行业在用）</li>\n<li>加壳，做成用户友好的应用程序</li>\n</ul>\n<h3 id=\"2020-6-2\"><a href=\"#2020-6-2\" class=\"headerlink\" title=\"2020.6.2\"></a>2020.6.2</h3><p>ICIP论文中的四个示例在recon_set中，编号为1，3，95，116  </p>\n<h3 id=\"2020-7-8\"><a href=\"#2020-7-8\" class=\"headerlink\" title=\"2020.7.8\"></a>2020.7.8</h3><p>专利：</p>\n<ul>\n<li>技术背景<ul>\n<li>应用与不足</li>\n<li>现有技术分析</li>\n<li>综上</li>\n</ul>\n</li>\n<li>发明内容</li>\n</ul>\n<h3 id=\"2020-7-13\"><a href=\"#2020-7-13\" class=\"headerlink\" title=\"2020.7.13\"></a>2020.7.13</h3><p>ICIP ppt<br><a href=\"https://zhuanlan.zhihu.com/p/25804146\">mesh deformation with Laplacian coordinates</a>：一种智能化的方法，能够让用户只需设置个别离散点的新位置来表达他所想要的形变，就能自动根据所需保持的形体信息来计算出剩余离散点应有的位置</p>\n<h3 id=\"2020-10-27\"><a href=\"#2020-10-27\" class=\"headerlink\" title=\"2020.10.27\"></a>2020.10.27</h3><script type=\"math/tex; mode=display\">L_{joint/anchor} = \\parallel p - \\hat{p} \\parallel_{2}</script><h3 id=\"2020-11-19\"><a href=\"#2020-11-19\" class=\"headerlink\" title=\"2020.11.19\"></a>2020.11.19</h3><p>PIFuHD的重建效果比hmd好多了，处理遮挡不好</p>\n<h3 id=\"2020-11-20\"><a href=\"#2020-11-20\" class=\"headerlink\" title=\"2020.11.20\"></a>2020.11.20</h3><p>开始研究star的用法，先看smpl-x是怎么使用smpl模型的  </p>\n<p>hmd中的laplacian形变code来自duke university, <a href=\"https://github.com/bmershon/laplacian-meshes\">course link</a><br>球谐函数是自己写的tql<br>renderer是hmr的</p>\n<p>得搞清楚smpl verts faces的维度和个数</p>\n<h3 id=\"2020-11-27\"><a href=\"#2020-11-27\" class=\"headerlink\" title=\"2020.11.27\"></a>2020.11.27</h3><p>texture：</p>\n<ul>\n<li>Semantic Human Texture Stitching: octupus//// opendr only workable on linux</li>\n<li>tex2shape: 有uv，unity里可以贴图</li>\n<li>pix2suf: 用衣服的2d图片，映射到衣服模型上，是分开的上衣和裤子（短裤）模型，不是smpl人体模型上</li>\n</ul>\n<p>geometry：自监督</p>\n<h3 id=\"2020-12-3\"><a href=\"#2020-12-3\" class=\"headerlink\" title=\"2020.12.3\"></a>2020.12.3</h3><p>标准SMPL模型提供了带uv信息的obj文件，可以使用stitching的纹理贴图<br>实验思路：</p>\n<ul>\n<li>单帧：包含遮挡和不包含遮挡和经过shift-net图像修复的受遮挡，用tex2shape的理论</li>\n<li>多帧：stitching原本，遮挡物随机放置，用stitching的理论</li>\n</ul>\n<h3 id=\"2020-12-4\"><a href=\"#2020-12-4\" class=\"headerlink\" title=\"2020.12.4\"></a>2020.12.4</h3><p>大论文参考论文，hmr，hmd，shift-net，ddrnet，tex2shape，stitching<br>理论知识点，smpl模型，GAN，Unet，Shift layer，拉普拉斯形变Laplacian mesh deformation，球谐函数gi</p>\n<h3 id=\"2020-11-3\"><a href=\"#2020-11-3\" class=\"headerlink\" title=\"2020.11.3\"></a>2020.11.3</h3><p><a href=\"https://blog.csdn.net/zddblog/article/details/7521424\">SIFT</a>：尺度不变特征变换，采用高斯核函数进行滤波，寻找不同的尺度空间<br>  可以解决occlusion和clutter？<br>  LoG(Laplacion of Gaussian)算子：<br>  高斯差分函数（Difference of Gaussian ，简称DOG算子）：<br>KNN：K最近邻，k-nearest neighbor<br>aggregator：<br>updater：<br><a href=\"https://blog.csdn.net/xholes/article/details/78461164\">multi-layer perceptron</a>（MLP） in updater：也就是Full-connection Neural Network </p>\n<p>self- attention mechanism：<br>  <a href=\"https://zhuanlan.zhihu.com/p/37601161\">attention机制</a>：soft-attention、attention、self-attention，就是source=target，寻找输入语句中单词间的联系<br>node-based clustering：聚类算法 有K-means，和knn有区别但是很像，前者是每次迭代调整聚类中心<br>PointCN：<br>epipolar distance:<br>Structure-from-Motion system:<br>shape-from- silhouette technique：搞出来的初始几何体都不完全并且有噪点<br>human parsing method：</p>\n<h3 id=\"2020-11-10\"><a href=\"#2020-11-10\" class=\"headerlink\" title=\"2020.11.10\"></a>2020.11.10</h3><p>LBS：smpl基于全身的linear blend skinning (LBS)<br>cocoapi报no module pycocotools._mask需要install pycocotools，在git repo pythonapi目录下执行makefile（注意看makefile的内容）</p>\n<h3 id=\"2021-4-7\"><a href=\"#2021-4-7\" class=\"headerlink\" title=\"2021.4.7\"></a>2021.4.7</h3><p>tf.variable_scope() reuse: <a href=\"https://blog.csdn.net/xpy870663266/article/details/98950853\">Link</a></p>\n<h3 id=\"2021-4-12\"><a href=\"#2021-4-12\" class=\"headerlink\" title=\"2021.4.12\"></a>2021.4.12</h3><ol>\n<li>数据集规模上要强调自监督在同等数据规模下没有dhd好，然后转到增加数据集规模</li>\n<li>4.3节强调采用dhd+自监督的原因是：自监督提供高频细节，dhd提供低频褶皱</li>\n<li>强调是框架结果的提升，而不是自监督方法与dhd方法间的比较</li>\n<li>dhd的输入是rgb+mask，hmd里shadingnet是rgb+depth，盲审版本第三章的流程图写的是rgb+sil..</li>\n<li>自监督训练数据自己拍的48000帧，网络视频3000组，大概等于12000帧</li>\n</ol>\n<h3 id=\"2021-5-24\"><a href=\"#2021-5-24\" class=\"headerlink\" title=\"2021.5.24\"></a>2021.5.24</h3><p>盲审三个良好，申优答辩很简单，明天交终版论文  </p>\n<p>终。  </p>\n<h2 id=\"conda-env\"><a href=\"#conda-env\" class=\"headerlink\" title=\"conda env\"></a>conda env</h2><ul>\n<li>pytorch：Python 3.7 + pytorch 1.3  detectron2/densepose/shift-net_pytorch</li>\n<li>tf2: python2 + tf1.14  hmr, tex2shape, Semantic Human Texture Stitching</li>\n<li>tf: python3 + tf1.14 + pytorch  human_dynamics, neuralgym/generative_inpainting</li>\n<li>dirt：py2.7 + tf1.13 + dirt  octopus, garment</li>\n<li>hmd(可以跟tf2合并)：py2.7 + pytorch1.0.1  hmd</li>\n</ul>\n<h2 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h2><ul>\n<li><p>三通道rgb原图到三通道depth.convert(‘RGB’)效果不好，中心预测的不好，四周也没有跟gt完全一致。</p>\n<ul>\n<li>缩小遮挡范围1/2改为1/4的宽高</li>\n<li>输入三通道rgb 输出单通道npy数组 改下可视化的代码使正常显示</li>\n</ul>\n</li>\n<li><p>human_depth: 输入三通道depth_png，输出三通道修复完成后的depth_png，这是下边实验的目标效果</p>\n</li>\n<li>rgb2depth_npy_2: 初试版本，1/4边长遮挡，王瑾周报</li>\n<li>rgb2depth_npy_3: G去tanh()版本，网格纹理问题解决</li>\n<li>rgb2depth_npy_4: 修改D输入图像范围，仅输入被遮挡区域</li>\n</ul>\n<h2 id=\"数学理论相关\"><a href=\"#数学理论相关\" class=\"headerlink\" title=\"数学理论相关\"></a>数学理论相关</h2><p><a href=\"https://www.zhihu.com/question/28552876/answer/1268629178\">压缩感知</a>中的欠定方程（undetermined equations）：</p>\n<h2 id=\"目标（朱邮件内容）\"><a href=\"#目标（朱邮件内容）\" class=\"headerlink\" title=\"目标（朱邮件内容）\"></a>目标（朱邮件内容）</h2><p>研究方向：<strong>非理想条件下的单目RGB相机三维人体重建</strong>  </p>\n<p>领域现状：目前基于相机阵列以及单目RGBD相机的三维人体重建技术已经较为成熟，仅依靠单目RGB相机的三维人体重建工作具有广阔的发展前景并且具有挑战性。以MPI、UCB、浙大为首的一些实验室已经在该研究方向上已经取得了一些成果，但是输入图像质量都比较理想，非理想条件下的重建效果并不明确。  </p>\n<p>我的工作：目前确定做非理想条件下的单目相机三维人体重建，提高重建精度包括模型细节、姿态、纹理贴图。非理想条件具体来说有以下情况：</p>\n<ol>\n<li>图像中人物受到遮挡（重点）</li>\n<li>图像中人物因高速移动产生的运动模糊</li>\n<li>图像中人物因环境光照产生的视觉偏差</li>\n</ol>\n<p>工作计划：看现有方法在上述非理想条件下的重建效果（文章中没有提到的需要亲自跑实验验证）；设计改善方法，反复实验验证，得到实验数据；论文撰写。</p>\n<h1 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h1><ul>\n<li>单图多人（人群）三维重建<br>可能需要解决的问题：<br>遮挡（周晓巍的PVNet解决了遮挡的问题，空间维度上的估计）<br>分割<br>大小/相对位置<br>…   </li>\n<li><p>跟游戏开发能关联的地方：<br>用引擎看效果<br>实用性  </p>\n</li>\n<li><p>从视频序列中选出作用显著的帧，设计量化评价方法  </p>\n</li>\n<li><p>从不同表达，面点云体素区别入手  </p>\n</li>\n<li><p>增加脸部细节（手部、脚步，观察几个论文的演示视频好像都没有动作细节，骨骼的问题应该是）呢？？结合3dmm（已经有结合的了19.10.10更新）  </p>\n</li>\n<li><p>考虑多模态，加入语义信息辅助重建（还得看nlp的东西，把特征映射到一个空间不知道能不能做）</p>\n</li>\n<li><p><strong>快速移动/运动模糊</strong>的视频/照片做重建（回到图像处理的问题上，不确定目前已有的方法在视频中任务快速移动情况下的重建效果）</p>\n</li>\n<li><p>UCB预测人体动作（时间维度上的估计） 能怎么改进</p>\n</li>\n<li><p>MPI做的实时 </p>\n</li>\n<li><p>UCB把SMPL用到了动物（斑马）模型重建；不是smpl是smal</p>\n</li>\n<li><p>光照条件对重建质量的影响</p>\n</li>\n</ul>\n<p>UCB做了动物的模型重建，根据视频<strong>预测</strong>人体接下来的动作；MPI<strong>实时</strong>Video to Mesh  </p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>shape：更有细节/遮挡、截断(空间维度预测)/<br>pose：根据视频、单图预测pose（时间维度预测）/实时更新pose<br>texture：单视角贴图/多视角贴图</p>\n</blockquote>\n</blockquote>\n<p><strong>疑问</strong><br>6D pose estimation 和 smpl/smal重建出的pose有何异同？？是一个东西吗<br>In contrast to coordinate or<br>heatmap based representations, learning such a representa-<br>tion enforces the network to focus on local features of ob-<br>jects and spatial relations between object parts. As a result,<br>the location of an invisible part can be inferred from the vis-<br>ible parts. In addition, this vector-field representation is able<br>to represent object keypoints that are even outside the input<br>image. All these advantages make it an ideal representation<br>for occluded or truncated objects.</p>\n</blockquote>\n<h2 id=\"大论文\"><a href=\"#大论文\" class=\"headerlink\" title=\"大论文\"></a>大论文</h2><h3 id=\"大论文结构\"><a href=\"#大论文结构\" class=\"headerlink\" title=\"大论文结构\"></a>大论文结构</h3><ul>\n<li>摘要<ul>\n<li>三维人体重建是什么</li>\n<li>挑战</li>\n<li>现有方法的局限性</li>\n<li>本文的两个贡献点</li>\n</ul>\n</li>\n<li>绪论<ul>\n<li>研究背景与意义<ul>\n<li>三维重建是什么</li>\n<li>主要挑战</li>\n<li>传统的三维重建方法</li>\n<li>传统方法存在的问题</li>\n<li>深度学习与GAN</li>\n<li>基于GAN的端到端系统</li>\n<li>本研究的方法意义</li>\n</ul>\n</li>\n<li>国内外研究现状<br>* </li>\n<li>本文主要研究内容+重点</li>\n<li>本文结构及安排</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>第四章 单视图三维人体纹理贴图重建算法</p>\n<ul>\n<li>detectron的人体分割和UV映射算法<br>* </li>\n<li>基于图像修复的UV纹理映射<ul>\n<li>输入单张人体RGB—&gt;IUV—&gt;normal texture—&gt;贴图的三维人体模型</li>\n</ul>\n</li>\n<li>实验结果分析<br>停滞在detectron2生成的IUV跟tex2shape中的IUV不一样，感觉就是多个了背景，不知道怎么去<br>困难在于还要训练densepose以应对遮挡，这块监督数据不知道怎么办，训练策略不知道怎么改  </li>\n</ul>\n</li>\n<li><p>第四章 自监督人体深度估计算法研究</p>\n</li>\n</ul>\n<ul>\n<li>总结<ul>\n<li>定义</li>\n<li>应用</li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"思路-1\"><a href=\"#思路-1\" class=\"headerlink\" title=\"思路\"></a>思路</h3><p>参数化人体模型—scape和smpl，将形体姿态转换为参数向量，方便神经网络进行学习<br>问题在于精度不够，没有细节，所以自由网格形变，非刚性的三维形变方法对模型进行优化  </p>\n<h2 id=\"时间安排\"><a href=\"#时间安排\" class=\"headerlink\" title=\"时间安排\"></a>时间安排</h2><blockquote>\n<p>VCIP 5月<br>ACM Multimedia 3月<br>ICIP 1月31日</p>\n<blockquote>\n<p>1月15日初稿和evaluation  </p>\n</blockquote>\n<p>1月开始写论文<br>12月实验，开题<br>开始编写代码，训练模型，评估实验数据<br>11月实验<br>设计优化思路，实验步骤，预期的实验结果 11.18-11.29 两周<br>现有方法在非理想情况下的表现 10.21-11.15 四周<br>10月底规划好实验步骤，预计出的结果<br>10月18号确定要做的目标</p>\n</blockquote>\n<h1 id=\"信息总结\"><a href=\"#信息总结\" class=\"headerlink\" title=\"信息总结\"></a>信息总结</h1><p>fusion<br>mulity domin<br>多元融合</p>\n<p>显著性<br>摘要<br>帧对重建质量的贡献</p>\n<p>王少帆 北工大计算机学院<br>dblp</p>\n<h1 id=\"todo-list\"><a href=\"#todo-list\" class=\"headerlink\" title=\"todo list\"></a>todo list</h1><p>数据清洗 三个数据集UP-3D，HumanEva-I，Human3.6M<br>清洗的目的？目标？要做成什么样？</p>\n","slug":"关于三维重建的文献综述","updated":"2021-05-26T04:43:35.010Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/","excerpt":"","categories":[{"name":"论文综述","slug":"论文综述","permalink":"https://blog.providencezhang.cn/categories/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"}],"tags":[{"name":"3D model reconstruction","slug":"3D-model-reconstruction","permalink":"https://blog.providencezhang.cn/tags/3D-model-reconstruction/"},{"name":"文献综述","slug":"文献综述","permalink":"https://blog.providencezhang.cn/tags/%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/"}]},{"title":"CS294-112 Fa18","date":"2018-12-21T06:19:30.000Z","path":"2018/12/21/CS294-112_Fa18/","text":"Deep reinforcement learningWeek One2018.12.6 Introduction and Course Overview Slide why now? reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization experience replay : material instructive training instances provided by human teachers hierarchical learning non-Markovian environments by having a memory of their past what can DL&amp;RL do well now? Acquire high degree of proficiency in domains governed by simple, known rules Learn simple skills with raw sensory inputs, given enough experience Learn from imitating enough humanprovided expert behavior challenges Humans can learn incredibly quickly Humans can reuse past knowledge Not clear what the reward function should be Not clear what the role of prediction should be Week Two2018.12.13 Goals: understand definitions &amp; notation understand basic imitation learning algorithms understand their strengths &amp; weeknesses Sequential decision-making 顺序决策经典监督学习模式(imitation learning)不能完成自动驾驶的原因： 就算只犯一点点错误（预测结果与训练集数据不同）都会导致后续预测的偏差被逐渐放大 markovian behaviorDAgger. for markovian behavior we can use RNN, Recurrent Neural Networksfor multimodal behavior output mixture of gaussians latent variable models autoregressive discretization cost function for imitation homework1 因为mujoco有visual c++的依赖 还得安vs studio 准备装个linux虚拟机再做 Week Three2018.12.20tensorflow tutorial Week Four2018.12.21 作业1下周该做完了 markov 决策过程的定义 rl问题的定义 rl算法剖析 rl算法的类型简介 markov decision process是rl的基础markov chain-&gt;mdpS:state A:action O:observation T:transition e:emission probability r:reward function-&gt;r:SA-&gt;Robjectives: 公式in slidestate-action marginal—&gt;finite*stationary distribution—&gt;infiniteeigenvalue:特征值问题 algorithms","raw":"---\ntitle: CS294-112 Fa18\ndate: 2018-12-21 14:19:30\ntags: \n    - reinforcement learning\n    - berkeley course\n    - Sergey Levine\n---\n\n# Deep reinforcement learning  \n\n## Week One\n\n2018.12.6  \n\nIntroduction and Course Overview [Slide](http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-1.pdf)  \n\n* why now?\n    reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization  \n    experience replay : [material](https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits)  \n    instructive training instances provided by human teachers  \n    hierarchical learning  \n    non-Markovian environments by having a memory of their past  \n\n* what can DL&RL do well now?\n    Acquire high degree of proficiency in domains governed by simple, known rules  \n    Learn simple skills with raw sensory inputs, given enough experience  \n    Learn from imitating enough humanprovided expert behavior  \n\n* challenges\n    Humans can learn incredibly quickly  \n    Humans can reuse past knowledge  \n    Not clear what the reward function should be  \n    Not clear what the role of prediction should be  \n\n## Week Two\n\n2018.12.13  \n\nGoals:\n\n* understand definitions & notation  \n* understand basic imitation learning algorithms\n* understand their strengths & weeknesses\n\nSequential decision-making 顺序决策\n经典监督学习模式(imitation learning)不能完成自动驾驶的原因：  \n\n* 就算只犯一点点错误（预测结果与训练集数据不同）都会导致后续预测的偏差被逐渐放大  \n\nmarkovian behavior  \nDAgger.  \n\nfor markovian behavior we can use RNN, Recurrent Neural Networks  \nfor multimodal behavior  \n\n1. output mixture of gaussians  \n2. latent variable models  \n3. autoregressive discretization  \n\ncost function for imitation  \n  \n* [homework1](http://rail.eecs.berkeley.edu/deeprlcourse/static/homeworks/hw1.pdf) 因为mujoco有visual c++的依赖 还得安vs studio 准备装个linux虚拟机再做  \n  \n## Week Three  \n  \n2018.12.20  \ntensorflow tutorial  \n  \n## Week Four  \n  \n2018.12.21  \n  \n作业1下周该做完了  \n  \n1. markov 决策过程的定义\n2. rl问题的定义\n3. rl算法剖析\n4. rl算法的类型简介  \n\nmarkov decision process是rl的基础\nmarkov chain->mdp  \nS:state A:action O:observation T:transition e:emission probability r:reward function->r:S*A->R  \nobjectives:  \n    公式in slide  \nstate-action marginal-->finite  \n**stationary distribution**-->infinite  \neigenvalue:特征值问题  \n  \n**algorithms**  \n","content":"<h1 id=\"Deep-reinforcement-learning\"><a href=\"#Deep-reinforcement-learning\" class=\"headerlink\" title=\"Deep reinforcement learning\"></a>Deep reinforcement learning</h1><h2 id=\"Week-One\"><a href=\"#Week-One\" class=\"headerlink\" title=\"Week One\"></a>Week One</h2><p>2018.12.6  </p>\n<p>Introduction and Course Overview <a href=\"http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-1.pdf\">Slide</a>  </p>\n<ul>\n<li><p>why now?<br>  reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization<br>  experience replay : <a href=\"https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits\">material</a><br>  instructive training instances provided by human teachers<br>  hierarchical learning<br>  non-Markovian environments by having a memory of their past  </p>\n</li>\n<li><p>what can DL&amp;RL do well now?<br>  Acquire high degree of proficiency in domains governed by simple, known rules<br>  Learn simple skills with raw sensory inputs, given enough experience<br>  Learn from imitating enough humanprovided expert behavior  </p>\n</li>\n<li><p>challenges<br>  Humans can learn incredibly quickly<br>  Humans can reuse past knowledge<br>  Not clear what the reward function should be<br>  Not clear what the role of prediction should be  </p>\n</li>\n</ul>\n<h2 id=\"Week-Two\"><a href=\"#Week-Two\" class=\"headerlink\" title=\"Week Two\"></a>Week Two</h2><p>2018.12.13  </p>\n<p>Goals:</p>\n<ul>\n<li>understand definitions &amp; notation  </li>\n<li>understand basic imitation learning algorithms</li>\n<li>understand their strengths &amp; weeknesses</li>\n</ul>\n<p>Sequential decision-making 顺序决策<br>经典监督学习模式(imitation learning)不能完成自动驾驶的原因：  </p>\n<ul>\n<li>就算只犯一点点错误（预测结果与训练集数据不同）都会导致后续预测的偏差被逐渐放大  </li>\n</ul>\n<p>markovian behavior<br>DAgger.  </p>\n<p>for markovian behavior we can use RNN, Recurrent Neural Networks<br>for multimodal behavior  </p>\n<ol>\n<li>output mixture of gaussians  </li>\n<li>latent variable models  </li>\n<li>autoregressive discretization  </li>\n</ol>\n<p>cost function for imitation  </p>\n<ul>\n<li><a href=\"http://rail.eecs.berkeley.edu/deeprlcourse/static/homeworks/hw1.pdf\">homework1</a> 因为mujoco有visual c++的依赖 还得安vs studio 准备装个linux虚拟机再做  </li>\n</ul>\n<h2 id=\"Week-Three\"><a href=\"#Week-Three\" class=\"headerlink\" title=\"Week Three\"></a>Week Three</h2><p>2018.12.20<br>tensorflow tutorial  </p>\n<h2 id=\"Week-Four\"><a href=\"#Week-Four\" class=\"headerlink\" title=\"Week Four\"></a>Week Four</h2><p>2018.12.21  </p>\n<p>作业1下周该做完了  </p>\n<ol>\n<li>markov 决策过程的定义</li>\n<li>rl问题的定义</li>\n<li>rl算法剖析</li>\n<li>rl算法的类型简介  </li>\n</ol>\n<p>markov decision process是rl的基础<br>markov chain-&gt;mdp<br>S:state A:action O:observation T:transition e:emission probability r:reward function-&gt;r:S<em>A-&gt;R<br>objectives:<br>    公式in slide<br>state-action marginal—&gt;finite<br><em>*stationary distribution</em></em>—&gt;infinite<br>eigenvalue:特征值问题  </p>\n<p><strong>algorithms</strong>  </p>\n","slug":"CS294-112_Fa18","updated":"2019-05-04T11:31:57.264Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/12/21/CS294-112_Fa18/","excerpt":"","categories":[],"tags":[{"name":"reinforcement learning","slug":"reinforcement-learning","permalink":"https://blog.providencezhang.cn/tags/reinforcement-learning/"},{"name":"berkeley course","slug":"berkeley-course","permalink":"https://blog.providencezhang.cn/tags/berkeley-course/"},{"name":"Sergey Levine","slug":"Sergey-Levine","permalink":"https://blog.providencezhang.cn/tags/Sergey-Levine/"}]},{"title":"git+sourcetree+腾讯云项目管理教程","date":"2018-12-20T02:36:46.000Z","path":"2018/12/20/git-sourcetree-腾讯云项目管理教程/","text":"注册腾讯云开发者平台 就是以前的coding.net 中文界面对国内开发者很友好，个人感觉可以代替github，新功能很有趣 进入项目-&gt;设置-&gt;成员管理可以添加项目成员，相当于github的organization 项目、仓库设置中可以转移项目所有权，免费将项目仓库设为私有，github私有仓库有月租 下载、安装git 注意配置环境变量 git GUI 推荐sourcetree，注册登录账号可能需要翻墙 2，3网上教程都很多这里就不写了 git lfs(large file storage) 当项目中有大小超过2m的文件时，建议使用lfs lfs使用教程(unity项目例子)LFS","raw":"---\ntitle: git+sourcetree+腾讯云项目管理教程\ndate: 2018-12-20 10:36:46\ntags:\n    - 腾讯云\n    - git\n    - sourcetree\n    - 版本控制\n    - 项目管理\n---\n\n1. 注册[腾讯云开发者平台](https://dev.tencent.com/)  \n    就是以前的coding.net  \n    *中文界面对国内开发者很友好，个人感觉可以代替github，新功能很有趣*  \n    进入项目->设置->成员管理可以添加项目成员，相当于github的organization  \n    项目、仓库设置中可以转移项目所有权，免费将项目仓库设为私有，github私有仓库有月租  \n2. 下载、安装git  \n    *注意配置环境变量*  \n3. git GUI  \n    推荐sourcetree，注册登录账号可能需要翻墙  \n    *2，3网上教程都很多这里就不写了*  \n4. git lfs(large file storage)  \n    当项目中有大小超过2m的文件时，建议使用lfs\n    lfs使用教程(unity项目例子)[LFS](https://blog.csdn.net/yaoyutian/article/details/78872102)","content":"<ol>\n<li>注册<a href=\"https://dev.tencent.com/\">腾讯云开发者平台</a><br> 就是以前的coding.net<br> <em>中文界面对国内开发者很友好，个人感觉可以代替github，新功能很有趣</em><br> 进入项目-&gt;设置-&gt;成员管理可以添加项目成员，相当于github的organization<br> 项目、仓库设置中可以转移项目所有权，免费将项目仓库设为私有，github私有仓库有月租  </li>\n<li>下载、安装git<br> <em>注意配置环境变量</em>  </li>\n<li>git GUI<br> 推荐sourcetree，注册登录账号可能需要翻墙<br> <em>2，3网上教程都很多这里就不写了</em>  </li>\n<li>git lfs(large file storage)<br> 当项目中有大小超过2m的文件时，建议使用lfs<br> lfs使用教程(unity项目例子)<a href=\"https://blog.csdn.net/yaoyutian/article/details/78872102\">LFS</a></li>\n</ol>\n","slug":"git-sourcetree-腾讯云项目管理教程","updated":"2019-05-04T11:31:57.270Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/12/20/git-sourcetree-%E8%85%BE%E8%AE%AF%E4%BA%91%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%95%99%E7%A8%8B/","excerpt":"","categories":[],"tags":[{"name":"腾讯云","slug":"腾讯云","permalink":"https://blog.providencezhang.cn/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"},{"name":"git","slug":"git","permalink":"https://blog.providencezhang.cn/tags/git/"},{"name":"sourcetree","slug":"sourcetree","permalink":"https://blog.providencezhang.cn/tags/sourcetree/"},{"name":"版本控制","slug":"版本控制","permalink":"https://blog.providencezhang.cn/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"项目管理","slug":"项目管理","permalink":"https://blog.providencezhang.cn/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"deeplearning.ai","date":"2018-12-18T02:08:59.000Z","path":"2018/12/18/deeplearning-ai/","text":"Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationtrain/dev/test data set 在过去通常 60/20/20% 的比例，总样本数在10,000大数据时代通常在 98/1/1 或者后两个更小的比例，总样本在1,000,000 high bias&amp;high variance判断网络模型高偏差还是高方差还是两者都有的方法： 训练集上的错误率过高就是高偏差（例：人错误率，也称base error 1%，模型训练集上错误率15%，模型在开发集上错误率16%） 开发集上的错误率比训练集上的错误率高过多是高方差（例：人错误率14%，模型训练集上错误率15%，模型在开发集上错误率30%） 高偏差—&gt;更大的网络高方差—&gt;更多的数据—&gt;可能导致偏差变高—&gt;高偏差 Regularization正则化为的是避免过拟合L2 正则化 最常用 也被称为weight decayL1 正则化实际上，可以将Logistic Regression看做是仅含有一个神经元的单层的神经网络！正则化是如何避免overfitting的，换句话说怎么减小方差（variance）的？使得w变小—&gt;z变小—&gt;导致激活函数所取范围接近线性—&gt;避免overfitting，即避免高维非线性 What is L2-regularization actually doing?: L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes. Dropput 正则化：inverted dropout///keep-prob 一层的unit个数越多过拟合的可能越大，所以keep probability可以设置的小一些dropout在计算机视觉中经常用 因为输入是像素会非常多 对训练数据，例如图片进行翻转可以double训练数据数量 还有旋转、剪裁 几乎没有花费Early stoppingnormalizing training sets 为的是加速梯度下降算法，增加优化的步长如果网络层数非常大，会导致梯度下降传递的值指数型增大或减小，为避免，应当合理的初始化weight，使其接近1 12.27gradient checking 反向传递函数容易有bug又不易察觉，梯度检查就是检查导数算的对不对，可以增加对反向传递函数实现的正确性的信心Debugging: Gradient Checking 参考资料","raw":"---\ntitle: deeplearning.ai\ndate: 2018-12-18 10:08:59\ntags:\n    - Andrew Ng\n    - Deeplearning\n    - AI\n---\n\n# Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization\n\ntrain/dev/test data set 在过去通常 60/20/20% 的比例，总样本数在10,000  \n大数据时代通常在 98/1/1 或者后两个更小的比例，总样本在1,000,000  \n  \nhigh bias&high variance  \n判断网络模型高偏差还是高方差还是两者都有的方法：  \n    训练集上的错误率过高就是高偏差（例：人错误率，也称base error 1%，模型训练集上错误率15%，模型在开发集上错误率16%）  \n    开发集上的错误率比训练集上的错误率高过多是高方差（例：人错误率14%，模型训练集上错误率15%，模型在开发集上错误率30%）  \n  \n高偏差-->更大的网络  \n高方差-->更多的数据-->可能导致偏差变高-->高偏差  \n\n## Regularization正则化\n\n为的是避免过拟合  \nL2 正则化 最常用 也被称为weight decay  \nL1 正则化  \n**实际上，可以将Logistic Regression看做是仅含有一个神经元的单层的神经网络！**  \n正则化是如何避免overfitting的，换句话说怎么减小方差（variance）的？  \n使得w变小-->z变小-->导致激活函数所取范围接近线性-->避免overfitting，即避免高维非线性  \n  \nWhat is L2-regularization actually doing?:  \n\nL2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes.   \n  \nDropput 正则化：  \ninverted dropout///keep-prob 一层的unit个数越多过拟合的可能越大，所以keep probability可以设置的小一些  \ndropout在计算机视觉中经常用 因为输入是像素会非常多  \n  \n对训练数据，例如图片进行翻转可以double训练数据数量 还有旋转、剪裁 几乎没有花费  \nEarly stopping  \nnormalizing training sets 为的是加速梯度下降算法，增加优化的步长  \n如果网络层数非常大，会导致梯度下降传递的值指数型增大或减小，为避免，应当合理的初始化weight，使其接近1  \n  \n12.27  \ngradient checking 反向传递函数容易有bug又不易察觉，梯度检查就是检查导数算的对不对，可以增加对反向传递函数实现的正确性的信心  \nDebugging: Gradient Checking [参考资料](http://ufldl.stanford.edu/tutorial/supervised/DebuggingGradientChecking/)  \n","content":"<h1 id=\"Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization\"><a href=\"#Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization\" class=\"headerlink\" title=\"Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization\"></a>Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</h1><p>train/dev/test data set 在过去通常 60/20/20% 的比例，总样本数在10,000<br>大数据时代通常在 98/1/1 或者后两个更小的比例，总样本在1,000,000  </p>\n<p>high bias&amp;high variance<br>判断网络模型高偏差还是高方差还是两者都有的方法：<br>    训练集上的错误率过高就是高偏差（例：人错误率，也称base error 1%，模型训练集上错误率15%，模型在开发集上错误率16%）<br>    开发集上的错误率比训练集上的错误率高过多是高方差（例：人错误率14%，模型训练集上错误率15%，模型在开发集上错误率30%）  </p>\n<p>高偏差—&gt;更大的网络<br>高方差—&gt;更多的数据—&gt;可能导致偏差变高—&gt;高偏差  </p>\n<h2 id=\"Regularization正则化\"><a href=\"#Regularization正则化\" class=\"headerlink\" title=\"Regularization正则化\"></a>Regularization正则化</h2><p>为的是避免过拟合<br>L2 正则化 最常用 也被称为weight decay<br>L1 正则化<br><strong>实际上，可以将Logistic Regression看做是仅含有一个神经元的单层的神经网络！</strong><br>正则化是如何避免overfitting的，换句话说怎么减小方差（variance）的？<br>使得w变小—&gt;z变小—&gt;导致激活函数所取范围接近线性—&gt;避免overfitting，即避免高维非线性  </p>\n<p>What is L2-regularization actually doing?:  </p>\n<p>L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes.   </p>\n<p>Dropput 正则化：<br>inverted dropout///keep-prob 一层的unit个数越多过拟合的可能越大，所以keep probability可以设置的小一些<br>dropout在计算机视觉中经常用 因为输入是像素会非常多  </p>\n<p>对训练数据，例如图片进行翻转可以double训练数据数量 还有旋转、剪裁 几乎没有花费<br>Early stopping<br>normalizing training sets 为的是加速梯度下降算法，增加优化的步长<br>如果网络层数非常大，会导致梯度下降传递的值指数型增大或减小，为避免，应当合理的初始化weight，使其接近1  </p>\n<p>12.27<br>gradient checking 反向传递函数容易有bug又不易察觉，梯度检查就是检查导数算的对不对，可以增加对反向传递函数实现的正确性的信心<br>Debugging: Gradient Checking <a href=\"http://ufldl.stanford.edu/tutorial/supervised/DebuggingGradientChecking/\">参考资料</a>  </p>\n","slug":"deeplearning-ai","updated":"2019-05-04T11:31:57.269Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/12/18/deeplearning-ai/","excerpt":"","categories":[],"tags":[{"name":"Andrew Ng","slug":"Andrew-Ng","permalink":"https://blog.providencezhang.cn/tags/Andrew-Ng/"},{"name":"Deeplearning","slug":"Deeplearning","permalink":"https://blog.providencezhang.cn/tags/Deeplearning/"},{"name":"AI","slug":"AI","permalink":"https://blog.providencezhang.cn/tags/AI/"}]},{"title":"pytorch入门教程","date":"2018-11-19T13:02:00.000Z","path":"2018/11/19/pytorch入门教程/","text":"任务目标对Cifar-10图像数据集，用卷积神经网络进行分类，统计正确率。学会安装pytorch开源深度学习框架并调用它的接口。直接采用pytorch针对Cifar-10数据集已训练好的网络模型，只做测试。 实验过程准备阶段开发环境：windows10+anaconda+vscode，python3.6，pytorch0.4.1。首先安装anaconda，内置的环境配置功能，Spyder、JupterNotebook工具都能提高学习和开发效率；因为要使用GPU加速训练，选择合适的CUDA版本进行安装，我使用的是9.2版本。根据自己的环境在pytorch官网查找对应的安装命令： conda install pytorch cuda92 -c pytorch pip3 install torchvision 图像分类Torchvision提供了数据集的下载API，可以很方便的下载Cifar-10数据集并分为训练集和测试集；成功载入数据后，开始搭建神经网络，定义神经网络的层次结构以及正向传递函数；初始化一个网络对象并载入GPU（使用CPU训练可以省略这个步骤）；下面定义训练函数，损失函数选择交叉熵损失函数，优化函数选择梯度下降算法，训练的每一次迭代中使用损失函数进行反向传递，优化器更新参数；下面进入测试阶段，统计10000张测试图片的正确率，统计每一类图片（1000张）的正确率。 Pytorch APITorchvision.datasets 数据集Torch.nn 神经网络模块Torch.optim 用于实现多种优化算法的包 torch.utils.data.DataLoader 载入数据（需要注意的是该方法第四个参数决定是否使用多线程载入数据，而windows上的python对于多线程的支持与linux不同）nn.conv2d() 卷积层nn.maxpool2d() 池化层nn.zeropad2d() 填充边界nn.linear() 线性变化nn.CrossEntropyLoss() 交叉熵损失函数optim.SGD 梯度下降算法torch.max() 返回张量中最大的值 保存和载入模型保存模型torch.save(net.state_dict(), ‘./MyTrainedModel/pretrained.pth’)载入模型net.load_state_dict(torch.load(‘./MyTrainedModel/pretrained.pth’))net.eval()","raw":"---\ntitle: pytorch入门教程\ndate: 2018-11-19 21:02:00\ntags:\n    - pytorch\n    - 深度学习\n    - cifar-10\n---\n\n### 任务目标\n对Cifar-10图像数据集，用卷积神经网络进行分类，统计正确率。\n学会安装pytorch开源深度学习框架并调用它的接口。\n直接采用pytorch针对Cifar-10数据集已训练好的网络模型，只做测试。\n\n### 实验过程\n\n**准备阶段**\n开发环境：windows10+anaconda+vscode，python3.6，pytorch0.4.1。 \n首先安装anaconda，内置的环境配置功能，Spyder、JupterNotebook工具都能提高学习和开发效率； \n因为要使用GPU加速训练，选择合适的CUDA版本进行安装，我使用的是9.2版本。 \n根据自己的环境在pytorch官网查找对应的安装命令： \n\tconda install pytorch cuda92 -c pytorch \n\tpip3 install torchvision \n\n**图像分类**\nTorchvision提供了数据集的下载API，可以很方便的下载Cifar-10数据集并分为训练集和测试集； \n成功载入数据后，开始搭建神经网络，定义神经网络的层次结构以及正向传递函数； \n初始化一个网络对象并载入GPU（使用CPU训练可以省略这个步骤）； \n下面定义训练函数，损失函数选择交叉熵损失函数，优化函数选择梯度下降算法，训练的每一次迭代中使用损失函数进行反向传递，优化器更新参数； \n下面进入测试阶段，统计10000张测试图片的正确率，统计每一类图片（1000张）的正确率。 \n\n**Pytorch API**\nTorchvision.datasets\t数据集 \nTorch.nn\t\t神经网络模块 \nTorch.optim\t用于实现多种优化算法的包 \n\ntorch.utils.data.DataLoader\t载入数据（需要注意的是该方法第四个参数决定是否使用多线程载入数据，而windows上的python对于多线程的支持与linux不同） \nnn.conv2d()\t卷积层 \nnn.maxpool2d()\t\t池化层 \nnn.zeropad2d()\t\t填充边界 \nnn.linear()\t\t\t线性变化 \nnn.CrossEntropyLoss()\t交叉熵损失函数 \noptim.SGD\t\t\t梯度下降算法 \ntorch.max()\t\t\t返回张量中最大的值 \n\n**保存和载入模型**\n保存模型 \ntorch.save(net.state_dict(), './MyTrainedModel/pretrained.pth') \n载入模型 \nnet.load_state_dict(torch.load('./MyTrainedModel/pretrained.pth')) \nnet.eval() ","content":"<h3 id=\"任务目标\"><a href=\"#任务目标\" class=\"headerlink\" title=\"任务目标\"></a>任务目标</h3><p>对Cifar-10图像数据集，用卷积神经网络进行分类，统计正确率。<br>学会安装pytorch开源深度学习框架并调用它的接口。<br>直接采用pytorch针对Cifar-10数据集已训练好的网络模型，只做测试。</p>\n<h3 id=\"实验过程\"><a href=\"#实验过程\" class=\"headerlink\" title=\"实验过程\"></a>实验过程</h3><p><strong>准备阶段</strong><br>开发环境：windows10+anaconda+vscode，python3.6，pytorch0.4.1。<br>首先安装anaconda，内置的环境配置功能，Spyder、JupterNotebook工具都能提高学习和开发效率；<br>因为要使用GPU加速训练，选择合适的CUDA版本进行安装，我使用的是9.2版本。<br>根据自己的环境在pytorch官网查找对应的安装命令：<br>    conda install pytorch cuda92 -c pytorch<br>    pip3 install torchvision </p>\n<p><strong>图像分类</strong><br>Torchvision提供了数据集的下载API，可以很方便的下载Cifar-10数据集并分为训练集和测试集；<br>成功载入数据后，开始搭建神经网络，定义神经网络的层次结构以及正向传递函数；<br>初始化一个网络对象并载入GPU（使用CPU训练可以省略这个步骤）；<br>下面定义训练函数，损失函数选择交叉熵损失函数，优化函数选择梯度下降算法，训练的每一次迭代中使用损失函数进行反向传递，优化器更新参数；<br>下面进入测试阶段，统计10000张测试图片的正确率，统计每一类图片（1000张）的正确率。 </p>\n<p><strong>Pytorch API</strong><br>Torchvision.datasets    数据集<br>Torch.nn        神经网络模块<br>Torch.optim    用于实现多种优化算法的包 </p>\n<p>torch.utils.data.DataLoader    载入数据（需要注意的是该方法第四个参数决定是否使用多线程载入数据，而windows上的python对于多线程的支持与linux不同）<br>nn.conv2d()    卷积层<br>nn.maxpool2d()        池化层<br>nn.zeropad2d()        填充边界<br>nn.linear()            线性变化<br>nn.CrossEntropyLoss()    交叉熵损失函数<br>optim.SGD            梯度下降算法<br>torch.max()            返回张量中最大的值 </p>\n<p><strong>保存和载入模型</strong><br>保存模型<br>torch.save(net.state_dict(), ‘./MyTrainedModel/pretrained.pth’)<br>载入模型<br>net.load_state_dict(torch.load(‘./MyTrainedModel/pretrained.pth’))<br>net.eval() </p>\n","slug":"pytorch入门教程","updated":"2019-05-04T11:31:57.271Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/11/19/pytorch%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://blog.providencezhang.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"pytorch","slug":"pytorch","permalink":"https://blog.providencezhang.cn/tags/pytorch/"},{"name":"cifar-10","slug":"cifar-10","permalink":"https://blog.providencezhang.cn/tags/cifar-10/"}]},{"title":"网络与信息安全总结","date":"2018-11-04T08:10:17.000Z","path":"2018/11/04/网络与信息安全总结/","text":"五种块加密操作模式总结 Electronic Code Book(ECB) ECB模式是最直接的块加密方法，将明文分成若干n-bit的块，然后分别进行块加密。过程如下所示：加密：yi = e(xi) 其中xi等大小为n解密：xi = e^-1(yi)因此ECB模式的速度很快，此外，该模式下各块可以并行操作无需同步，也就是说解密方可以在得到所有块之前就开始进行解密。同时一个字节的错误（丢失）只会影响到其所在块。缺点在于，只要其加密密钥不变，相同明文生成的密文也将一致，最直观的例子就是使用ECB模式加密位图，可以很明显的看出原图的样子，这导致该模式易受到攻击。 Cipher Block Chaining(CBC) CBC模式不同于ECB模式，该模式下所有块被看作是一条完整的消息。CBC模式使用初始向量(Initialization Vector)保证加密的不确定性。第一个块的明文与IV进行与或运算，然后通过块加密算法进行加密。生成的密文作为下一个块的IV，以此类推，这个过程被称为反馈机制。过程如下所示：加密： y1 = e(xi XOR IV) yi = e(xi XOR yi-1), 以此类推解密： x1 = (e^-1(yi) XOR IV) xi = (e^-1(yi) XOR yi-1), 以此类推CBC模式最为常用，合理选择IV的情况下可以很大程度抵御攻击，但缺点是其不支持并行。 Cipher Feedback(CFB) CFB模式对IV进行加密，再与明文进行与或运算，生成的密文作为下一块的IV。CFB与OFB模式都将块加密当作流加密处理。加密过程不能并行，解密过程可以。同时如果一个密文损坏，将有两个明文块受损。过程如下所示：加密：y1=e(IV) XOR x1yi=(e(yi-1) XOR xi)，以此类推解密：x1=(e(IV) XOR y1)xi=(e(yi-1) XOR yi)，以此类推 Output Feedback(OFB) 与CFB模式类似，区别在于作为下一块IV的数据由与明文与或运算后的密文变为运算之前的密文。如果一个明文或者密文损坏，只有一个相应的密文或者明文损坏，并可以使用校正算法恢复损坏部分的先前值。过程如下：加密：s1= e(IV); y1=(s1 XOR x1)si = e(si-1); yi=(si XOR xi)，以此类推解密：s1= e(IV); x1=(s1 XOR y1)si = e(si-1); xi=(si XOR yi)，以此类推 Counter(CTR) CTR模式使块加密类似于流加密，每块采用一个随机数加计数器作为IV，经过加密运算后与明文进行与或运算后生成密文。优点在于加密解密都可以并行，明文密文一个损坏只影响一个相应输出，并可以使用校正算法恢复。过程如下：加密：yi = (e(IV || CTRi) XOR xi)解密：xi = (e(IV || CTRi) XOR yi) 定性分析与比较：ECB模式是最直接的使用块加密算法的方式，该模式速度快但是安全程度低；CBC弥补了ECB模式安全性上的缺陷，安全性高，但是其加密过程不支持并行，会导致效率较低；CFB和OFB模式极为相似，两个模式的加密与解密过程一致并且可以减少代码行数，但是与CBC相同，加密过程不支持并行，使得效率较低，安全性高；最后的CTR模式支持并行，理论上效率最高，安全性高，在实际中也使用最为广泛。 参考资料pdf加密文本、图片的脚本","raw":"---\ntitle: 网络与信息安全总结\ndate: 2018-11-04 16:10:17\ntags: \n    - 研究生课程\n    - 信息安全\n    - 加密\n    - 随机数\n    - 数字签名\n---\n\n# 五种块加密操作模式总结\n\n1. Electronic Code Book(ECB)\n\nECB模式是最直接的块加密方法，将明文分成若干n-bit的块，然后分别进行块加密。过程如下所示：\n加密：  \nyi = e(xi) 其中xi等大小为n  \n解密：  \nxi = e^-1(yi)  \n因此ECB模式的速度很快，此外，该模式下各块可以并行操作无需同步，也就是说解密方可以在得到所有块之前就开始进行解密。同时一个字节的错误（丢失）只会影响到其所在块。缺点在于，只要其加密密钥不变，相同明文生成的密文也将一致，最直观的例子就是使用ECB模式加密位图，可以很明显的看出原图的样子，这导致该模式易受到攻击。\n\n2. Cipher Block Chaining(CBC)\n\nCBC模式不同于ECB模式，该模式下所有块被看作是一条完整的消息。CBC模式使用初始向量(Initialization Vector)保证加密的不确定性。第一个块的明文与IV进行与或运算，然后通过块加密算法进行加密。生成的密文作为下一个块的IV，以此类推，这个过程被称为反馈机制。过程如下所示：\n加密：  \n    y1 = e(xi XOR IV)  \n    yi = e(xi XOR yi-1), 以此类推  \n解密：  \n    x1 = (e^-1(yi) XOR IV)  \n    xi = (e^-1(yi) XOR yi-1), 以此类推  \nCBC模式最为常用，合理选择IV的情况下可以很大程度抵御攻击，但缺点是其不支持并行。\n\n3. Cipher Feedback(CFB)\n\nCFB模式对IV进行加密，再与明文进行与或运算，生成的密文作为下一块的IV。CFB与OFB模式都将块加密当作流加密处理。加密过程不能并行，解密过程可以。同时如果一个密文损坏，将有两个明文块受损。过程如下所示：\n加密：  \ny1=e(IV) XOR x1  \nyi=(e(yi-1) XOR xi)，以此类推  \n解密：  \nx1=(e(IV) XOR y1)  \nxi=(e(yi-1) XOR yi)，以此类推  \n\n4. Output Feedback(OFB)\n\n与CFB模式类似，区别在于作为下一块IV的数据由与明文与或运算后的密文变为运算之前的密文。如果一个明文或者密文损坏，只有一个相应的密文或者明文损坏，并可以使用校正算法恢复损坏部分的先前值。过程如下：\n加密：  \ns1= e(IV); y1=(s1 XOR x1)  \nsi = e(si-1); yi=(si XOR xi)，以此类推  \n解密：  \ns1= e(IV); x1=(s1 XOR y1)  \nsi = e(si-1); xi=(si XOR yi)，以此类推  \n\n5. Counter(CTR)\n\nCTR模式使块加密类似于流加密，每块采用一个随机数加计数器作为IV，经过加密运算后与明文进行与或运算后生成密文。优点在于加密解密都可以并行，明文密文一个损坏只影响一个相应输出，并可以使用校正算法恢复。过程如下：\n加密：  \nyi = (e(IV || CTRi) XOR xi)  \n解密：  \nxi = (e(IV || CTRi) XOR yi)  \n\n**定性分析与比较：**\nECB模式是最直接的使用块加密算法的方式，该模式速度快但是安全程度低；CBC弥补了ECB模式安全性上的缺陷，安全性高，但是其加密过程不支持并行，会导致效率较低；CFB和OFB模式极为相似，两个模式的加密与解密过程一致并且可以减少代码行数，但是与CBC相同，加密过程不支持并行，使得效率较低，安全性高；最后的CTR模式支持并行，理论上效率最高，安全性高，在实际中也使用最为广泛。\n\n参考资料[pdf](ref.pdf)\n加密[文本](text.py)、[图片](pic.py)的脚本","content":"<h1 id=\"五种块加密操作模式总结\"><a href=\"#五种块加密操作模式总结\" class=\"headerlink\" title=\"五种块加密操作模式总结\"></a>五种块加密操作模式总结</h1><ol>\n<li>Electronic Code Book(ECB)</li>\n</ol>\n<p>ECB模式是最直接的块加密方法，将明文分成若干n-bit的块，然后分别进行块加密。过程如下所示：<br>加密：<br>yi = e(xi) 其中xi等大小为n<br>解密：<br>xi = e^-1(yi)<br>因此ECB模式的速度很快，此外，该模式下各块可以并行操作无需同步，也就是说解密方可以在得到所有块之前就开始进行解密。同时一个字节的错误（丢失）只会影响到其所在块。缺点在于，只要其加密密钥不变，相同明文生成的密文也将一致，最直观的例子就是使用ECB模式加密位图，可以很明显的看出原图的样子，这导致该模式易受到攻击。</p>\n<ol>\n<li>Cipher Block Chaining(CBC)</li>\n</ol>\n<p>CBC模式不同于ECB模式，该模式下所有块被看作是一条完整的消息。CBC模式使用初始向量(Initialization Vector)保证加密的不确定性。第一个块的明文与IV进行与或运算，然后通过块加密算法进行加密。生成的密文作为下一个块的IV，以此类推，这个过程被称为反馈机制。过程如下所示：<br>加密：<br>    y1 = e(xi XOR IV)<br>    yi = e(xi XOR yi-1), 以此类推<br>解密：<br>    x1 = (e^-1(yi) XOR IV)<br>    xi = (e^-1(yi) XOR yi-1), 以此类推<br>CBC模式最为常用，合理选择IV的情况下可以很大程度抵御攻击，但缺点是其不支持并行。</p>\n<ol>\n<li>Cipher Feedback(CFB)</li>\n</ol>\n<p>CFB模式对IV进行加密，再与明文进行与或运算，生成的密文作为下一块的IV。CFB与OFB模式都将块加密当作流加密处理。加密过程不能并行，解密过程可以。同时如果一个密文损坏，将有两个明文块受损。过程如下所示：<br>加密：<br>y1=e(IV) XOR x1<br>yi=(e(yi-1) XOR xi)，以此类推<br>解密：<br>x1=(e(IV) XOR y1)<br>xi=(e(yi-1) XOR yi)，以此类推  </p>\n<ol>\n<li>Output Feedback(OFB)</li>\n</ol>\n<p>与CFB模式类似，区别在于作为下一块IV的数据由与明文与或运算后的密文变为运算之前的密文。如果一个明文或者密文损坏，只有一个相应的密文或者明文损坏，并可以使用校正算法恢复损坏部分的先前值。过程如下：<br>加密：<br>s1= e(IV); y1=(s1 XOR x1)<br>si = e(si-1); yi=(si XOR xi)，以此类推<br>解密：<br>s1= e(IV); x1=(s1 XOR y1)<br>si = e(si-1); xi=(si XOR yi)，以此类推  </p>\n<ol>\n<li>Counter(CTR)</li>\n</ol>\n<p>CTR模式使块加密类似于流加密，每块采用一个随机数加计数器作为IV，经过加密运算后与明文进行与或运算后生成密文。优点在于加密解密都可以并行，明文密文一个损坏只影响一个相应输出，并可以使用校正算法恢复。过程如下：<br>加密：<br>yi = (e(IV || CTRi) XOR xi)<br>解密：<br>xi = (e(IV || CTRi) XOR yi)  </p>\n<p><strong>定性分析与比较：</strong><br>ECB模式是最直接的使用块加密算法的方式，该模式速度快但是安全程度低；CBC弥补了ECB模式安全性上的缺陷，安全性高，但是其加密过程不支持并行，会导致效率较低；CFB和OFB模式极为相似，两个模式的加密与解密过程一致并且可以减少代码行数，但是与CBC相同，加密过程不支持并行，使得效率较低，安全性高；最后的CTR模式支持并行，理论上效率最高，安全性高，在实际中也使用最为广泛。</p>\n<p>参考资料<a href=\"ref.pdf\">pdf</a><br>加密<a href=\"text.py\">文本</a>、<a href=\"pic.py\">图片</a>的脚本</p>\n","slug":"网络与信息安全总结","updated":"2019-05-04T11:31:57.320Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/11/04/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%80%BB%E7%BB%93/","excerpt":"","categories":[],"tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://blog.providencezhang.cn/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"},{"name":"研究生课程","slug":"研究生课程","permalink":"https://blog.providencezhang.cn/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"},{"name":"加密","slug":"加密","permalink":"https://blog.providencezhang.cn/tags/%E5%8A%A0%E5%AF%86/"},{"name":"随机数","slug":"随机数","permalink":"https://blog.providencezhang.cn/tags/%E9%9A%8F%E6%9C%BA%E6%95%B0/"},{"name":"数字签名","slug":"数字签名","permalink":"https://blog.providencezhang.cn/tags/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/"}]},{"title":"IPhoneX的叉","date":"2018-10-23T00:02:23.000Z","path":"2018/10/23/LostMyIPhone/","text":"钓鱼网站攻击记录XSScross site script网页里有input都可以插入html代码，一般是返回服务器的cookie，找到服务器管理员的相关信息。也可以从url插入代码 burpsuite功能强大的web攻击集成环境，community版本提供大部分功能，但是需要手动设置参数，企业版提供scanner扫描漏洞。 已知的钓鱼网站防护 限制input长度 将input的值使用document.* 方法转为%..%..样式的字符串，使其无法在html中编译 限制ip，每次进入网页的url都有唯一编码，看起来是md5加密的，一旦提交过信息封ip","raw":"---\ntitle: IPhoneX的叉\ndate: 2018-10-23 08:02:23\ntags: \n    - 信息安全\n    - XSS\n    - 钓鱼网站\n    - burpsuite\n---\n\n# 钓鱼网站攻击记录\n\n## XSS\n\n_cross site script_\n网页里有input都可以插入html代码，一般是返回服务器的cookie，找到服务器管理员的相关信息。\n也可以从url插入代码\n\n## burpsuite\n\n功能强大的web攻击集成环境，community版本提供大部分功能，但是需要手动设置参数，企业版提供scanner扫描漏洞。\n\n## 已知的钓鱼网站防护\n\n1. 限制input长度\n2. 将input的值使用document.* 方法转为%..%..样式的字符串，使其无法在html中编译\n3. 限制ip，每次进入网页的url都有唯一编码，看起来是md5加密的，一旦提交过信息封ip\n","content":"<h1 id=\"钓鱼网站攻击记录\"><a href=\"#钓鱼网站攻击记录\" class=\"headerlink\" title=\"钓鱼网站攻击记录\"></a>钓鱼网站攻击记录</h1><h2 id=\"XSS\"><a href=\"#XSS\" class=\"headerlink\" title=\"XSS\"></a>XSS</h2><p><em>cross site script</em><br>网页里有input都可以插入html代码，一般是返回服务器的cookie，找到服务器管理员的相关信息。<br>也可以从url插入代码</p>\n<h2 id=\"burpsuite\"><a href=\"#burpsuite\" class=\"headerlink\" title=\"burpsuite\"></a>burpsuite</h2><p>功能强大的web攻击集成环境，community版本提供大部分功能，但是需要手动设置参数，企业版提供scanner扫描漏洞。</p>\n<h2 id=\"已知的钓鱼网站防护\"><a href=\"#已知的钓鱼网站防护\" class=\"headerlink\" title=\"已知的钓鱼网站防护\"></a>已知的钓鱼网站防护</h2><ol>\n<li>限制input长度</li>\n<li>将input的值使用document.* 方法转为%..%..样式的字符串，使其无法在html中编译</li>\n<li>限制ip，每次进入网页的url都有唯一编码，看起来是md5加密的，一旦提交过信息封ip</li>\n</ol>\n","slug":"LostMyIPhone","updated":"2019-06-06T14:26:27.996Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/10/23/LostMyIPhone/","excerpt":"","categories":[],"tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://blog.providencezhang.cn/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"},{"name":"XSS","slug":"XSS","permalink":"https://blog.providencezhang.cn/tags/XSS/"},{"name":"钓鱼网站","slug":"钓鱼网站","permalink":"https://blog.providencezhang.cn/tags/%E9%92%93%E9%B1%BC%E7%BD%91%E7%AB%99/"},{"name":"burpsuite","slug":"burpsuite","permalink":"https://blog.providencezhang.cn/tags/burpsuite/"}]},{"title":"核聚变","date":"2018-05-06T04:12:37.000Z","path":"2018/05/06/核聚变/","text":"先说说嘉宾女流、女王盐、羽毛、伯爵、谷歌…永远都是前后脚差一步，就是见不到。五仁叔还是随和，下午抽时间进行了集中签名合影。因为只计划去一天，如果时间再充裕些应该去wegame，ps展区蹲他们一波。有些遗憾。吹哥Jonathan Blow被安排在了6号压轴出场，5号其实也在现场，只不过在采访间，不对外开放，由女流进行采访。这部分确实去现场还不如在家看直播。然后是Mr.Quin，没想到秦川现在这么火，一同来的朋友进场第一件事就是光顾quin先生的店铺，黑魂3-21期居然也在五月五号晚更新了，两万人同时观看，惊了。能消费的物品基本上就是T-shirt、抱枕、挂件，讲真确实无法激起我这种非秦国人消费的欲望。一姐——王妙一也在现场，《Will美好世界》有提供试玩，对她和她的作品知道的不多，不过能感受到她很愿意与玩家互动，交流看法。据她所言，新游戏已经在构思了，但是离发布应该还有很长的时间。 周边、贩卖区、消费相关上边提到了秦先生的店铺，这里展开评价下。印象比较深刻的是官方推出的LootBox——200块，两件T、两个马克杯、挂件、贴纸一些。肯定比单买要便宜，还有抽奖性质，有可能获得额外礼品。不好的地方在于L以上的号码10点之前就抢没了，每天限量，早起抢不到就只能第二天了；而且T、杯子的样式完全看脸，如果不喜欢随机到的样式，购物体验不会很好。然后是机核的吉考斯工业，专卖8周年的机组服装、包、挂件，价格略贵（最后附价格照片），但是蛮好看的。其他的..小店，漫画书，育碧的模型有一些，光顾的人不算多。关于饮食中午二楼提供盒饭，30一份至少看着干净，毕竟大家是来玩的。水的话自带比较方便。 游戏试玩PlayStation完爆Xbox，独立游戏真的多，游戏大厂表现平平。索尼有战神4和底特律变人，微软是Forza和古墓丽影崛起。育碧提供了起源和彩六。战马工作室也来了！看起来很重视中国市场啊，制作人一直在展区，很热情的跟大家互动。游戏很迷，大概是短短15分钟没法展现它的魅力吧。 红蓝对抗四个红蓝对抗——马车、GangBeasts、炸弹人、OverCooked都是初体验，但是全胜，还是有点膨胀的，平均排队时间15分钟上下。地狱挑战有火车、猎天使魔女2、马里奥制造和俄罗斯方块..如果不提前练习，确实很难完成挑战。最后红队微弱优势赢下第一天的红蓝对抗，临走是听见工作人员对着对讲机说有人中了switch，是真的牛逼疯了（3500个红队玩家抽4台switch，挂奖卡挂出“牛比疯了”就是switch）。 总的来说，第一次核聚变体验还是不错的，走的很累，对于没有switch的我玩了个够（在场的玩家感觉三个人里就有一个有switch）。大佬们露脸都不提前通知的，体验有点差，不知道是官方故意（怕拥堵）还是没有照顾到我们这些运气不好的玩家。真的想消费，但真的没什么特喜欢的（摊手。不过托机核的福，已经下单战神4了:)。","raw":"---\ntitle: 核聚变\ndate: 2018-05-06 12:12:37\ntags: \n    - 机核\n    - 游戏展\ncategories: 随笔\n---\n\n### 先说说嘉宾\n\n女流、女王盐、羽毛、伯爵、谷歌...永远都是前后脚差一步，就是见不到。五仁叔还是随和，下午抽时间进行了集中签名合影。因为只计划去一天，如果时间再充裕些应该去wegame，ps展区蹲他们一波。有些遗憾。吹哥Jonathan Blow被安排在了6号压轴出场，5号其实也在现场，只不过在采访间，不对外开放，由女流进行采访。这部分确实去现场还不如在家看直播。\n然后是Mr.Quin，没想到秦川现在这么火，一同来的朋友进场第一件事就是光顾quin先生的店铺，黑魂3-21期居然也在五月五号晚更新了，两万人同时观看，惊了。能消费的物品基本上就是T-shirt、抱枕、挂件，讲真确实无法激起我这种非秦国人消费的欲望。  \n一姐——王妙一也在现场，《Will美好世界》有提供试玩，对她和她的作品知道的不多，不过能感受到她很愿意与玩家互动，交流看法。据她所言，新游戏已经在构思了，但是离发布应该还有很长的时间。  \n\n### 周边、贩卖区、消费相关\n\n上边提到了秦先生的店铺，这里展开评价下。印象比较深刻的是官方推出的LootBox——200块，两件T、两个马克杯、挂件、贴纸一些。肯定比单买要便宜，还有抽奖性质，有可能获得额外礼品。不好的地方在于L以上的号码10点之前就抢没了，每天限量，早起抢不到就只能第二天了；而且T、杯子的样式完全看脸，如果不喜欢随机到的样式，购物体验不会很好。然后是机核的吉考斯工业，专卖8周年的机组服装、包、挂件，价格略贵（最后附价格照片），但是蛮好看的。其他的..小店，漫画书，育碧的模型有一些，光顾的人不算多。  \n关于饮食中午二楼提供盒饭，30一份至少看着干净，毕竟大家是来玩的。水的话自带比较方便。\n\n### 游戏试玩\n\nPlayStation完爆Xbox，独立游戏真的多，游戏大厂表现平平。    \n索尼有战神4和底特律变人，微软是Forza和古墓丽影崛起。育碧提供了起源和彩六。  \n战马工作室也来了！看起来很重视中国市场啊，制作人一直在展区，很热情的跟大家互动。游戏很迷，大概是短短15分钟没法展现它的魅力吧。\n\n### 红蓝对抗\n\n四个红蓝对抗——马车、GangBeasts、炸弹人、OverCooked都是初体验，但是全胜，还是有点膨胀的，平均排队时间15分钟上下。地狱挑战有火车、猎天使魔女2、马里奥制造和俄罗斯方块..如果不提前练习，确实很难完成挑战。最后红队微弱优势赢下第一天的红蓝对抗，临走是听见工作人员对着对讲机说有人中了switch，是真的牛逼疯了（3500个红队玩家抽4台switch，挂奖卡挂出“牛比疯了”就是switch）。  \n\n总的来说，第一次核聚变体验还是不错的，走的很累，对于没有switch的我玩了个够（在场的玩家感觉三个人里就有一个有switch）。大佬们露脸都不提前通知的，体验有点差，不知道是官方故意（怕拥堵）还是没有照顾到我们这些运气不好的玩家。真的想消费，但真的没什么特喜欢的（摊手。不过  \n**托机核的福，已经下单战神4了:)。**  \n\n{% asset_img 微信图片_20180506143855.jpg 门票 %}\n{% asset_img 微信图片_201805061438551.jpg 红蓝对抗 %}\n{% asset_img 微信图片_201805061438552.jpg 地狱挑战 %}\n{% asset_img 微信图片_201805061438553.jpg 部分标价 %}\n{% asset_img 微信图片_201805061438554.jpg 玩家地区 %}\n{% asset_img 微信图片_201805061438555.jpg OW %}\n{% asset_img 微信图片_201805061438556.jpg overcooked %}\n{% asset_img 微信图片_201805061438557.jpg 战马 %}\n{% asset_img 微信图片_201805061438558.jpg 战神 %}\n{% asset_img 微信图片_201805061438559.jpg 底特律1 %}\n{% asset_img 微信图片_2018050614385510.jpg 底特律2 %}\n{% asset_img 微信图片_2018050614385511.jpg 大门 %}\n{% asset_img 微信图片_2018050614385512.jpg 场馆 %}","content":"<h3 id=\"先说说嘉宾\"><a href=\"#先说说嘉宾\" class=\"headerlink\" title=\"先说说嘉宾\"></a>先说说嘉宾</h3><p>女流、女王盐、羽毛、伯爵、谷歌…永远都是前后脚差一步，就是见不到。五仁叔还是随和，下午抽时间进行了集中签名合影。因为只计划去一天，如果时间再充裕些应该去wegame，ps展区蹲他们一波。有些遗憾。吹哥Jonathan Blow被安排在了6号压轴出场，5号其实也在现场，只不过在采访间，不对外开放，由女流进行采访。这部分确实去现场还不如在家看直播。<br>然后是Mr.Quin，没想到秦川现在这么火，一同来的朋友进场第一件事就是光顾quin先生的店铺，黑魂3-21期居然也在五月五号晚更新了，两万人同时观看，惊了。能消费的物品基本上就是T-shirt、抱枕、挂件，讲真确实无法激起我这种非秦国人消费的欲望。<br>一姐——王妙一也在现场，《Will美好世界》有提供试玩，对她和她的作品知道的不多，不过能感受到她很愿意与玩家互动，交流看法。据她所言，新游戏已经在构思了，但是离发布应该还有很长的时间。  </p>\n<h3 id=\"周边、贩卖区、消费相关\"><a href=\"#周边、贩卖区、消费相关\" class=\"headerlink\" title=\"周边、贩卖区、消费相关\"></a>周边、贩卖区、消费相关</h3><p>上边提到了秦先生的店铺，这里展开评价下。印象比较深刻的是官方推出的LootBox——200块，两件T、两个马克杯、挂件、贴纸一些。肯定比单买要便宜，还有抽奖性质，有可能获得额外礼品。不好的地方在于L以上的号码10点之前就抢没了，每天限量，早起抢不到就只能第二天了；而且T、杯子的样式完全看脸，如果不喜欢随机到的样式，购物体验不会很好。然后是机核的吉考斯工业，专卖8周年的机组服装、包、挂件，价格略贵（最后附价格照片），但是蛮好看的。其他的..小店，漫画书，育碧的模型有一些，光顾的人不算多。<br>关于饮食中午二楼提供盒饭，30一份至少看着干净，毕竟大家是来玩的。水的话自带比较方便。</p>\n<h3 id=\"游戏试玩\"><a href=\"#游戏试玩\" class=\"headerlink\" title=\"游戏试玩\"></a>游戏试玩</h3><p>PlayStation完爆Xbox，独立游戏真的多，游戏大厂表现平平。<br>索尼有战神4和底特律变人，微软是Forza和古墓丽影崛起。育碧提供了起源和彩六。<br>战马工作室也来了！看起来很重视中国市场啊，制作人一直在展区，很热情的跟大家互动。游戏很迷，大概是短短15分钟没法展现它的魅力吧。</p>\n<h3 id=\"红蓝对抗\"><a href=\"#红蓝对抗\" class=\"headerlink\" title=\"红蓝对抗\"></a>红蓝对抗</h3><p>四个红蓝对抗——马车、GangBeasts、炸弹人、OverCooked都是初体验，但是全胜，还是有点膨胀的，平均排队时间15分钟上下。地狱挑战有火车、猎天使魔女2、马里奥制造和俄罗斯方块..如果不提前练习，确实很难完成挑战。最后红队微弱优势赢下第一天的红蓝对抗，临走是听见工作人员对着对讲机说有人中了switch，是真的牛逼疯了（3500个红队玩家抽4台switch，挂奖卡挂出“牛比疯了”就是switch）。  </p>\n<p>总的来说，第一次核聚变体验还是不错的，走的很累，对于没有switch的我玩了个够（在场的玩家感觉三个人里就有一个有switch）。大佬们露脸都不提前通知的，体验有点差，不知道是官方故意（怕拥堵）还是没有照顾到我们这些运气不好的玩家。真的想消费，但真的没什么特喜欢的（摊手。不过<br><strong>托机核的福，已经下单战神4了:)。</strong>  </p>\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"核聚变","updated":"2021-04-07T10:39:07.260Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/05/06/%E6%A0%B8%E8%81%9A%E5%8F%98/","excerpt":"","categories":[{"name":"随笔","slug":"随笔","permalink":"https://blog.providencezhang.cn/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"机核","slug":"机核","permalink":"https://blog.providencezhang.cn/tags/%E6%9C%BA%E6%A0%B8/"},{"name":"游戏展","slug":"游戏展","permalink":"https://blog.providencezhang.cn/tags/%E6%B8%B8%E6%88%8F%E5%B1%95/"}]},{"title":"中国什么时候能有3A游戏","date":"2018-04-18T14:32:50.000Z","path":"2018/04/18/中国什么时候能有3A游戏/","text":"16号，《Will:美好世界》的制作人王妙一发了一篇文章《为什么中国不会有3A游戏》，一时间游戏圈里不少人讨论。其实对国内3A这事，在我17年大三下找实习的时候就有考虑过，今天梳理记录下。 文中提到真实渲染瓶颈——次时代游戏画面已经不足以成为游戏宣传的噱头或者说买点；然后是市场选择——手游实在是太方便，太容易做（相对于策划、美术、技术都要做到A的3A游戏），太容易挣钱了。 渲染瓶颈这点对我而言确实是新思路。作为一名玩家我喜欢拥有更真实的画面，更真实的细节的游戏，但仔细想想，近年来游戏画质的进步速度确实已经放缓看COD系列这种年货便可知。如今我们选择游戏，更多的是玩法（PUBG，爆红大逃杀），剧情（巫师3），关卡设计（塞尔达），甚至是观光看高还原度的风景（GTA，看门狗，farcry）。3A在近几年失去了渲染画面这个卖点。 然后是市场选择其实就是玩家选择，玩不玩你的游戏，给不给你花钱买账。说到底还是因为玩家的素质，国内愿意买主机的少，愿意为3A配一台1W块上下的电脑的人更少。不过，2017年好在一款PUBG横空出世，推动了国内中高档PC硬件的普及，这是3A游戏的一大利好。PUBG迟早要过劲儿，因为外挂，因为土豆服务器，因为BUG等等。谁能接住这些为了PUBG买了高端PC的玩家呢？R6能回温，Steam上游戏开发者各种感谢中国玩家和游戏主播都说明想玩好游戏的玩家数量在增加，而且这些玩家愿意为玩好游戏花钱了。中国3A，有戏。 这篇blog的title是中国什么时候能有3A，跟王 的不一样，是因为我相信中国能做3A，只是时间问题。可能因为玩家素质的问题，要等到我们90这一代的孩子出来玩游戏；也可能给贪玩蓝月充钱的油腻中年人受他孩子的影响想尝试真正的好游戏，这可能只用五年。中国第一款3A，划时代的意义，游戏界的里程碑，我相信许多人盯着这项荣誉。唯一阻拦他们的就是市场经济，是资本。而降低商业风险的根本还是有人买账，是消费者，是玩家。 腾讯和一系列网游时代的厂商，培养了国内玩家，免费游戏，付费增值的玩家习惯。不能说不对，赚到钱了就是对的，对商人。对开发者、想做3A的团队，是噩梦。 摆在开发者面前的还有一座大山，国内对于游戏影音等出版物的审查。跟电影行业一样，影响会小于影视创作，国内的游戏创作也是带着枷锁跳舞。能不能写出好故事，结合好玩法，就看制作人，策划的功力了。 一点题外话技术上，目前，仅仅是目前，我认为游戏制作其实已经有固定的工业流程了。国内目前普遍的手游开发过程都是精简（但不一定残缺）的游戏开发流程。作为一线开发人员只需要具备具体某一项能力，熟悉业务操作，掌握基本的技能技巧即可。即没有过多的发挥空间，有规范化模板，重复性较高。但是还是有需要技术突破的地方，可能是底层，可能是架构上，可能是一些先进的功能需求，这部分工作需要创造力和专业知识，是真正应该努力的方向。 Jonathan Blow的游戏设计哲学是合理的疯狂（还是的落在疯狂上）g-core节目","raw":"---\ntitle: 中国什么时候能有3A游戏\ndate: 2018-04-18 22:32:50\ntags:\n    - 3A\n    - 王妙一\ncategories: 随笔\n---\n\n16号，《Will:美好世界》的制作人王妙一发了一篇文章[《为什么中国不会有3A游戏》](https://weibo.com/ttarticle/p/show?id=2309404229552229480395)，一时间游戏圈里不少人讨论。其实对国内3A这事，在我17年大三下找实习的时候就有考虑过，今天梳理记录下。  \n\n文中提到真实渲染瓶颈——次时代游戏画面已经不足以成为游戏宣传的噱头或者说买点；然后是市场选择——手游实在是太方便，太容易做（相对于策划、美术、技术都要做到A的3A游戏），太容易挣钱了。  \n\n*渲染瓶颈*这点对我而言确实是新思路。作为一名玩家我喜欢拥有更真实的画面，更真实的细节的游戏，但仔细想想，近年来游戏画质的进步速度确实已经放缓看COD系列这种年货便可知。如今我们选择游戏，更多的是玩法（PUBG，爆红大逃杀），剧情（巫师3），关卡设计（塞尔达），甚至是观光看高还原度的风景（GTA，看门狗，farcry）。3A在近几年失去了渲染画面这个卖点。  \n\n然后是*市场选择*其实就是*玩家选择*，玩不玩你的游戏，给不给你花钱买账。说到底还是因为玩家的素质，国内愿意买主机的少，愿意为3A配一台1W块上下的电脑的人更少。不过，2017年好在一款PUBG横空出世，推动了国内中高档PC硬件的普及，这是3A游戏的一大利好。PUBG迟早要过劲儿，因为外挂，因为土豆服务器，因为BUG等等。谁能接住这些为了PUBG买了高端PC的玩家呢？R6能回温，Steam上游戏开发者各种感谢中国玩家和游戏主播都说明想玩好游戏的玩家数量在增加，而且这些玩家愿意为玩好游戏花钱了。中国3A，有戏。  \n\n这篇blog的title是中国什么时候能有3A，跟王 的不一样，是因为我相信中国能做3A，只是时间问题。可能因为玩家素质的问题，要等到我们90这一代的孩子出来玩游戏；也可能给贪玩蓝月充钱的油腻中年人受他孩子的影响想尝试真正的好游戏，这可能只用五年。中国第一款3A，划时代的意义，游戏界的里程碑，我相信许多人盯着这项荣誉。唯一阻拦他们的就是市场经济，是资本。而降低商业风险的根本还是有人买账，是消费者，是玩家。  \n\n腾讯和一系列网游时代的厂商，培养了国内玩家，免费游戏，付费增值的*玩家习惯*。不能说不对，赚到钱了就是对的，对商人。对开发者、想做3A的团队，是噩梦。  \n\n摆在开发者面前的还有一座大山，国内对于游戏影音等出版物的*审查*。跟电影行业一样，影响会小于影视创作，国内的游戏创作也是带着枷锁跳舞。能不能写出好故事，结合好玩法，就看制作人，策划的功力了。  \n\n# 一点题外话\n\n技术上，目前，仅仅是目前，我认为游戏制作其实已经有固定的工业流程了。国内目前普遍的手游开发过程都是精简（但不一定残缺）的游戏开发流程。作为一线开发人员只需要具备具体某一项能力，熟悉业务操作，掌握基本的技能技巧即可。即没有过多的发挥空间，有规范化模板，重复性较高。但是还是有需要技术突破的地方，可能是底层，可能是架构上，可能是一些先进的功能需求，这部分工作需要创造力和专业知识，是真正应该努力的方向。  \n\nJonathan Blow的游戏设计哲学是合理的疯狂（还是的落在疯狂上）  \ng-core节目  \n<iframe src=\"https://www.gcores.com/volumes/95312/embed\" width=\"480\" height=\"400\" allowtransparency=\"true\" border=\"0\" frameborder=\"0\" style=\"width:480px;height:400px;\"></iframe>","content":"<p>16号，《Will:美好世界》的制作人王妙一发了一篇文章<a href=\"https://weibo.com/ttarticle/p/show?id=2309404229552229480395\">《为什么中国不会有3A游戏》</a>，一时间游戏圈里不少人讨论。其实对国内3A这事，在我17年大三下找实习的时候就有考虑过，今天梳理记录下。  </p>\n<p>文中提到真实渲染瓶颈——次时代游戏画面已经不足以成为游戏宣传的噱头或者说买点；然后是市场选择——手游实在是太方便，太容易做（相对于策划、美术、技术都要做到A的3A游戏），太容易挣钱了。  </p>\n<p><em>渲染瓶颈</em>这点对我而言确实是新思路。作为一名玩家我喜欢拥有更真实的画面，更真实的细节的游戏，但仔细想想，近年来游戏画质的进步速度确实已经放缓看COD系列这种年货便可知。如今我们选择游戏，更多的是玩法（PUBG，爆红大逃杀），剧情（巫师3），关卡设计（塞尔达），甚至是观光看高还原度的风景（GTA，看门狗，farcry）。3A在近几年失去了渲染画面这个卖点。  </p>\n<p>然后是<em>市场选择</em>其实就是<em>玩家选择</em>，玩不玩你的游戏，给不给你花钱买账。说到底还是因为玩家的素质，国内愿意买主机的少，愿意为3A配一台1W块上下的电脑的人更少。不过，2017年好在一款PUBG横空出世，推动了国内中高档PC硬件的普及，这是3A游戏的一大利好。PUBG迟早要过劲儿，因为外挂，因为土豆服务器，因为BUG等等。谁能接住这些为了PUBG买了高端PC的玩家呢？R6能回温，Steam上游戏开发者各种感谢中国玩家和游戏主播都说明想玩好游戏的玩家数量在增加，而且这些玩家愿意为玩好游戏花钱了。中国3A，有戏。  </p>\n<p>这篇blog的title是中国什么时候能有3A，跟王 的不一样，是因为我相信中国能做3A，只是时间问题。可能因为玩家素质的问题，要等到我们90这一代的孩子出来玩游戏；也可能给贪玩蓝月充钱的油腻中年人受他孩子的影响想尝试真正的好游戏，这可能只用五年。中国第一款3A，划时代的意义，游戏界的里程碑，我相信许多人盯着这项荣誉。唯一阻拦他们的就是市场经济，是资本。而降低商业风险的根本还是有人买账，是消费者，是玩家。  </p>\n<p>腾讯和一系列网游时代的厂商，培养了国内玩家，免费游戏，付费增值的<em>玩家习惯</em>。不能说不对，赚到钱了就是对的，对商人。对开发者、想做3A的团队，是噩梦。  </p>\n<p>摆在开发者面前的还有一座大山，国内对于游戏影音等出版物的<em>审查</em>。跟电影行业一样，影响会小于影视创作，国内的游戏创作也是带着枷锁跳舞。能不能写出好故事，结合好玩法，就看制作人，策划的功力了。  </p>\n<h1 id=\"一点题外话\"><a href=\"#一点题外话\" class=\"headerlink\" title=\"一点题外话\"></a>一点题外话</h1><p>技术上，目前，仅仅是目前，我认为游戏制作其实已经有固定的工业流程了。国内目前普遍的手游开发过程都是精简（但不一定残缺）的游戏开发流程。作为一线开发人员只需要具备具体某一项能力，熟悉业务操作，掌握基本的技能技巧即可。即没有过多的发挥空间，有规范化模板，重复性较高。但是还是有需要技术突破的地方，可能是底层，可能是架构上，可能是一些先进的功能需求，这部分工作需要创造力和专业知识，是真正应该努力的方向。  </p>\n<p>Jonathan Blow的游戏设计哲学是合理的疯狂（还是的落在疯狂上）<br>g-core节目  </p>\n<iframe src=\"https://www.gcores.com/volumes/95312/embed\" width=\"480\" height=\"400\" allowtransparency=\"true\" border=\"0\" frameborder=\"0\" style=\"width:480px;height:400px;\"></iframe>","slug":"中国什么时候能有3A游戏","updated":"2019-05-04T11:31:57.273Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/04/18/%E4%B8%AD%E5%9B%BD%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E8%83%BD%E6%9C%893A%E6%B8%B8%E6%88%8F/","excerpt":"","categories":[{"name":"随笔","slug":"随笔","permalink":"https://blog.providencezhang.cn/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"3A","slug":"3A","permalink":"https://blog.providencezhang.cn/tags/3A/"},{"name":"王妙一","slug":"王妙一","permalink":"https://blog.providencezhang.cn/tags/%E7%8E%8B%E5%A6%99%E4%B8%80/"}]},{"title":"完整游戏开发流程","date":"2018-04-12T13:43:40.000Z","path":"2018/04/12/完整游戏开发流程/","text":"如何完整的开发一款游戏GAD文章地址 简化： 确立核心玩法（策划团队与程序美术核心成员共同完成） Demo——验证玩法可行性 制定开发计划（原型阶段——核心阶段——迭代阶段——调整阶段） 原型阶段 更新计划 核心阶段（确定开发重点/工作重心） 正式迭代前的版本计划 开发规范需要提前做，做不好会导致返工，效率低 todo 联系软件工程理论，过程模型","raw":"---\ntitle: 完整游戏开发流程\ndate: 2018-04-12 21:43:40\ntags: \n    - GAD\n    - 开发流程\ncategories: 游戏开发\n---\n\n### 如何完整的开发一款游戏\n\nGAD文章[地址](https://mp.weixin.qq.com/s?__biz=MzA4MDc5OTg5MA==&mid=2650601307&idx=1&sn=1d38c6011cde7a332a148ff849a66ea6&chksm=8796e6a6b0e16fb0dc5e94af9225c0b59689666243e2cc26b9ef0127953d47a1c19c2ac384cc&scene=0#rd)\n\n简化：\n1. 确立核心玩法（策划团队与程序美术核心成员共同完成）\n2. Demo——验证玩法可行性\n3. 制定开发计划（原型阶段——核心阶段——迭代阶段——调整阶段）\n4. 原型阶段\n5. 更新计划\n6. 核心阶段（确定开发重点/工作重心）\n7. 正式迭代前的版本计划\n\n开发规范需要提前做，做不好会导致返工，效率低\n\ntodo 联系软件工程理论，过程模型","content":"<h3 id=\"如何完整的开发一款游戏\"><a href=\"#如何完整的开发一款游戏\" class=\"headerlink\" title=\"如何完整的开发一款游戏\"></a>如何完整的开发一款游戏</h3><p>GAD文章<a href=\"https://mp.weixin.qq.com/s?__biz=MzA4MDc5OTg5MA==&amp;mid=2650601307&amp;idx=1&amp;sn=1d38c6011cde7a332a148ff849a66ea6&amp;chksm=8796e6a6b0e16fb0dc5e94af9225c0b59689666243e2cc26b9ef0127953d47a1c19c2ac384cc&amp;scene=0#rd\">地址</a></p>\n<p>简化：</p>\n<ol>\n<li>确立核心玩法（策划团队与程序美术核心成员共同完成）</li>\n<li>Demo——验证玩法可行性</li>\n<li>制定开发计划（原型阶段——核心阶段——迭代阶段——调整阶段）</li>\n<li>原型阶段</li>\n<li>更新计划</li>\n<li>核心阶段（确定开发重点/工作重心）</li>\n<li>正式迭代前的版本计划</li>\n</ol>\n<p>开发规范需要提前做，做不好会导致返工，效率低</p>\n<p>todo 联系软件工程理论，过程模型</p>\n","slug":"完整游戏开发流程","updated":"2021-04-07T10:39:07.258Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/04/12/%E5%AE%8C%E6%95%B4%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/","excerpt":"","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://blog.providencezhang.cn/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"GAD","slug":"GAD","permalink":"https://blog.providencezhang.cn/tags/GAD/"},{"name":"开发流程","slug":"开发流程","permalink":"https://blog.providencezhang.cn/tags/%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/"}]},{"title":"PUBG-Unity","date":"2018-04-11T13:39:17.000Z","path":"2018/04/11/PUBG-Unity/","text":"游戏功能（技术实现） 安全区系统(Electric Field) 游戏计时器 根据预设点位(Pos)和尺寸(Scale)按时间触发缩圈 伤害判定 Player FP Controller Player物品栏 Player生命状态 AI 巡逻系统 攻击系统 AI生命状态 武器系统 物理子弹/射线子弹 子弹扩散 UI 开始菜单 主游戏界面—小地图 主游戏界面—player信息 主游戏界面—弹出类消息 背包界面 地图 方向指示 外部资源Next-Gen FPStodo 结构分析 功能改进 MapMagictodo emmm 截图 先写论文 写完在更","raw":"---\ntitle: PUBG-Unity\ndate: 2018-04-11 21:39:17\ntags: \n    - Unity\n    - FPS\n    - Sandbox\ncategories: 个人项目\n---\n\n### 游戏功能（技术实现）\n\n1. 安全区系统(Electric Field)\n\n    游戏计时器  \n    根据预设点位(Pos)和尺寸(Scale)按时间触发缩圈  \n    伤害判定\n\n2. Player\n\n    FP Controller  \n    Player物品栏  \n    Player生命状态  \n\n3. AI\n\n    巡逻系统  \n    攻击系统  \n    AI生命状态  \n\n4. 武器系统\n\n    物理子弹/射线子弹  \n    子弹扩散  \n\n5. UI\n\n    开始菜单  \n    主游戏界面--小地图\n    主游戏界面--player信息\n    主游戏界面--弹出类消息\n    背包界面\n    地图\n    方向指示\n\n\n### 外部资源\n\n## Next-Gen FPS\n\ntodo 结构分析 功能改进\n\n## MapMagic\n\ntodo emmm\n\n### 截图\n{% asset_img 1.png 游戏截图 %}\n{% asset_img 2.png 游戏截图 %}\n{% asset_img 3.png 游戏截图 %}\n{% asset_img 4.png 游戏截图 %}\n{% asset_img 5.png 游戏截图 %}\n{% asset_img 6.png 游戏截图 %}\n\n\n先写论文 写完在更","content":"<h3 id=\"游戏功能（技术实现）\"><a href=\"#游戏功能（技术实现）\" class=\"headerlink\" title=\"游戏功能（技术实现）\"></a>游戏功能（技术实现）</h3><ol>\n<li><p>安全区系统(Electric Field)</p>\n<p> 游戏计时器<br> 根据预设点位(Pos)和尺寸(Scale)按时间触发缩圈<br> 伤害判定</p>\n</li>\n<li><p>Player</p>\n<p> FP Controller<br> Player物品栏<br> Player生命状态  </p>\n</li>\n<li><p>AI</p>\n<p> 巡逻系统<br> 攻击系统<br> AI生命状态  </p>\n</li>\n<li><p>武器系统</p>\n<p> 物理子弹/射线子弹<br> 子弹扩散  </p>\n</li>\n<li><p>UI</p>\n<p> 开始菜单<br> 主游戏界面—小地图<br> 主游戏界面—player信息<br> 主游戏界面—弹出类消息<br> 背包界面<br> 地图<br> 方向指示</p>\n</li>\n</ol>\n<h3 id=\"外部资源\"><a href=\"#外部资源\" class=\"headerlink\" title=\"外部资源\"></a>外部资源</h3><h2 id=\"Next-Gen-FPS\"><a href=\"#Next-Gen-FPS\" class=\"headerlink\" title=\"Next-Gen FPS\"></a>Next-Gen FPS</h2><p>todo 结构分析 功能改进</p>\n<h2 id=\"MapMagic\"><a href=\"#MapMagic\" class=\"headerlink\" title=\"MapMagic\"></a>MapMagic</h2><p>todo emmm</p>\n<h3 id=\"截图\"><a href=\"#截图\" class=\"headerlink\" title=\"截图\"></a>截图</h3>\n\n\n\n\n\n<p>先写论文 写完在更</p>\n","slug":"PUBG-Unity","updated":"2021-04-07T10:39:07.255Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2018/04/11/PUBG-Unity/","excerpt":"","categories":[{"name":"个人项目","slug":"个人项目","permalink":"https://blog.providencezhang.cn/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://blog.providencezhang.cn/tags/Unity/"},{"name":"FPS","slug":"FPS","permalink":"https://blog.providencezhang.cn/tags/FPS/"},{"name":"Sandbox","slug":"Sandbox","permalink":"https://blog.providencezhang.cn/tags/Sandbox/"}]},{"title":"A* Pathfinding","date":"2017-01-01T16:00:00.000Z","path":"2017/01/02/AStarPathfinding/","text":"A* Pathfinding tutorial in unity G cost: distance from starting nodeH cost(heuristic): distance from end nodeF cost: G cost + H cost 算最小F cost周围的node的cost，如果已经有值并且新cost小于旧cost，进行覆盖，迭代","raw":"---\ntitle: A* Pathfinding\ndate: 2017-1-2 00:00:00\ntag: \n    - algorithm\n---\n[A* Pathfinding tutorial in unity](https://www.youtube.com/watch?v=-L-WgKMFuhE&list=PLFt_AvWsXl0cq5Umv3pMC9SPnKjfp9eGW)\n\nG cost: distance from starting node  \nH cost(heuristic): distance from end node  \nF cost: G cost + H cost  \n\n算最小F cost周围的node的cost，如果已经有值并且新cost小于旧cost，进行覆盖，迭代  ","content":"<p><a href=\"https://www.youtube.com/watch?v=-L-WgKMFuhE&amp;list=PLFt_AvWsXl0cq5Umv3pMC9SPnKjfp9eGW\">A* Pathfinding tutorial in unity</a></p>\n<p>G cost: distance from starting node<br>H cost(heuristic): distance from end node<br>F cost: G cost + H cost  </p>\n<p>算最小F cost周围的node的cost，如果已经有值并且新cost小于旧cost，进行覆盖，迭代  </p>\n","slug":"AStarPathfinding","updated":"2020-05-25T11:59:26.656Z","comments":true,"link":"","permalink":"https://blog.providencezhang.cn/2017/01/02/AStarPathfinding/","excerpt":"","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://blog.providencezhang.cn/tags/algorithm/"}]}],"categories":[{"name":"随笔","slug":"随笔","permalink":"https://blog.providencezhang.cn/categories/%E9%9A%8F%E7%AC%94/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"论文综述","slug":"论文综述","permalink":"https://blog.providencezhang.cn/categories/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://blog.providencezhang.cn/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"个人项目","slug":"个人项目","permalink":"https://blog.providencezhang.cn/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"}],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://blog.providencezhang.cn/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"资源链接","slug":"资源链接","permalink":"https://blog.providencezhang.cn/tags/%E8%B5%84%E6%BA%90%E9%93%BE%E6%8E%A5/"},{"name":"装修","slug":"装修","permalink":"https://blog.providencezhang.cn/tags/%E8%A3%85%E4%BF%AE/"},{"name":"建材","slug":"建材","permalink":"https://blog.providencezhang.cn/tags/%E5%BB%BA%E6%9D%90/"},{"name":"室内设计","slug":"室内设计","permalink":"https://blog.providencezhang.cn/tags/%E5%AE%A4%E5%86%85%E8%AE%BE%E8%AE%A1/"},{"name":"图形学","slug":"图形学","permalink":"https://blog.providencezhang.cn/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"线上课程","slug":"线上课程","permalink":"https://blog.providencezhang.cn/tags/%E7%BA%BF%E4%B8%8A%E8%AF%BE%E7%A8%8B/"},{"name":"C++","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"notebook","slug":"notebook","permalink":"https://blog.providencezhang.cn/tags/notebook/"},{"name":"boost","slug":"boost","permalink":"https://blog.providencezhang.cn/tags/boost/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.providencezhang.cn/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"stl","slug":"stl","permalink":"https://blog.providencezhang.cn/tags/stl/"},{"name":"C/C++","slug":"C-C","permalink":"https://blog.providencezhang.cn/tags/C-C/"},{"name":"智能指针","slug":"智能指针","permalink":"https://blog.providencezhang.cn/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"},{"name":"设计模式","slug":"设计模式","permalink":"https://blog.providencezhang.cn/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://blog.providencezhang.cn/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"命令模式","slug":"命令模式","permalink":"https://blog.providencezhang.cn/tags/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/"},{"name":"Unity","slug":"Unity","permalink":"https://blog.providencezhang.cn/tags/Unity/"},{"name":"线程池","slug":"线程池","permalink":"https://blog.providencezhang.cn/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"Dx12","slug":"Dx12","permalink":"https://blog.providencezhang.cn/tags/Dx12/"},{"name":"WindowsApp","slug":"WindowsApp","permalink":"https://blog.providencezhang.cn/tags/WindowsApp/"},{"name":"COM","slug":"COM","permalink":"https://blog.providencezhang.cn/tags/COM/"},{"name":"Shader","slug":"Shader","permalink":"https://blog.providencezhang.cn/tags/Shader/"},{"name":"ICIP","slug":"ICIP","permalink":"https://blog.providencezhang.cn/tags/ICIP/"},{"name":"三维人体重建","slug":"三维人体重建","permalink":"https://blog.providencezhang.cn/tags/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA/"},{"name":"深度学习","slug":"深度学习","permalink":"https://blog.providencezhang.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"shift_net","slug":"shift-net","permalink":"https://blog.providencezhang.cn/tags/shift-net/"},{"name":"hmd","slug":"hmd","permalink":"https://blog.providencezhang.cn/tags/hmd/"},{"name":"ECS","slug":"ECS","permalink":"https://blog.providencezhang.cn/tags/ECS/"},{"name":"DOTS","slug":"DOTS","permalink":"https://blog.providencezhang.cn/tags/DOTS/"},{"name":"云服务","slug":"云服务","permalink":"https://blog.providencezhang.cn/tags/%E4%BA%91%E6%9C%8D%E5%8A%A1/"},{"name":"腾讯云","slug":"腾讯云","permalink":"https://blog.providencezhang.cn/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"},{"name":"研究生课程","slug":"研究生课程","permalink":"https://blog.providencezhang.cn/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"},{"name":"互联网体系结构","slug":"互联网体系结构","permalink":"https://blog.providencezhang.cn/tags/%E4%BA%92%E8%81%94%E7%BD%91%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"},{"name":"基础知识","slug":"基础知识","permalink":"https://blog.providencezhang.cn/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"C#","slug":"C","permalink":"https://blog.providencezhang.cn/tags/C/"},{"name":"数据分析","slug":"数据分析","permalink":"https://blog.providencezhang.cn/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://blog.providencezhang.cn/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"Kaggle","slug":"Kaggle","permalink":"https://blog.providencezhang.cn/tags/Kaggle/"},{"name":"3D model reconstruction","slug":"3D-model-reconstruction","permalink":"https://blog.providencezhang.cn/tags/3D-model-reconstruction/"},{"name":"文献综述","slug":"文献综述","permalink":"https://blog.providencezhang.cn/tags/%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/"},{"name":"reinforcement learning","slug":"reinforcement-learning","permalink":"https://blog.providencezhang.cn/tags/reinforcement-learning/"},{"name":"berkeley course","slug":"berkeley-course","permalink":"https://blog.providencezhang.cn/tags/berkeley-course/"},{"name":"Sergey Levine","slug":"Sergey-Levine","permalink":"https://blog.providencezhang.cn/tags/Sergey-Levine/"},{"name":"git","slug":"git","permalink":"https://blog.providencezhang.cn/tags/git/"},{"name":"sourcetree","slug":"sourcetree","permalink":"https://blog.providencezhang.cn/tags/sourcetree/"},{"name":"版本控制","slug":"版本控制","permalink":"https://blog.providencezhang.cn/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"项目管理","slug":"项目管理","permalink":"https://blog.providencezhang.cn/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"Andrew Ng","slug":"Andrew-Ng","permalink":"https://blog.providencezhang.cn/tags/Andrew-Ng/"},{"name":"Deeplearning","slug":"Deeplearning","permalink":"https://blog.providencezhang.cn/tags/Deeplearning/"},{"name":"AI","slug":"AI","permalink":"https://blog.providencezhang.cn/tags/AI/"},{"name":"pytorch","slug":"pytorch","permalink":"https://blog.providencezhang.cn/tags/pytorch/"},{"name":"cifar-10","slug":"cifar-10","permalink":"https://blog.providencezhang.cn/tags/cifar-10/"},{"name":"信息安全","slug":"信息安全","permalink":"https://blog.providencezhang.cn/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"},{"name":"加密","slug":"加密","permalink":"https://blog.providencezhang.cn/tags/%E5%8A%A0%E5%AF%86/"},{"name":"随机数","slug":"随机数","permalink":"https://blog.providencezhang.cn/tags/%E9%9A%8F%E6%9C%BA%E6%95%B0/"},{"name":"数字签名","slug":"数字签名","permalink":"https://blog.providencezhang.cn/tags/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/"},{"name":"XSS","slug":"XSS","permalink":"https://blog.providencezhang.cn/tags/XSS/"},{"name":"钓鱼网站","slug":"钓鱼网站","permalink":"https://blog.providencezhang.cn/tags/%E9%92%93%E9%B1%BC%E7%BD%91%E7%AB%99/"},{"name":"burpsuite","slug":"burpsuite","permalink":"https://blog.providencezhang.cn/tags/burpsuite/"},{"name":"机核","slug":"机核","permalink":"https://blog.providencezhang.cn/tags/%E6%9C%BA%E6%A0%B8/"},{"name":"游戏展","slug":"游戏展","permalink":"https://blog.providencezhang.cn/tags/%E6%B8%B8%E6%88%8F%E5%B1%95/"},{"name":"3A","slug":"3A","permalink":"https://blog.providencezhang.cn/tags/3A/"},{"name":"王妙一","slug":"王妙一","permalink":"https://blog.providencezhang.cn/tags/%E7%8E%8B%E5%A6%99%E4%B8%80/"},{"name":"GAD","slug":"GAD","permalink":"https://blog.providencezhang.cn/tags/GAD/"},{"name":"开发流程","slug":"开发流程","permalink":"https://blog.providencezhang.cn/tags/%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/"},{"name":"FPS","slug":"FPS","permalink":"https://blog.providencezhang.cn/tags/FPS/"},{"name":"Sandbox","slug":"Sandbox","permalink":"https://blog.providencezhang.cn/tags/Sandbox/"},{"name":"algorithm","slug":"algorithm","permalink":"https://blog.providencezhang.cn/tags/algorithm/"}]}